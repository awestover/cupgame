\section{Adaptive Filler Lower Bound}\label{sec:adaptive}

In this section we give a $2^{\polylog n}$-time filling strategy
that achieves backlog $n^{1 - \varepsilon}$ for any positive
constant $\varepsilon$. 
We also give a $O(n!)$-time filling strategy that achieves
backlog $\Omega(n)$.

We begin with a trivial filling strategy that we call
\defn{$\trivalg$} that gives backlog at least $1/2$ when applied
to at least $2$ cups.
\begin{proposition}
  \label{prop:adaptiveBase}
  Consider an instance of the negative-fill $1$-processor cup
  game on $n$ cups, and let the cups start in any state with
  average fill is $0$. If $n\ge 2$, there is an $O(1)$-step
  adaptive filling strategy $\trivalg$ that achieves backlog at
  least $1/2$. If $n=1$, $\trivalg$ achieves backlog $0$ in
  running time $0$.
\end{proposition}
\begin{proof}
  If $n=1$, $\trivalg$ does nothing and acheives backlog $0$; for
  thre rest of the proof we consider the case $n\ge 2$.

  Let $a$ and $b$ be the fullest and second fullest cups in the in
  the starting configuration, and let their initial fills be
  $\fil(a) = \alpha, \fil(b) = \beta$. 
  If $\alpha\ge 1/2$ the filler need not do anything, the desired
  backlog is already achieved.
  Otherwise, if $\alpha \in [0, 1/2]$, the filler places
  $1/2-\alpha$ fill into $a$ and $1/2 + \alpha$ fill into $b$
  (which is possible as both fills are in $[0,1]$, and they sum
  to $1$). Since $\alpha + \beta \ge 0$ we have $\beta \ge -\alpha$.
  Clearly $a$ and $b$ now both have fill at least $1/2$.
  The emptier cannot empty from both $a$ and $b$ as $p=1$, so
  even after the emptier empties from a cup we still have backlog
  $1/2$, as desired.
\end{proof}

% We begin by modifying the proof of the classic lower bound for
% the single-processor cup game to work with a cup configuration
% that includes negative fills; allowing for negative fills will be
% important when applying the result in later constructions. 
% \begin{proposition}
% \label{prop:adaptiveBaseAlternate}
%   Consider an instance of the negative-fill $1$-processor cup
%   game on $n$ cups, and let the cups start in any state where the
%   average fill is $0$. There is an $O(n)$-step adaptive filling
%   strategy that achieves backlog at least
%   $\frac{1}{4}(\ln (n/2) - 1)$.
% \end{proposition}
% \begin{proof}
%   Let $h = \frac{1}{4}(\ln (n/2) -1)$ be the desired fill. Once a cup with fill at
%   least $h$ is achieved the filler stops, and the algorithm is done.  
  
%   We claim that, at the beginning of the game, either the
%   algorithm is already done, or there are at least $n / 2$ cups
%   containing fills greater than $-2h$. If the filling process is
%   not yet complete then $\fil(c) < h$ for all cups $c$, and thus
%   the mass of the cups with non-negative fills is less than $hn$.
%   Assume for contradiction that at least $n / 2$ cups have fills
%   $-2h$ or smaller. The mass of those cups is less than or equal
%   to $-hn$. Since the mass of the cups with non-negative fills is
%   less than $hn$, it follows that the total mass of the cups is
%   negative, a contradiction. 

%   We now describe the filler's strategy. If the algorithm is not
%   already done at the beginning of the game, then at least $n /
%   2$ cups must have fills greater than $-2h$. At the beginning of
%   the algorithm, $n / 2$ such cups are labeled as \defn{active
%   cups}. In each of step of the algorithm, the filler distributes
%   $1$ unit of water evenly among the active cups. The emptier
%   then removes water from some cup $c$. Finally, the filler
%   reduces the number of active cups by $1$, removing cup $c$ if
%   it was active, and otherwise removing an arbitrary cup. Now
%   consider the state of the final active cup after $n / 2  - 1$
%   steps. This cup's fill has increased by 
%   $$1/(n/2) + 1/(n/2 - 1) + \cdots + 1/2 \ge \ln (n/2) -1 = 4h.$$ 
%   This cup's fill started as at least $-2h$. Thus this cup now
%   has fill at least $2h$, as desired.
% \end{proof}

Next we prove the \defn{Amplification Lemma}, which takes as
input a filling strategy $\alg(f)$ and outputs a new filling
strategy $\alg(f')$ that we call the \defn{amplification} of
$\alg(f)$. $\alg(f')$ is able to achieve higher fill than
$\alg(f)$; in particular, we will show that by starting with a
filling strategy $\alg(f_0)$ for achieving constant backlog and
then forming a sufficiently long sequence of filling strategies
$\alg(f_0), \alg(f_1), \ldots, \alg(f_{i_*})$ with
$\alg(f_{i+1})$ the amplification of $\alg(f_i)$, we eventually
get a filling strategy for achieving $\poly(n)$ backlog.

\begin{lemma}[Adaptive Amplification Lemma]\label{lem:adaptiveAmplification}
  Let $\delta\in(0,1/2]$ be a parameter.
  Let $\alg(f)$ be an adaptive filling strategy that 
  achieves backlog $f(n) < n$ in the negative-fill variable-processor cup game
  on $n$ cups in running time $T(n)$ starting from any initial
  cup state where the average fill is $0$.

  Then there exists an adaptive filling strategy $\alg(f')$ that
  achieves backlog $f'(n)$ satisfying 
  $$f'(n) \ge (1-\delta)f(\floor{(1-\delta)n}) + f(\ceil{\delta n}) $$
  and $f'(n) \ge f(n)$
  in the negative-fill variable-processor cup game on $n$ cups in running time 
  $$T'(n) \le n\ceil{\delta n} \cdot T(\floor{(1-\delta)n}) + T(\ceil{\delta n})$$
  starting from any initial cup state where the average fill is $0$.
\end{lemma}
\begin{proof}
  Let $n_A = \ceil{\delta n}, n_B = n-n_A = \floor{(1-\delta) n}$.

  The filler defaults to using $\alg(f)$ if 
  $$f(n) \ge (1-\delta)f(n_B) + f(n_A).$$ 
  In this case using $\alg(f)$ achieves the desired backlog in
  the desired running time. In the rest of the proof, we describe
  our strategy in the case that we cannot simply use $\alg(f)$ to
  achieve the desired backlog. 

  Let $A$, the \defn{anchor set}, be initialized to consist of
  the $n_A$ fullest cups, and let $B$ the
  \defn{non-anchor set} be initialized to consist of the rest of
  the cups (so $|B| = n_B$). Let $h = (1-\delta)f(n_B).$

  The filler's strategy can be summarized as follows: \\
  \textbf{Step 1:} Make $\mu(A) \ge h$ by using $\alg(f)$
  repeatedly on $B$ to achieve cups with fill at least $\mu(B) +
  f(n_B)$ in $B$ and then swapping these into $A$. While doing
  this the filler always places $1$ unit of fill in each anchor
  cup.\\
  \textbf{Step 2:} Use $\alg(f)$ once on $A$ to obtain some cup
  with fill $\mu(A)+f(n_A)$.\\
  Note that in order to use $\alg(f)$ on subsets of the cups the
  filler will need to vary $p$.

  We now describe how to achieve Step 1, which is
  complicated by the fact that the emptier may attempt to
  prevent the filler from achieving high fill in a cup
  in $B$.

  The filling strategy always places $1$ unit of water in each
  anchor cup. This ensures that no cups in the anchor set ever
  have their fill decrease. If the emptier wishes to keep the
  average fill of the anchor cups from increasing, then emptier
  must empty from every anchor cup on each step. If the emptier
  fails to do this on a given round, then we say that the emptier
  has \defn{neglected} the anchor cups. 

  We say that the filler \defn{applies} $\alg(f)$ to $B$ if it
  follows the filling strategy $\alg(f)$ on $B$ while placing $1$
  unit of water in each anchor cup. An application of $\alg(f)$
  to $B$ is said to be \defn{successful} if $A$ is never
  neglected during the application of $\alg(f)$ to $B$. The
  filler uses a procedure that we call a \defn{swapping-process}
  to achieve the desired average fill in $A$. In a
  swapping-process, the filler repeatedly applies $\alg(f)$ to
  $B$ until a successful application occurs, and then takes the
  cup generated by $\alg(f)$ within $B$ on this successful
  application with fill at least $\mu(B) + f(|B|)$ and swaps it
  with the least full cup in $A$ so long as doing so would
  increase $\mu(A)$. If the average fill in $A$ ever reaches $h$,
  then the algorithm immediately halts (even if it is in the
  middle of a swapping-process) and is complete.

  We give pseudocode for the filling strategy in
  \cref{alg:adaptiveAmplification}.

\begin{algorithm}
  \caption{Adaptive Amplification (Step 1)}
  \label{alg:adaptiveAmplification}
  \begin{algorithmic}
    \State \textbf{Input:} $\alg(f), \delta, $ set of $n$ cups
    \State \textbf{Output:} Guarantees that $\mu(A) \ge h$
    \State
    \State $A \gets n_A$ fullest cups, $B \gets $ rest of the cups
    \State Always place $1$ fill in each cup in $A$
    \While{$\mu(A) < h$} \Comment Swapping-Processes
    \State Immediately \textbf{exit} this loop if ever $\mu(A) \ge h$ 
      \State successful $\gets $ false
      \While{not successful} 
      \State Apply $\alg(f)$ to $B$, $\alg(f)$ gives cup $c$
        \If{$\fil(c) \ge h$}
          \State successful $\gets$ true
        \EndIf
      \EndWhile
      \State Swap $c$ with least full cup in $A$
    \EndWhile
  \end{algorithmic}
\end{algorithm}
  
  Note that $$\mu(A) \cdot |A| + \mu(B)\cdot |B| = \mu(AB) \ge 0,$$
  as $\mu(AB)$ starts as $0$, but could become positive if the
  emptier skips emptyings.
  Thus we have 
  $$\mu(A) \ge - \mu(B) \cdot
  \frac{\floor{(1-\delta)n}}{\ceil{\delta n}} \ge -
  \frac{1-\delta}{\delta} \mu(B).$$ Thus, if at any
  point $B$ has average fill lower than $-h \cdot
  \delta/(1-\delta)$, then $A$ has average fill at least $h$, so
  the algorithm is finished. Thus we can assume in our analysis that
  \begin{equation}
    \mu(B) \ge -h\cdot\delta/(1-\delta).
  \label{eq:Batleast}
  \end{equation}
  We will now show that during each swapping process, the filler
  applies $\alg(f)$ to $B$ at most $h n_A$ times. 
  Each time the emptier neglects the anchor set, the mass of the
  anchor set increases by $1$. If the emptier neglects the anchor set $h
  n_A$ times, then the average fill in the anchor set increases by
  $h$. Since $\mu(A)$ started as at least $0$, and
  since $\mu(A)$ never decreases (note in particular that cups are only
  swapped into $A$ if doing so will increase $\mu(A)$), an
  increase of $h$ in $\mu(A)$ implies that $\mu(A) \ge h$, as
  desired. Thus the swapping process consists of at most
  $h n_A$ applications of $\alg(f)$.  

  Consider the fill of a cup $c$ swapped into $A$ at the end of a
  swapping-process. Cup $c$'s fill is at least $\mu(B) + f(n_B)$,
  which by \eqref{eq:Batleast} is at least
  $$-h \cdot \frac{\delta}{1-\delta} + f(n_B) = (1-\delta)f(n_B) = h.$$ 
  Thus the algorithm for Step 1 succeeds within $|A|$
  swapping-processes, since at the end of the $|A|$-th swapping
  process either every cup in $A$ has fill at least $h$, or the
  algorithm halted before $|A|$ swapping-processes because it
  already achieved $\mu(A) \ge h$. 
  
  After achieving $\mu(A) \ge h$, the filler performs Step 2,
  i.e. the filler applies $\alg(f)$ to $A$, and hence achieves a
  cup with fill at least $$\mu(A) + f(|A|) \ge (1-\delta)f(n_B) +
  f(n_A),$$ as desired.

  Now we analyze the running time of the filling strategy
  $\alg(f')$. First, recall that in Step 1 $\alg(f')$ calls
  $\alg(f)$ on $B$, which has size $n_B$, as many as $h n_A$ times.
  Because we mandate that $h < n$, Step 1 contributes no more
  than $(n\cdot n_A) \cdot T(n_B)$ to the running time.
  Step 2 requires applying $\alg(f)$ to $A$, which has size
  $n_A$, once, and hence
  contributes $T(n_A)$ to the running time. Summing these we have
  $$T'(n) \le n \cdot n_A \cdot T(n_B) + T(n_A).$$

\end{proof}

We next show that by recursively using the Amplification Lemma we
can achieve backlog $n^{1 - \varepsilon}$.
\begin{theorem}
  \label{thm:adaptivePoly}
  There is an adaptive filling strategy for the variable-processor cup game on
  $n$ cups that achieves backlog $\Omega(n^{1-\varepsilon})$ for any constant
  $\varepsilon > 0$ of our choice in running time $2^{O(\log^2 n)}$.
\end{theorem}
\begin{proof}
  Take constant $\varepsilon \in (0,1/2)$. Let $c, \delta$ be
  constants that will be chosen (later) as functions of
  $\varepsilon$ satisfying $c\in (0,1), 0 < \delta \ll 1/2$.
  We show how to achieve backlog at least $cn^{1-\varepsilon}-1$.

 Let $\alg(f_0)=\trivalg$, the algorithm given by
 \cref{prop:adaptiveBase}; recall $\trivalg$ achieves backlog $f_0(k)
 \ge 1/2$ for all $k \ge 2$, and $f_0(1) = 0$. 

  Next, using the Amplification Lemma we recursively construct
  $\alg(f_{i+1})$ as the amplification of $\alg(f_{i})$ for $i\ge 0$. 

  Define a sequence $g_i$ with 
  $$ g_i = \begin{cases}
    \ceil{16/\delta},  & i = 0,\\
    \floor{g_{i-1}/(1-\delta)} & i \ge 1
  \end{cases} $$

  We claim the following regarding this construction:
  \begin{clm}
    \label{clm:fikinduction}
    For all $i\ge0$,
    \begin{equation}
      f_i(k) \ge ck^{1-\varepsilon}-1\,\, \text{ for all }\,\, k\in [g_{i}].
    \label{eqn:fikinduction}
    \end{equation}
  \end{clm}
  \begin{proof}
  We prove \cref{clm:fikinduction} by induction on $i$.
  For $i=0$, the base case, \eqref{eqn:fikinduction} can
  be made true by taking $c$ sufficiently small; in particular,
  taking $c<1$ makes \eqref{eqn:fikinduction} hold for $k = 1$,
  and, as $g_0 > 2$, taking $c$ small enough to make $c
  g_0^{1-\varepsilon} -1 \le f_0(g_0) = 1/2$ makes
  \eqref{eqn:fikinduction} hold for $k\in [2, g_0]$ by
  monotonicity of $k \mapsto ck^{1-\varepsilon}-1$. \footnote{Note
  that it is important here that $\varepsilon$ and
  $\delta$ are constants, that way $c$ is also a constant.}

  As our inductive hypothesis we assume
  \eqref{eqn:fikinduction} for $f_i$; we aim to show that 
  \eqref{eqn:fikinduction} holds for $f_{i+1}$. Note that, by
  design of $g_i$, if $k \le g_{i+1}$ then $\floor{k\cdot (1-\delta)} \le g_i$.
  Consider any $k\in [g_{i+1}]$. First we deal with the trivial
  case where $k \le g_0$. In this case 
  $$f_{i+1}(k) \ge f_i(k) \ge \cdots \ge f_0(k) \ge ck^{1-\varepsilon} -1.$$

  Now we consider the case where $k \ge g_0$.
  Since $f_{i+1}$ is the amplification of $f_i$ we have
  $$f_{i+1}(k) \ge (1-\delta) f_i(\floor{(1-\delta)k}) + f_i(\ceil{\delta k}).$$
  By our inductive hypothesis, which applies as $\ceil{\delta k}\le g_i, \floor{k\cdot (1-\delta)} \le g_i$, we have
  $$f_{i+1}(k) \ge (1-\delta) (c \cdot\floor{(1-\delta)k}^{1-\varepsilon}-1) + c\ceil{\delta k}^{1-\varepsilon} - 1. $$
  Dropping the floor and ceiling, incurring a $-1$ for dropping the floor, we have
  $$f_{i+1}(k) \ge (1-\delta) (c \cdot ((1-\delta)k-1)^{1-\varepsilon}-1) + c (\delta k)^{1-\varepsilon} - 1.$$
  Because $(x-1)^{1-\varepsilon} \ge x^{1-\varepsilon} -1$, due to the
  fact that $x\mapsto x^{1-\varepsilon}$ is a sub-linear
  sub-additive function, we have 
  $$f_{i+1}(k) \ge (1-\delta) c \cdot (((1-\delta)k)^{1-\varepsilon}-2) + c(\delta k)^{1-\varepsilon}-1.$$
  Moving the $ck^{1-\varepsilon}$ to the front we have
  $$ f_{i+1}(k) \ge ck^{1-\varepsilon} \cdot\left((1-\delta)^{2-\varepsilon} + \delta^{1-\varepsilon} - \frac{2(1-\delta)}{k^{1-\varepsilon}} \right) -1.$$
  Because $(1-\delta)^{2-\varepsilon} \ge 1-(2-\varepsilon)\delta$, a fact called Bernoulli's Identity, we have
  $$f_{i+1}(k) \ge ck^{1-\varepsilon} \cdot\left(1-(2-\varepsilon)\delta + \delta^{1-\varepsilon} - \frac{2(1-\delta)}{k^{1-\varepsilon}} \right)-1.$$
  Of course $-2(1-\delta) \ge -2$, so 
  $$f_{i+1}(k) \ge ck^{1-\varepsilon} \cdot\left(1-(2-\varepsilon)\delta + \delta^{1-\varepsilon} - \frac{2}{k^{1-\varepsilon}} \right) -1.$$
  Because 
  $$\frac{-2}{k^{1-\varepsilon}} \ge \frac{-2}{g_0^{1-\varepsilon}} \ge -2(\delta/16)^{1-\varepsilon} \ge -\delta^{1-\varepsilon}/2,$$ 
  which follows from our choice of $g_0 = \ceil{16/\delta}$ and the restriction
  $\varepsilon<1/2$, we have
  $$f_{i+1}(k) \ge ck^{1-\varepsilon}
  \cdot\left(1-(2-\varepsilon)\delta + \delta^{1-\varepsilon} - \delta^{1-\varepsilon}/2 \right)-1.$$
  Finally, combining terms we have
  $$f_{i+1}(k) \ge  ck^{1-\varepsilon} \cdot\left(1-(2-\varepsilon)\delta + \delta^{1-\varepsilon}/2\right)-1. $$

  Because $\delta^{1-\varepsilon}$ dominates $\delta$ for
  sufficiently small $\delta$, there is a choice of
  $\delta=\Theta(1)$ such that 
  $$1-(2-\varepsilon)\delta + \delta^{1-\varepsilon}/2 \ge 1.$$ 
  Taking $\delta$ to be this
  small we have,
  $$f_{i+1}(k) \ge ck^{1-\varepsilon}-1,$$
  completing the proof. We remark that the choices of $c, \delta$
  are the same for every $i$ in the inductive proof, and depend
  only on $\varepsilon$. 
  \end{proof}

  To complete the proof, we will show that $g_i$ grows exponentially in $i$. Thus,
  after there exists $i_* \le O(\log n)$ such that
  $g_{i_*} \ge n$, and hence we have an algorithm $\alg(f_{i_*})$
  that achieves backlog $cn^{1-\varepsilon}-1$ on $n$ cups, as
  desired.
  
  We lower bound the sequence $g_i$ with another sequence $g_i'$
  defined as 
  $$g_i'=\begin{cases}
    4/\delta, & i=0\\
    g_{i-1}' / (1-\delta) -1, & i> 0.
  \end{cases}$$
  Solving this recurrence, we find 
  $$g_i' = \frac{4-(1-\delta)^2}{\delta} \frac{1}{(1-\delta)^i}
  \ge \frac{1}{(1-\delta)^i},$$
  which clearly exhibits exponential growth. 
  In particular, let $i_* = \ceil{\log_{1/(1-\delta)} n}$. Then,
  $$ g_{i_*} \ge g_{i_*}' \ge n,$$ as desired.

  Let the running time of $f_i(n)$ be $T_i(n)$. From the
  Amplification Lemma we have following recurrence bounding
  $T_i(n)$:
  \begin{align*}
    T_i(n) &\le n\ceil{\delta n} \cdot T_{i-1}(\floor{(1-\delta)n}) +
  T_{i-1}(\ceil{\delta n}) \\
  &\le 2n^2T_{i-1}(\floor{(1-\delta)n}).
  \end{align*}
  It follows that $\alg(f_{i_*})$, recalling that $i_* \le O(\log n)$, has running time
  $$T_{i_*}(n) \le (2n^2)^{O(\log n)} \le 2^{O(\log^2 n)}$$
  as desired.

\end{proof}

Now we provide a very simple construction that can achieve backlog $\Omega(n)$
in very long games. The construction can be interpreted as the same
argument as in \cref{thm:adaptivePoly} but with an extremal setting of
$\delta$ to $\Theta(1/n)$. \footnote{Or more precisely, setting
$\delta$ in each level of recursion to be $\Theta(1 / n)$, where
$n$ is the subproblem size; note in particular that $\delta$
changes between levels of recursion, which was not the case in
the proof of \cref{thm:adaptivePoly}.}

\begin{proposition}
  \label{prop:factorialTimeAlg}
  There is an adaptive filling strategy that
  achieves backlog $\Omega(n)$ in time $O(n!)$.
\end{proposition}
\begin{proof}
  First we construct a slightly stronger version of $\trivalg$
  that achieves backlog $1$ on $n \ge n_0=8$ cups, instead of
  just backlog $1/2$; this simplifies the analysis.
  \begin{clm}
    There is a filling algorithm $\trivalg_2$ that achieves
    backlog at least $1$ on $n_0 = 8$ cups.
  \end{clm}
  \begin{proof}
    Let $\trivalg_1$ be the amplification of $\trivalg$ using
    $\delta = 1/2$. On $4$ cups $\trivalg_1$ achieves backlog at
    least $(1/2)(1/2)+1/2 = 3/4$.
    Let $\trivalg_2$ be the amplification of $\trivalg_1$ using
    $\delta = 1/2$. On $8$ cups $\trivalg_2$ achieves backlog at
    least $(1/2)(3/4) + 3/4 \ge 1$.
  \end{proof}

  Let $\alg(f_0)=\trivalg_2$; we have $f_0(k) \ge 1$ for all $k
  \ge n_0$. For $i > 0$ we construct $\alg(f_{i})$ as the
  amplification of $\alg(f_{i-1})$ using the Amplification Lemma
  with parameter $\delta = 1/(i+1)$. 

  We claim the following regarding this construction:
  \begin{clm}
    \label{clm:yayactuallygetn}
  For all $i\ge 0$,
  \begin{equation}
    \label{eq:omegaNpfinduction}
    f_i((i+1)n_0) \ge \sum_{j=0}^i \left(1-\frac{j}{i+1}\right).
  \end{equation}
  \end{clm}
  \begin{proof}
  We prove \cref{clm:yayactuallygetn} by induction on $i$. When
  $i=0$, the base case, \eqref{eq:omegaNpfinduction} becomes
  $f_{0}(n_0) \ge 1$ which is true. Assuming
  \eqref{eq:omegaNpfinduction} for $f_{i-1}$, we now show
  \eqref{eq:omegaNpfinduction} holds for $f_{i}$.
  Because $f_{i}$ is the amplification of $f_{i-1}$ with $\delta = 1/(i+1)$, we have by the Amplification Lemma
  $$f_{i}((i+1)\cdot n_0) \ge \left(1 - \frac{1}{i+1}\right) f_{i-1}(i\cdot n_0) + f_{i-1}(n_0).$$
  Since $f_{i-1}(n_0) \ge f_0(n_0) \ge 1$ we have
  $$f_{i}((i+1)\cdot n_0) \ge \left(1 - \frac{1}{i+1}\right) f_{i-1}(i\cdot n_0) + 1.$$
  Using the inductive hypothesis we have
  $$f_{i}((i+1)\cdot n_0) \ge \left(1 - \frac{1}{i+1}\right)\sum_{j=0}^{i-1} \left(1-\frac{j}{i}\right) + 1.$$
  Note that 
  \begin{align*}
    \left(1 - \frac{1}{i+1}\right)\cdot \left(1-\frac{j}{i}\right) &= \frac{i}{i+1} \cdot \frac{i-j}{i} \\
  &= \frac{i-j}{i+1}\\
  &= 1 - \frac{j+1}{i+1}.
  \end{align*}
  Thus we have
  $$f_{i}((i+1)\cdot n_0) \ge \sum_{j=1}^{i} \left(1-\frac{j}{i+1}\right) + 1 = \sum_{j=0}^{i} \left(1-\frac{j}{i+1}\right),$$
  as desired.
  \end{proof}

  Let $i_* = \floor{n/n_0}-1$, which by design satisfies
  $(i_*+1)n_0 \le n$. By \cref{clm:yayactuallygetn} we have
  $$f_{i_*}((i_*+1)\cdot n_0) \ge \sum_{j=0}^{i_*} \left(1 -
  \frac{j}{i_*+1} \right) = i_*/2 + 1.$$ As $i_* = \Theta(n)$, we
  have thus shown that $\alg(f_{i_*})$ can achieve backlog
  $\Omega(n)$ on $n$ cups.

  Let $T_i$ be the running time of $\alg(f_i)$.
  The recurrence for the running running time of $f_{i_*}$ is 
  $$T_i(n) \le n \cdot n_0T_{i-1}(n-n_0)+O(1).$$
  Clearly $T_{i_*}(n) \le O(n!)$.

  % This algorithm can be interpreted very simply. To achieve large backlog on
  % $n$ cups we create an anchor set $A$ of $n_0$ cups and a set $B$ of $n-n_0$
  % cups; We recursively apply our strategy to $B$ for each cup in $A$. In
  % order for the average fill difference between $A$ and $B$ to be $f(n-n_0)$,
  % $\mu(A)$ must rise by $\frac{n-n_0}{n}$ of this difference whereas $\mu(B)$
  % must sink by $\frac{n_0}{n}$ of this difference. Hence we achieve average
  % fill $\frac{n-n_0}{n}f(n-n_0)$ in $A$. Then, using the strategy from
  % \cref{prop:adaptiveBase} we can achieve backlog $1$ on these cups. 
\end{proof}

