\documentclass[twocolumn]{article}[10pt]
\usepackage[left=1in, right=1in, top=1in, bottom=1in]{geometry}
\usepackage[moderate, mathspacing=normal]{savetrees}

\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{xspace}

\newcommand{\defn}[1]{{\textit{\textbf{\boldmath #1}}}\xspace}
\renewcommand{\paragraph}[1]{\vspace{0.09in}\noindent{\bf \boldmath #1.}} 
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\Var}{\text{Var}}
\DeclareMathOperator{\img}{Im}
\DeclareMathOperator{\polylog}{\text{polylog}}
\DeclareMathOperator{\poly}{\text{poly}}
\DeclareMathOperator{\st}{\text{ such that }}
\DeclareMathOperator{\tilt}{\text{tilt}}
\DeclareMathOperator{\fil}{\text{fill}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\newcommand{\contr}[0]{\[ \Rightarrow\!\Leftarrow \]}
\newcommand{\defeq}{\vcentcolon=}
\newcommand{\eqdef}{=\vcentcolon}

\newtheorem{fact}{Fact}
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}
\newtheorem{proposition}{Proposition}
\newtheorem{clm}{Claim}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{theorem}{Theorem}
\newtheorem{conjecture}{Conjecture}

\usepackage{authblk}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}
\fancyfoot[R]{\thepage}
\renewcommand{\headrulewidth}{0pt}

\title{Variable-Processor Cup Games}
\date{\vspace{-5ex}}

\author[1]{\small William Kuszmaul\thanks{Supported by a Hertz fellowship and a NSF GRFP fellowship}}
\author[2]{\small Alek Westover\thanks{Supported by MIT PRIMES}}

\affil[ ]{\footnotesize MIT\textsuperscript{1}, MIT PRIMES\textsuperscript{2}}
\affil[ ]{\textit{kuszmaul@mit.edu, alek.westover@gmail.com}}


\begin{document}
\maketitle
\abstract{ 
  In a \defn{cup game} a filler and an emptier take turns adding and removing water
  from cups, subject to certain constraints. In one version of the cup game,
  the $p$-processor cup game, the filler distributes $p$ units of water among
  the $n$ cups with at most $1$ unit of water to any particular cup, and the
  emptier chooses $p$ cups to remove at most one unit of water from. Analysis
  of the cup game is important for applications in processor scheduling, buffer
  management in networks, quality of service guarantees, and deamortization.

  We investigate a new variant of the classic multi-processor cup game, which
  we call the \defn{variable-processor cup game}, in which the resources of the
  emptier and filler are variable. In particular, in the variable-processor cup
  game the filler is allowed to change $p$ at the beginning of each round. 
  Although the modification to allow variable resources seems small, we
  show that it drastically alters the outcome of the game.

  We construct a filling strategy that an adaptive filler can use to get
  backlog $\Omega(n)$ in running time $2^{O(n)}$. We also construct a filling
  strategy that an adaptive filler can use to get backlog
  $\Omega(n^{1-\epsilon})$ for any constant $\epsilon > 0$ in running time
  $2^{O(\log ^2 n)}$. Not only is this bound shockingly large, but the steep
  trade off-curve between running-time and backlog is very surprising: the time
  required to genuinely get a $1$ as the exponent instead of $1-\epsilon$ (e.g.
  $0.999$) goes up from quasi-polynomial time to exponential time!

  Furthermore, we demonstrate that this lower bound on backlog is tight: 
  using a novel set of invariants we prove that a greedy emptier never lets
  backlog exceed $O(n)$.

  We also investigate bounds on an oblivious filler. We show, using
  concentration bounds for random variables (Hoeffding's Inequality), that --
  surprisingly -- an oblivious filler can use very similar techniques as the
  adaptive filler to achieve very large backlog. In particular, an oblivious
  filler can achieve backlog $2^{\Omega(\sqrt{\log n})}$ in running time
  $O(\poly(n))$ with constant probability against any ``greedy-like" emptier.
}

\section{Introduction}\label{sec:intro}
\paragraph{Definition and Motivation}
The \defn{cup game} is a multi-round game in which the two players -- the
\defn{filler} and the \defn{emptier} -- take turns adding and removing water
from cups. On each round of the classic \defn{$p$-processor cup game} on $n$
cups, the filler first distributes $p$ units of water among
the $n$ cups with at most $1$ unit to any particular cup (without this
restriction the filler can trivially achieve unbounded backlog by placing all
of its fill in a single cup every round), and then the emptier 
removes at most $1$ unit of water from each of $p$ cups\footnote{note that negative
fill is not allowed, so if the emptier empties from a cup with fill below $1$
the cups fill will become $0$.}.

The cup game naturally arises in the study of processor-scheduling.
The incoming water added by the filler represents work added to the system at
time steps. At each time step after the new work comes in each of $p$
processors must be allocated to a task, which they will achieve $1$ unit of
progress on before the next time step. The assignment of processors to tasks is
modeled by the emptier deciding which cups to empty from. The backlog of
the system is the largest amount of work left on any given task. To model this,
in the cup game, the \defn{backlog} of the cups is defined to be the fill of
the fullest cup at a given state. 
It is important to know bounds on how large backlog can get.

\paragraph{Previous Work}
The bounds on backlog are well known for the case where $p=1$, i.e. the
\defn{single-processor cup game}.
In the single-processor cup game an adaptive filler can achieve backlog
$\Omega(\log n)$ and a greedy emptier never lets backlog exceed $O(\log n)$.
The bounds are much better against an oblivious filler.
In the randomized version of the single-processor cup game, which can be
interpreted as a smoothed analysis of the deterministic version, the emptier
never lets backlog exceed $O(\log \log n)$, and a filler can achieve backlog
$\Omega(\log\log n)$.

Recently Kuszmaul has achieved bounds on the case where $p>1$, i.e. the
\defn{multi-processor cup game} \cite{wku20}. Kuszmaul showed that in the 
$p$-processor cup game on $n$ cups a greedy emptier never lets backlog exceed
$O(\log n)$. He also proved a lower bound of $\Omega(\log (n-p))$. Recently we
showed a lower bound of $\Omega(\log n - \log (n-p))$. Combined these bounds
imply a lower bound of $\Omega(\log n)$.
Kuszmaul also established an upper bound of $O(\log\log n + \log p)$ against
oblivious fillers, and a lower bound of $\Omega(\log\log n)$ (note that tight
bounds on backlog against an oblivious filler are not yet known for large $p$).

\paragraph{Our Variant}
We investigate a variant of the vanilla multi-processor cup game which we call
the \defn{variable-processor cup game}. In the variable-processor cup game the
filler is allowed to change $p$ (the total amount of water that the filler
adds, and the emptier removes, from the cups per round) at the beginning of
each round. Note that we do not allow the resources of the filler and emptier
to vary separately; just like in the classic cup game we take the resources of
the filler and emptier to be identical.
Although this restriction may seem artificial, it is crucial; if
the filler has more resources than the emptier, then
the filler could trivially achieve unbounded backlog, as average fill will
increase by at least some positive constant at each round.
Taking the resources of the players to be identical makes the game balanced,
and hence interesting.

A priori having variable resources offers neither player a clear advantage:
lower values of $p$ mean that the emptier is at more of a discretization
disadvantage but also mean that the filler can ``anchor" fewer cups\footnote{A
useful part of many filling algorithms is maintaining an ``anchor" set of
``anchored" cups. The filler always places $1$ unit of water in each anchored
cup. This ensures that the fill of an anchored cup never decreases after it is
placed in the anchor set.}. We hoped that the variable-processor cup game could
be simulated in the vanilla multi-processor cup game, because the extra
ability given to the filler does not seem very strong. 

% We invented the new version of the cup game arose as we tried to get a bound of
% $\Omega(\log p)$ backlog in the multi-processor game against an oblivious
% filler, which would combine with previous results to give us a lower bound that
% matches our upper bound: $O(\log\log n + \log p)$ \cite{wku20}. In Proposition
% \ref{prop:obliviousBase} we prove that there is an oblivious filling strategy
% in the variable-processor cup game on $n$ cups that achieve backlog
% $\Omega(\log n)$ as desired. \footnote{Note that we have $\Omega(\log n)$ in
%   this proposition instead of $\Omega(\log p)$ because the filler can increase
%   the number of processors, so it increases the number of processors to $n-1$
%   to start. A nearly identical construction could be used to show that backlog
%   $\Omega(\log p_{\max})$ can be achieved, where the number of processors
%   starts at $p_{\max}$ and the filler does not ever increase the number of
%   processors. However, using $p_{\max} = n$ is natural in the
% variable-processor cup game, so we do not consider the game with the
% restriction that the filler can not increase the number of processors above
% some $p_{\max} < n$.}
However, we show that attempts at simulating the variable-processor cup
game are futile because the variable-processor cup game
is--surprisingly--vastly different from the multi-processor cup game. 

\paragraph{Outline and Results}
In Section \ref{sec:prelims} we establish the conventions and notations we will
use to discuss the variable-processor cup game. 

In Section \ref{sec:adaptive} we provide an inductive
proof of a lower bound on backlog in Corollary \ref{cor:adaptivePoly}.
The base case of the argument is a direct consequence of Proposition
\ref{prop:adaptiveBase}, and the inductive step follows from the ``Adaptive
Amplification Lemma" (Lemma \ref{lem:adaptiveAmplification}). Corollary
\ref{cor:adaptivePoly} gives a lower bound of $\Omega(n)$ on backlog. Corollary
\ref{cor:adaptivePoly} provides two algorithms: one algorithm with running time
$2^{O(n)}$ that achieves backlog $\Omega(n)$, and another with running time
$2^{O(\log^2 n)}$ that achieves backlog $\Omega(n^{1-\epsilon})$ for any
constant $\epsilon > 0$.

In Section \ref{sec:adaptiveUpperBound} we prove a novel invariant: the average
fill of the $k$ fullest cups is at most $2n-k$. In particular this implies
(setting $k=1$) that backlog is $O(n)$. Thus, our analysis is tight.

Section \ref{sec:oblivious} has similar macro-structure to Section
\ref{sec:adaptive}: We lower bound backlog in Corollary
\ref{cor:obliviousPoly}, using Proposition \ref{prop:obliviousBase} as the base
case of the inductive argument and the ``Oblivious Amplification Lemma" (Lemma
\ref{lem:obliviousAmplification}) to facilitate the inductive step. Corollary
\ref{cor:obliviousPoly} gives the lower bound $2^{\Omega(\sqrt{\log n})}$ on
backlog, against a ``greedy-like" emptier. In particular the corollary asserts
that we can achieve this backlog in time $O(\poly(n))$. Note that the
restriction on runtime of the filler is the main way in which this bound
differs from the adaptive case.

\section{Preliminaries}\label{sec:prelims}
The cup game consists of a sequence of rounds. On the $t$-th round the state
starts as $S_t$. The filler chooses the number of processors $p_t$ for the
round. Then the filler distributes $p_t$ units of water among the cups (with at
most $1$ unit of water to any particular cup). After this, the game is in an
intermediate state, which we call state $I_t$. Then the emptier chooses $p_t$
cups to empty at most $1$ unit of water from. Note that if the fill of a cup
that the emptier empties from is less than $1$ the emptier reduces the fill of
this cup to $0$ by emptying from it; we say that the emptier \defn{zeros-out} a
cup if it empties from a cup with fill less than $1$. Note that whenever the
emptier zeros-out a cup the emptier has removed less fill than the filler has
added; hence the average fill will increase. This concludes the round; the
state of the game is now $S_{t+1}$.

Denote the fill of a cup $c$ by $\fil(c)$. Let the \defn{positive tilt} of a cup $c$ be
$\tilt(c) = \max(0, \fil(c))$, and let the positive tilt of a set $X$ of
cups be $\tilt(X) = \sum_{c\in X} \tilt(c)$. Let the \defn{mass} of a set of cups $X$
be $m(X) = \sum_{c\in X} \fil(c)$. Denote the average fill of a set of cups $X$
by $\mu(X)$. Note that $\mu(X) |X| = m(X)$.

Let the \defn{rank} of a cup at a given state be its position in a list of the
cups sorted by fill at the given state, breaking ties arbitrarily but
consistently. For example, the fullest cup at a state has rank $1$, and the
least full cup has rank $n$.

Many of our lower bound proofs will adopt the convention of allowing for
negative fill. This is because our results are used recursively, so this
negative fill is really just fill below the average fill. Note that it is
strictly easier for the filler to achieve high backlog when cups can zero out,
because then some of the emptiers resources are wasted. On the other hand,
during the upper-bound proof we show that a greedy emptier maintains the
desired invariants even if cups zero-out. This is crucial as the game is harder
for the emptier when cups can zero out.

When measuring fill relative to average fill, we will reference the actual --
i.e. non-relative -- fills by calling them \defn{absolute} fills.

\section{Adaptive Filler Lower Bound}\label{sec:adaptive}
\begin{proposition}
\label{prop:adaptiveBase}
  There exists an adaptive filling strategy for the variable-processor cup game
  on $n$ cups that achieves backlog at least $\frac{1}{4}\ln (n/2)$, where fill
  is relative to the average fill of the cups, with negative fill allowed.
\end{proposition}
\begin{proof}
  Let $h = \frac{1}{4}\ln (n/2)$ be the desired fill. Once a cup with fill at
  least $h$ is achieved the filler stops, the process completed.  
  Let $A$ consist of the $n/2$ fullest cups, and $B$ consist of the rest of the
  cups. Note that $A, B$ are implicitly functions of the round $t$.

  If the process is not yet complete, that is $\fil(c) < h$ for all cups $c$,
  then $\tilt(A\cup B) < h\cdot n$. Assume for sake of contradiction that there
  are more than $n/2$ cups $c$ with $\fil(c) \le -2h$. The mass of those cups
  would be at most $-hn$ but the mass of the remaining cups cannot exceed
  $hn/2$. This implies that average fill is negative when it is in fact $0$ by
  definition, a contradiction. Hence there are at most $n/2$ cups $c$ with
  $\fil(c) \le -2h$. 

  The filler sets the number of processors equal to $1$ and plays a single
  processor cup game on $n/2$ cups that each have fill at least $-2h$ (which
  must exist) for $n/2 -1$ steps. Throughout this process the filler maintains
  a set of cups called the \defn{active set}: the set of cups that the filler
  will place fill in. The filler initializes the active set to be $A$. Note
  that that $\fil(c) \ge -2h$ for all cups $c\in A$, as $A$ consists of the
  $n/2$ fullest cups. The filler removes $1$ cup from the active set at each
  step. At each step the filler distributes water equally among the cups in its
  active set. Then, the emptier will choose some cup to empty from. If this cup
  is in the active set, the filler removes it from the active set. Otherwise,
  the filler chooses an arbitrary cup to remove from the active set.

  After $n/2-1$ steps, the active set will consist of a single cup. This cup's
  fill has increased by $1/(n/2) + 1/(n/2 - 1) + \cdots + 1/2 + 1/1 \ge \ln n/2
  = 4h$. This cup's fill started as at least $-2h$. Thus this cup has fill at
  least $2h$ now, as desired.
\end{proof}

\begin{lemma}[The Adaptive Amplification Lemma]\label{lem:adaptiveAmplification}
  Let $f$ be an adaptive filling strategy that achieves backlog $f(n)$ in the
  variable-processor cup game on $n$ cups (relative to average fill, with
  negative fill allowed).
  Let $n_0 \in \mathbb{N}$ be a constant such that a filler can achieve backlog $1$
  on $n_0$ cups ($n_0$ exists by Proposition \ref{prop:adaptiveBase}).
  Let $\delta\in(0,1)$ be a parameter, and let $L\in\mathbb{N}$ be a parameter
  such that $n_0 \le (1-\delta)\delta^L n \le n_0/\delta$.
  \footnote{Note that $n$ must be sufficiently large, and $\delta, L$ must be
  chosen such that $(1-\delta)\delta^L n \in \mathbb{N}$ because it doesn't
  make sense to talk of ``fractional cups".}

  Then, there exists an adaptive filling strategy that achieves backlog $f'(n)$ satisfying
  $$f'(n) \ge (1-\delta)\sum_{\ell= 0}^{L} f((1-\delta)\delta^\ell n)$$
  in the variable-processor cup game on $n$ cups.
\end{lemma}
\begin{proof}
  The basic idea of this analysis is as follows:
  \begin{itemize}
    \item \textbf{Step 1:} Using $f$ repeatedly, achieve average fill at least $(1-\delta)
      f(n(1-\delta))$ in a set of $n\delta$ cups. 
    \item \textbf{Step 2:} Reduce the number of processors to $n\delta$, and
      recurse on the $n\delta$ cups with high average fill.
  \end{itemize}

  Let $A$, the \defn{anchor set}, be initialized to consist of the $n\delta$
  fullest cups, and let $B$ the \defn{non-anchor set} be initialized to consist
  of the rest of the cups (so $|B| = (1-\delta)n$).
  Let $n_\ell = n\delta^{\ell-1}$, $h_\ell = (1-\delta)f(n_\ell(1-\delta))$;
  the filler will achieve a set of at least $n_\ell \delta$ cups with average
  fill at least $h_\ell$ on the $\ell$-th
  level of recursion. On the $\ell$-th level of recursion $|A| = \delta\cdot
  n_\ell, |B| = (1-\delta)\cdot n_\ell$.

  We now elaborate on how to achieve Step 1.
  The filling strategy always places $1$ unit of water in each anchor cup. This
  ensures that no cups in the anchor set ever have their fill decrease.

  On the $\ell$-th level of recursion the filler uses the following procedure,
  termed a \defn{swapping-process}, to achieve the desired average fill in $A$:
  repeatedly apply $f$ to $B$, and then take the cup generated by $f$ within
  $B$ with fill at least $f(|B|)$ and swap it with a cup in $A$; repeat until $A$ has
  the desired average fill. Note that $$\mu(A) \cdot |A| +\mu(B)\cdot |B| =
  0,$$ so $$\mu(A) = - \mu(B) \cdot (1-\delta)/ \delta.$$

  Thus, if at any point in the process $B$ has average fill lower than $-h_\ell
  \cdot \delta/(1-\delta)$, then $A$ has average fill at least $h_\ell$, so the
  process is finished. So long as $B$ has average fill at least $-h_\ell\cdot
  \delta/(1-\delta)$ we will apply $f$ to $B$.
  
  It is somewhat complicated to apply $f$ to $B$ however, because we must
  guarantee that in the steps that the algorithm takes while applying $f$ the
  amount of mass removed from $B$ by the emptier is the same as the amount of
  mass added to $B$ by the filler. This might not be the case if the emptier
  does not empty from each anchor cup at each step. We say that the emptier
  \defn{neglects} the anchor set on an application of $f$ if there is some step
  during the application of $f$ in which the emptier does not empty from some
  anchor cup.

  We will apply $f$ to $B$ at most $h_\ell n_\ell\delta + 1$ times, and at the
  end of an application of $f$ we only swap the generated cup into $A$ if the
  emptier has not neglected the anchor set during the application of $f$.

  Note that each time the emptier neglects the anchor set the mass of the
  anchor set increases by $1$. If the emptier neglects the anchor set $h_\ell
  n_\ell\delta + 1$ times, then the average fill in the anchor set increases by
  more than $h_\ell$, so the desired average fill is achieved in the anchor set.

  Otherwise, there must have been an application of $f$ for which the emptier
  did not neglect the anchor set. We only swap a cup into the anchor set if
  this is the case. In this case we achieve fill 
  $$-h_\ell \cdot \delta/(1-\delta) + f(n_\ell (1-\delta)) = (1-\delta)f(n_\ell
  (1-\delta)) = h_\ell$$
  in a non-anchor cup, and swap it with the smallest cup in the anchor set.

  We achieve average fill $h_\ell$ in the anchor set for $L$ levels of
  recursion. Summing $h_\ell$ for $0\le \ell \le L$ yields the desired result.

\end{proof}

\begin{corollary}
  \label{cor:adaptivePoly}
  There are adaptive filling strategies for the variable-processor cup game on
  $n$ cups that achieve backlog $\Omega(n)$ in time $2^{O(n)}$ and backlog
  $\Omega(n^{1-\epsilon})$ for any constant $\epsilon > 0$ in time $2^{O(\log^2 n)}$.
\end{corollary}
\begin{proof}$ $\\
  Fix $\epsilon \in (0,1/2)$, and let $c, \delta$ be parameters, with $c\in
  (0,1), 0 < \delta \ll 1/2$ -- these will depend on $\epsilon, n$.
  Say that we aim to achieve backlog at least $cn^{1-\epsilon}$.
  Observe that if we apply the Amplification Lemma to a function $f$ satisfying
  $f(k) \ge ck^{1-\epsilon}$ for $k \le g$ then for any $k_0$ with
  $k_0(1-\delta)\le g$ (which enforces $k_0 \le g/ (1-\delta)$) we have the
  following:
  \begin{align*}
  f'(k_0)\ge&\\
  &(1-\delta)\sum_{\ell=0}^L c (((1-\delta)\delta^\ell)k_0)^{1-\epsilon}\\
  &= ck_0^{1-\epsilon} (1-\delta)^{2-\epsilon} \sum_{\ell=0}^L (\delta^\ell)^{1-\epsilon},
  \end{align*}
  where $L$ is the greatest integer such that $(1-\delta)\delta^Ln \ge n_0$
  where $n_0$ is a constant such that a filler can achieve backlog $1$ on $n_0$ cups
  (this definition is identical to the definition in the statement of Lemma
  \ref{lem:adaptiveAmplification}).
  Note that as $\delta$ will be very small, $\sum_{\ell=0}^L
  (\delta^L)^{1-\epsilon}$ is very well approximated by
  $1+\delta^{1-\epsilon}$, so we will not loose much by relaxing our lower
  bound on $f'(k_0)$ to only use the first $2$ terms of the sum. We have the looser bound
  $$f'(k_0) \ge ck_0^{1-\epsilon}(1-\delta)^{2-\epsilon}(1+\delta^{1-\epsilon}).$$
  Let 
  $$h(\delta) = (1-\delta)^{2-\epsilon}(1+\delta^{1-\epsilon}).$$
  We prove the following claim:

  \begin{clm}
    \label{clm:validchoices}
    There exists an appropriate choice of $\delta$ that is small enough such
    that $h(\delta) >1$ and large enough such that $L \ge 1$, when $\epsilon$
    is chosen to be $4/\lg n$, or a positive constant. In particular, if
    $\epsilon$ is chosen to be $4/\lg n$ then we will choose $\delta \le
    O(1/n)$, and if $\epsilon$ is chosen to be a positive constant then we will
    choose $\delta \le O(1)$.
  \end{clm}

  Note that if $h(\delta)\ge 1$, then $f'(k_0) \ge c k_0^{1-\epsilon}$, meaning
  we have constructed from $f$ a new function $f'$ that satisfies the
  inequality $f'(k) \ge ck^{1-\epsilon}$ for $k\le g/(1-\delta)$, as opposed to
  only for $k \le g$ as in the case of $f$. 
  \footnote{Note that although $f'(k) \ge ck^{1-\epsilon}$ holds for at least
    as many $k$ as $f(k) \ge c k^{1-\epsilon}$, it does not necessarily hold
    for strictly more; in particular, if $\lfloor g/(1-\delta) \rfloor = g$
    then the inequality on $f'$ holds for no more $k$ than the inequality on
    $f$, as $f$ and $f'$ are functions on $\mathbb{N}$. In general we have to
    be somewhat careful about the fact that there are an integer number of cups
    throughout this proof (this issue was deferred from earlier proofs to be
  dealt with here).} 
  Then by repeatedly amplifying a function, we should be able to arbitrarily
  extend the support, which will allow us to attain the desired backlog.

  We now prove Claim \ref{clm:validchoices}.
  \begin{proof}
  Consider the Taylor series for $(1-\delta)^{2-\epsilon}$ about $\delta = 0$:
  $$(1-\delta)^{2-\epsilon} = 1 - (2-\epsilon)\delta + O(\delta^2).$$
 
  So, to find a $\delta$ where $h(\delta) \ge 1$ it suffices -- note that, again, we choose
  to neglect the $\delta^2$ term as it does not strengthen the lower bound substantially because
  it is so small -- to find a $\delta$ with 
  $$(1-(2-\epsilon)\delta)(1+\delta^{1-\epsilon}) \ge 1.$$
  Rearranging we have 
  $$\delta^{1-\epsilon} \ge (2-\epsilon)\delta + (2-\epsilon)\delta^{2-\epsilon}.$$
  This clearly is true for sufficiently small $\delta$, as
  $\delta^{1-\epsilon}$ will be much greater than $\delta$ or
  $\delta^{2-\epsilon}$.
  However it will be beneficial to have a more explicit criterion for possible
  choices of $\delta$ in terms of $\epsilon$. To get this, we enforce a much
  stronger inequality on $\delta^{1-\epsilon}$ by vastly overestimating
  $\delta^{2-\epsilon}$ as $\delta$. Surprisingly even with this overestimate
  we are still able to get the desired value of $\epsilon$ to work, as we will demonstrate later.
  We have,
  \begin{equation}
    \label{eqn:deltaUpperIneq}
    \delta \le \frac{1}{(2(2-\epsilon))^{1/\epsilon}}. 
  \end{equation}

  In addition to the constraint that $\delta$ must be small enough such that
  $h(\delta) \ge 1$, the only other constraint on $\delta$ is that $\delta$
  must be large enough that the sum from the Amplification Lemma has at least
  two terms, i.e. such that $L \ge 1$. We need $L\ge 1$ because otherwise the
  Amplification Lemma doesn't give a larger function.
  The condition $L \ge 1$ enforces 
  $$\delta(1-\delta)n \ge n_0. $$
  Recall that we choose $\delta < 1/2$, so $1-\delta > 1/2$. Thus to make
  $\delta$ sufficiently big it suffices to chose $\delta$ with 
  \begin{equation}
    \label{eqn:deltaLowerBound}
    \delta \ge 2n_0/n.
  \end{equation}
  Any choice of $\delta$ that is sufficiently large to make $L \ge 1$ and
  simultaneously small enough to make $h(\delta) \ge 1$ is a valid choice of
  $\delta$. That is, $\delta$ is valid if and only if it satisfies
  \begin{equation}
    \label{eqn:deltainequality}
    \frac{2n_0}{n} \le \delta \le  \frac{1}{(2(2-\epsilon))^{1/\epsilon}}.
  \end{equation}
  To achieve the desired backlog of $\Omega(n)$ we can use $\epsilon =
  \gamma/\lg n$ for appropriate constant $\gamma$, as $$n^{1-\gamma/\lg n} =
  n/2^\gamma = \Omega(n).$$
  We show that there is a valid choice of $\gamma$ such that the following inequality is satisfied:
  \begin{equation}
    \label{eqn:thatinequality}
   2n_0/n \le \frac{1}{(2(2-\gamma/\lg n))^{(1/\gamma)\lg n}}.
  \end{equation}
  Note that 
  $$(2(2-\gamma/\lg n))^{(1/\gamma)\lg n} \le 4^{(1/\gamma)\lg n} \le n^{2/\gamma}.$$
  Thus, clearly by choosing e.g. $\gamma = 4$ we have the desired inequality.
  Inequality \ref{eqn:thatinequality} implies that there is a valid choice of
  $\delta$ when we chose $\epsilon = \gamma / \lg n$. When proving that we can
  achieve backlog $\Omega(n)$ we use $\epsilon = 4 / \lg n$, and $\delta =
  O(1/n)$ satisfying Inequality \ref{eqn:deltainequality} for our choice
  of $\epsilon$. When proving that we can achieve backlog
  $\Omega(n^{1-\epsilon})$ for constant $\epsilon > 0$ we choose $\delta > 0$ to be
  a constant satisfying Inequality \ref{eqn:deltaUpperIneq}, and $\delta$,
  being constant, trivially satisfies Inequality \ref{eqn:deltaLowerBound}.
    
  \end{proof}

  Now we proceed to show that with the appropriate values of $\delta, \epsilon$ we
  can achieve a filling strategy that achieves backlog $cn^{1-\epsilon}$ on $n$ cups.
  First we present a simple existential argument to show that an algorithm
  achieving backlog $\Omega(n^{1-\epsilon})$ for $\epsilon$ constant exists. Next we modify the
  existential proof to achieve an algorithm achieving the same backlog, but in
  bounded running time, specifically running time $2^{O(\log^2 n)}$.
  Finally we present an algorithm where $\delta$ is set extremally; doing so,
  along with other modifications of the approach, we can achieve backlog
  $\Omega(n)$ in running time $2^{O(n)}$.
  
  \begin{proposition}
    There exists a filling algorithm that achieves backlog
    $\Omega(n^{1-\epsilon})$ for any constant $\epsilon > 0$.
  \end{proposition}
  \begin{proof}
  Let $\epsilon > 0$ be constant. By Claim \ref{clm:validchoices}, there is a
  valid constant setting of $\delta$; let $\delta \ll 1/2$ be an appropriate
  constant. Let $f^*(n)$ be the supremum over all filling strategies of the
  backlog achievable on $n$ cups. Clearly $f^*$ must be greater than or equal to
  the amplification of $f^*$. Assume for contradiction that there is some least
  $n_*$ such that 
  $$\begin{cases}
    f^*(k)< ck^{1-\epsilon}, & k > n_*\\
    f^*(k)> ck^{1-\epsilon}, & k \le n_*
  \end{cases} $$
  Note that $n_*(1-\delta)\delta \ge n_0/(1-\delta)$ by appropriate choice of constant
  $c$, and Proposition \ref{prop:adaptiveBase}, which states that we can get
  backlog $O(\log n_*)$ on $n_*$ cups\footnote{Note: this is where it is
  crucial that $\epsilon, \delta$ are constants.}.
  Because $f^*$ satisfies the Amplification Lemma we have:
\begin{align*}
  f^*(n_*) & \\
           &\ge (1-\delta)\sum_{\ell=0}^L f^*((1-\delta)\delta^\ell n_*) \\
           &\ge cn_*^{1-\epsilon} h(\delta)\\
           &\ge cn_*^{1-\epsilon}
\end{align*}
which is a contradiction. Hence $f^*$ achieves backlog $cn^{1-\epsilon}$.
    
  \end{proof}

  \begin{proposition}
    \label{prop:constructive_nepsil}
    We can construct a filling strategy that achieves backlog
    $\Omega(n^{1-\epsilon})$ for constant $\epsilon > 0$ in time $2^{O(\log^2 n)}$.
  \end{proposition}
  \begin{proof}
It is desirable to have an algorithm for achieving this backlog with bounded
running time; we now modify the existential argument to make it constructive, 
which yields an algorithm for achieving backlog $cn^{1-\epsilon}$ on $n$ cups 
in finite running time. We again use constant $\epsilon > 0$ and appropriate constant $\delta$.

  We start with the algorithm given by Proposition \ref{prop:adaptiveBase} for achieving backlog
  $$f_0(k) = 
  \begin{cases} 
    \lg k, & k\geq 1, \\
    0 & \text{else.}
  \end{cases}$$
  Then we construct an algorithm that achieves better backlog using the
  Amplification Lemma (Lemma \ref{lem:adaptiveAmplification}):
  we construct $f_{i+1}$ as the amplification of $f_{i}$. 

  Define a sequence $g_i \in \mathbb{N}^\infty$ with 
  $$ g_i = \begin{cases}
    \lceil 1/\delta \rceil \gg 1,  & i = 0,\\
    \lceil g_{i-1}/(1-\delta)\rceil -1 & i  \ge 1
  \end{cases} $$
  That is, $g_{i+1}$ is the greatest integer strictly less than $g_i/(1-\delta)$.
  Note that $ (1/\delta) / (1-\delta) > (1+\delta)/\delta = 1/\delta + 1.$
  Thus $g_1 = 1+ g_0$, and in general, $g_{i+1} > g_i$, because the difference
  $g_{i+1}-g_i$ can only grow as $i$ grows.

  We claim the following regarding this construction:
  \begin{clm}
    \label{clm:fikinduction}
  \begin{equation}
    f_i(k) \ge ck^{1-\epsilon} \text{ for all } k < g_i. 
  \end{equation}
  \end{clm}
  \begin{proof}
  We prove Claim \ref{clm:fikinduction} by induction on $i$.
  Claim \ref{clm:fikinduction} is true in the base case of $f_0$ by taking $c$
  sufficiently small, in particular small enough that $f_0(k) \ge
  ck^{1-\epsilon}$ holds for $k < g_0$.\footnote{Note: this is where it is
    crucial that $\epsilon, \delta$ are constants.}
  As our inductive hypothesis we assume Claim \ref{clm:fikinduction} for $f_i$;
  we aim to show that Claim \ref{clm:fikinduction} holds for $f_{i+1}$. Note
  the key property of $g_i$, that $g_{i+1}\cdot(1-\delta) < g_i$. Also note
  that (at least without loss of generality) the $f_i$ are monotonically increasing
  functions: given more cups we can always achieve higher fill than with fewer
  cups. Thus we have, for any $k<g_{i+1}$,
  \begin{align*}
    f_{i+1}(k) &\\
    &\ge (1-\delta)\sum_{\ell=0}^L f_i((1-\delta)\delta^\ell k)\\
    &\ge ck^{1-\epsilon}h(\delta)\\
    &\ge ck^{1-\epsilon},
  \end{align*}
  as desired. 
  \end{proof}

  Note that $g_{i+1} \ge g_i + 1$ so by continuing this process we eventually
  reach some $f_{i_*}$ such that $f_{i_*}(n) \ge cn^{1-\epsilon}$.
  Note that $i_* \le n$.
  Let the running time $f_{i_*}(n)$ be $T(n)$.
  Note that $f_{i_*}(n)$ must call $f_{i_*-1}(n(1-\delta)\delta^\ell)$ as many
  as $n(1-\delta)\delta^\ell$ times, for all $0 \le \ell\le L$. However, we
  only need the terms of the sum where $\ell=0,1$, so we can take $L=1$.
  Thus we have the following (loose) recurrence bounding $T(n)$:
  $$T(n) \le \delta n \cdot T(n(1-\delta)) + T(\delta n).$$
  We can upper bound this by
  $$n^{\frac{\log n}{\log (1/(1-\delta))}}.$$
  Continuing for $O(\log n)$ levels of recursion should be sufficient to
  achieve the desired backlog. This gives running time
  $$T(n) \le ((1+\delta) n)^{O(\log n)} \le 2^{O(\lg^2 n)}$$
  as desired.
  {\color{red} ok, technically I'm ignoring integer problems in saying lets
  only do $O(\lg n)$ levels of recursion, it'll be enough. I should prove it.
But for $\delta$ constant it seems pretty obvious.}
    
  \end{proof}

  \begin{proposition}
    We can construct a filling algorithm that achieves backlog $\Omega(n)$ in
    time $2^{O(n)}$.
  \end{proposition}
  \begin{proof}
  We describe a simple filling strategy that gives the desired backlog. Let
  $n_0 \le O(1)$ be a constant such that we can achieve backlog $1$ on $n_0$
  cups, and note that this is possible by Proposition \ref{prop:adaptiveBase}.
  We construct a function that achieves large backlog on $n$ cups.
  To achieve large backlog on $n$ cups we first recursively apply our function to
  $(1-\delta)n$ cups repeatedly (for each of the $\delta n$ cups that we are
  attempting to get high fill in), as described in the proof of the
  Amplification Lemma, and transfer over the cups that we get. Then we achieve backlog $1$ on
  the $\delta n$ cups whose average fill has been increased. The backlog we
  achieve satisfies the following recurrence:
  $$f(n) \ge \begin{cases}
    (1-\delta)f((1-\delta)n) + 1, & \text{if } n\delta(1-\delta) > n_0\\
    0, \text{ else.}
  \end{cases}$$
  Let $(1-\delta)^c = \delta$, let $\delta^2 n < n_0 < (1-\delta)^{2c-1} n$ by
  our choice of $\delta = O(1/n)$.
    We can get backlog 
    $$\sum_{i=1}^c (1-\delta)^i. $$
    To see this, consider a binary tree representing our algorithm. At every
    branch we both proceed to recurse on a $1-\delta$ fraction of the cups, and
    achieve backlog $1$ on a $\delta$ fraction of the cups.

    The sum evaluates to 
    $$\frac{(1-\delta)^2}{\delta}$$
    which, if we chose $\delta = 1/n$, becomes $\Omega(n)$.

    The running time satisfies the recurrence 
    $$T(n) = \delta n T((1-\delta)n) + O(1)$$
    because to achieve backlog $f(n)$ we must achieve backlog
    $f((1-\delta)n)$ $\delta n$ times, and then achieve backlog $1$ on the
    remaining cups. Solving this recurrence yields that the running time is
    $$\frac{(\delta n)^c - 1}{\delta n - 1}.$$
    Recalling that $\delta = O(1/n)$ this becomes 
    $$2^{O(n)}.$$


    % Solving this inequality yields
    % $$\epsilon \ge \frac{2 \ln(n) - W(\frac{1}{2} n^2 \ln n)}{\ln n}$$
    % where $W$ is the Lambert-W function, i.e. the inverse of the function $z\mapsto ze^z$.
    % Note that as $n\to \infty$ smaller and smaller values of $\epsilon$ are permissible.

    % Note that the Lambert-W function satisfies $W(x) = \ln x -\ln\ln x + o(1)$.
    % Using this, we can get a very loose lower bound of $\Omega(n^{1-2/\ln n})$,
    % although of course the expression with the $W$ in it is a better lower bound.
    
  \end{proof}


\end{proof}

\section{Adaptive Filler Upper Bound}\label{sec:adaptiveUpperBound}
Let $\mu_S(X)$ and $m_S(X)$ denote the average fill and mass of a set of cups $X$
at state $S$ (e.g. $S=S_t$ or $S=I_t$).\footnote{Note that in the lower bound
  proofs (e.g. Section \ref{sec:adaptive}) when we used the notation $m$ (for
  mass) and $\mu$ (for average fill), we omitted the subscript indicating the
  state at which the properties were measured. In those proofs it was
sufficiently clear to leave the state implicit. However, in this section the
state is crucial, and needs to be explicit in the notation.}
Let $S_t(\{r_1, \ldots, r_m\})$ and $I_t(\{r_1,\ldots, r_m\})$ denote the cups
of ranks $r_1, r_2, \ldots, r_m$ at states $S_t$ and $I_t$ respectively.
Let $[n] = \{1,2,\ldots, n\}$, let $i+[n] = \{i+1, i+2, \ldots, i+n\}$. We will
use concatenation of sets to denote unions, i.e. $AB = A\cup B$.\\
We establish the following Lemma:

\begin{lemma}
  The greedy emptier maintains the invariant $$\mu_{S_t}(S_t([k])) \le 2n-k
  \text{ for all } t\ge 1, k \in [n].$$ In particular, for $k=1$, this
  implies that the greedy emptier never lets backlog exceed $O(n)$.
\end{lemma}
\begin{proof}

We prove the invariant by induction on $t$.
The invariant holds trivially for $t=1$ (the base case for the inductive proof): 
the cups start empty so $\mu_{S_1}(S_1([k])) = 0 \le 2n-k$ for all $k \in [n]$.

Fix a round $t \ge 1$, and any $k \in [n]$. We assume invariant for all
values of $k' \in[n]$ for state $S_t$ (we will only explicitly use two of the
invariants for each $k$, but the invariants that we need depend on the
choice of $p_t$ by the filler, so we actually need all of them) and show that
the invariant on the $k$ fullest cups holds on round $t+1$, i.e. that
$$\mu_{S_{t+1}}(S_{t+1}([k])) \le 2n-k.$$

Note that because the emptier is greedy it always empties from the cups $I_t([p_t])$.
Let $A$, with $a=|A|$, be $A = I_t([\min(k, p_t)]) \cap S_{t+1}([k])$; $A$
consists of cups that are among the $k$ fullest cups in $I_t$, are emptied from, and
are among the $k$ fullest cups in $S_{t+1}$.
Let $B$, with $b=|B|$, be $I_t([\min(k, p_t)]) \setminus A$; $B$ consists of
the cups that are among the $k$ fullest cups in state $I_t$, are emptied from,
and aren't among the $k$ fullest cups in $S_{t+1}$. 
Let $C = I_t(p_t+[k-a])$, with $c=k-a = |C|$.

Note that $k-a\ge 0$ as $a+b \le k$, and also $|ABC| = k+b \le n$, because by
definition the $b$ cups in $B$ must not be among the $k$ fullest cups in state
$S_{t+1}$ so there are at least $k+b$ cups. 
Note that $a+ b = \min(k, p_t)$. We also have that $A = I_t([a])$ and $B =
I_t(a+[b])$, as every cup in $A$ must have higher fill than all cups in $B$ in
order to remain above the cups in $B$ after $1$ unit of water is removed from
all cups in $AB$.
Further, note that $S_{t+1}([k]) = AC$ because once the cups in $B$
are emptied from the cups in $B$ are not among the $k$ fullest cups, so the
cups in $C$ take their places among the $k$ fullest cups.

We now establish the following claim, which we call the \defn{interchangeability of cups}:
\begin{clm}
  \label{clm:interchangable}
  Without loss of generality $$S_t([r]) = I_t([r])$$ for any rank $r \in [n]$.
\end{clm}
\begin{proof}
  Say there are cups $x, y$ with $x\in S_t([r]) \setminus I_t([r]), y \in
  I_t([r])\setminus S_t([r])$. Let the fills of cups $x,y$ at state $S_t$
  be $f_x, f_y$; note that $f_x > f_y$. Let the amount of fill that the emptier
  adds to these cups be $\Delta_x, \Delta_y \le 1$; note that $f_x +\Delta_x <
  f_y + \Delta_y$.

Define a new state $S_t'$ where cup $x$ has fill $f_y$ and cup $y$ has fill $f_x$. 
Let the amount of water that the filler places in these cups from the new state be
$f_x-f_y+\Delta_x$ and $f_y-f_x + \Delta_y$ for cups $x,y$ respectively.
This is valid as both fill amounts are at most $1$: $f_x-f_y+\Delta_x<\Delta_y
\le 1$ and $f_y-f_x + \Delta_x < \Delta_x \le 1$.

We can repeatedly apply this process to swap each cup in $I_t([r])\setminus
S_t([r])$ into being one of the $a+b$ fullest cups in the new state $S_t'$.
At the end of this process we will have some ``fake" state $S_t^f$. Note that
$S_t^f$ must satisfy the invariants if $S_t$ satisfied the invariants, because
our process can be thought of as just relabelling the cups; in particular
$\fil(S_t^f(r)) = \fil(S_t(r))$ for all ranks $r \in [n]$.

It is without loss of generality that we start in state $S_t^f$ because from
state $I_t$ we could equally well have come from state $S_t$ or state $S_t^f$.
Thus we consider state $I_t$ to have come from state $S_t^f$.
\end{proof}

Now we proceed with the proof of the Lemma.
\begin{clm}
  If some cup in $A$ zeros out then invariant holds.
\end{clm}
\begin{proof}
  Say a cup in $A$ zeroes out. Then 
  $$m_{S_{t+1}}(A) \le (a-1)(2n-(a-1))$$
  because the $a-1$ fullest cups must have satisfied the invariant on round
  $S_t$, and $\fil_{S_{t+1}}(I_{t+1}(a)) = 0$.
  Furthermore, the fill of all cups in $C$ must be at most $1$ in $I_t$ to be
  less than the fill of the cup in $A$ that zeroed out.

  Thus, 
  $$m_{S_{t+1}}(S_{t+1}([k])) \le (a-1)(2n-(a-1))+k-a.$$
  We claim that this is less than $a(2n-a)$. 
  This follows from simple manipulation of the above expression:
  \begin{align*}
    &(a-1)(2n-(a-1))+k-a\\
    &= a(2n-a) +a -2n+a-1 + k -a\\
    &= a(2n-a) + (k-n) + (a-n) -1\\
    &< a(2n-a)
  \end{align*}
  as desired.

  As $k$ increases from $1$ to $n$, $k(2n-k)$ strictly increases (it is a
  quadratic in $k$ that achieves its maximal value at $k=n$).
  Thus $a(2n-a) \le k(2n-k)$ because $a\le k$.

  And we have
  $$m_{S_{t+1}}(S_{t+1}([k])) \le k(2n-k).$$
\end{proof}

\begin{clm}
  If no cups in $A$ zero out and $b=0$ the invariant holds.
\end{clm}
\begin{proof}
First we consider the case $b=0$. If $b=0$, then $S_{t+1}([k]) = S_t([k])$. 

The emptier has removed $a$ units of fill from the cups in $S_t([k])$,
specifically the cups in $A$. The filler cannot have added more than $k$ fill
to these cups, because it can add at most $1$ fill to any given cup. Also, the
filler cannot have added more than $p_t$ fill to the cups because this is the
total amount of fill that the filler is allowed to add. Hence the filler adds
at most $\min(p_t, k) = a+b=a+0=a$ fill to these cups.
Thus the invariant holds:
$$m_{S_{t+1}}(S_{t+1}([k])) \le m_{S_t}(S_t([k]))+a-a \le k(2n-k).$$

\end{proof}

\begin{clm}
  If no cups in $A$ zero out and $b > 0$ the invariant holds.
\end{clm}
\begin{proof}
Because $b>0$ and $a+b \le k$ we have that $a
< k$, and $c = k-a > 0$. Recall that $S_{t+1}([k]) = AC$, so the mass of the
$k$ fullest cups at $S_{t+1}$ is the mass of $AC$ at $S_t$ plus any water added
to cups in $AC$ by the filler, minus any water removed from cups in $AC$ by the
emptier. The emptier removes exactly $a$ units of water from $AC$.
The filler adds no more than $p_t$ units of water from $AC$ (because the filler
adds at most $p_t$ total units of water per round) and the filler also
adds no more than $k = |AC|$ units of water from $AC$ (because the filler adds
at most $1$ unit of water to each of the $k$ cups in $AC$).
Thus, the filler adds no more than $a+b = \min(p_t, k)$ units of water to $AC$.
Combining these observations we have:
$$m_{S_{t+1}}(S_{t+1}([k])) \le m_{S_t}(A) + m_{S_t}(C) + b.$$

% This is easy to bound if $m_{S_t}(C) \le m_{S_t}(BC) - b$, because 
% $$m_{S_t}(A) + m_{S_t}(BC)  = m_{S_t}(ABC) \le m_{S_t}([k])$$
% which would imply the invariant for $S_{t+1}$, $k$.
% If $\mu_{S_t}(C)$ is not significantly less than $\mu_{S_t}(BC)$ we have more difficulty.
The key insight necessary to bound this is to notice that larger values for
$m_{S_t}(A)$ correspond to smaller values for $m_{S_t}(C)$ because of the
invariants; the higher fill in $A$ \defn{pushes down} the fill that $C$ can
have. By quantifying exactly how much higher fill in $A$ pushes down fill in
$C$ we can achieve the desired inequality.
We can upper bound $m_{S_t}(C)$ by 
$$m_{S_t}(C) \le \frac{c}{b+c}m_{S_t}(BC) = (m_{S_t}(ABC) - m_{S_t}(A))\frac{c}{b+c}$$ because
$\mu_{S_t}(C) \le \mu_{S_t}(B)$ without loss of generality by the
interchangeability of cups.
Thus we have 
\begin{equation}
  \label{eqn:BCdiscounted}
m_{S_t}(AC) \le m_{S_t}(A) + \frac{c}{b+c}m_{S_t}(BC)
\end{equation}
{\color{red}
where 
\begin{equation}
  \label{eqn:redistributeA}
\begin{split}
  &m_{S_t}(A) + \frac{c}{b+c}m_{S_t}(BC) \\
  &= \frac{c}{b+c}m_{S_t}(ABC) + \frac{b}{b+c}m_{S_t}(A).
\end{split}
\end{equation}
Note that the expression in Equation \ref{eqn:redistributeA} is monotonically
increasing in both $\mu_{S_t}(ABC)$ and $\mu_{S_t}(A)$. 
Thus, by numerically replacing both average fills with
their extremal values ($2n-|ABC|, 2n-|A|$) we upper bound $m_{S_t}(A) + m_{S_t}(C)$.
At this point the inequality can be verified by straightforward algebra,
however this is not elegant; instead, we combinatorially interpret the sum.

We define a new ``fake" state $F$, which may not represent
a valid configuration of cups (i.e. might not satisfy the invariants), where
$\mu_F(A)=2n-|A|$ and $\mu_F(ABC)=2n-|ABC|$, in particular with all the cups in $A$
having identical fill, and all the cups in $BC$ having identical fill.
We can think of $F$ as having come from a state where every cup has fill
$\mu_F(ABC) = 2n-|ABC|$. To reach $F$ from this state where every cup has
identical fill we must increase the fill of each cup in $A$ by some amount, and
decrease the fill of each cup in $BC$ by an amount such that the mass added to
$A$ is taken away from $BC$. To reach fill $\mu_F(A) = 2n-|A|$, the cups in $A$
must have been increased by $|BC|$ from their previous fill of $2n-|ABC|$.
To equalize an increase in $\mu_{F}(A)$ of $|BC|$, we need a corresponding
decrease in $\mu_{F}(BC)$ by $|A|$.
That is, $$\mu_{F}(BC) = 2n-|ABC|-|A|.$$
Thus we have the following bound:
\begin{align*}
  m_{S_t}(A) + m_{S_t}(C)& \\
&\le m_{F}(A) + c\mu_{F}(BC) \tag{*}\\
&\le a(2n-a) + c(2n-|ABC|-a) \\
&\le (a+c)(2n-a) - c(a+c+b) \\
&\le (a+c)(2n-a-c) - cb,
\end{align*}
where (*) follows from Equation \ref{eqn:redistributeA}.
}

{\color{blue}
  Consider a new configuration of fills $F$ achieved by starting with state
  $S_t$, and moving water from $BC$ into $A$ until $\mu_{F}(A) = 2n-|A|$.
  \footnote{Note that whether or not $F$ satisfies the invariants is irrelevant.}
  This transformation increases (strictly increases if and only if we move a
  non-zero amount of water) the mass in $AC$ because water in $BC$
  counts less towards mass in $AC$ than water in $A$ by Inequality
  \ref{eqn:BCdiscounted}. In particular, if mass $\Delta \ge 0$ fill is moved from
  $BC$ to $A$, then the mass of $AC$ increases by $\frac{b}{b+c} \Delta \ge 0$.

  Since $\mu_F(A)$ is above $\mu_{F}(ABC)$, the greater than average fill of
  $A$ must be counter-balanced by the lower than average fill of $BC$. In
  particular we must have
  $$(\mu_F(A) - \mu_F(ABC))|A| = (\mu_F(ABC) -\mu_F(BC))|BC|.$$
  Note that $$\mu_F(A) -\mu_F(ABC) \ge (n-|A|) - (n-|ABC|) = |BC|.$$
  Hence we must have 
  $$\mu_F(ABC) - \mu_F(BC) \ge |A|.$$
  Thus 
  $$\mu_F(BC) \le \mu_F(ABC) - |A| \le 2n-|ABC| -|A|.$$

  Thus we have the following bound:
  \begin{align*}
    m_{S_t}(A) + m_{S_t}(C)& \\
  &\le m_{F}(A) + c\mu_{F}(BC)\\
  &\le a(2n-a) + c(2n-|ABC|-a) \\
  &\le (a+c)(2n-a) - c(a+c+b) \\
  &\le (a+c)(2n-a-c) - cb.
  \end{align*}
}

Recall that we were considering $b> 0$, and since $b>0$ we have that $c = k-a
\ge b > 0$, i.e. $c \ge 1$. 
Hence we have 
$$m_{S_t}(A) + m_{S_t}(C) \le k(2n-k) -b$$
So 
$$m_{S_t}(A) + m_{S_t}(C)+b \le k(2n-k).$$
As shown previously the left hand side of the above expression is an upper
bound for $m_{S_{t+1}}([k])$.
Hence the invariant holds.
  
\end{proof}

We have shown the inductive hypothesis for arbitrary $k$, so given that the
invariants all hold at state $S_t$ they also must all hold at state $S_{t+1}$.
Thus, by induction we have the invariant for all rounds $t\in\mathbb{N}$.
\end{proof}


% \section{Oblivious Filler Lower Bound}\label{sec:oblivious}
% An important theorem that we use throughout our analysis is Hoeffding's Inequality:
% \begin{theorem}[Hoeffding's Inequality]
%   Let $X_i$ for $i=1,2,\ldots, k$ be independent bounded random variables with
%   $X_i \in [a,b]$ for all $i$. Then,
%   $$P\left(\Big|\frac{1}{k} \sum_{i=1}^k (X_i - \E[X_i])\Big|\ge t\right) \le
%   2\exp\left(-\frac{2kt^2}{(b-a)^2}\right) $$
% \end{theorem}
% Let $S$ be a finite population, let $X_i$ for $i=1,2\ldots, k$ be chosen
% uniformly at random from $S \setminus \{X_1,\ldots, X_{i-1}\}$, and let $Y_i$
% for $i=1,2,\ldots, k$ be chosen uniformly at random from $S$.
% Note that $\{X_1,\ldots, X_k\}$ represents a sample of $S$ chosen without
% replacement, whereas $\{Y_1,\ldots, Y_k\}$ represents a sample with
% replacement. Note that as the $Y_i$ are independent random variables
% Hoeffding's Inequality provides a bound on the probability of $\sum_{i=1}^k
% Y_i$ deviating from its mean by more than $t$.

% The same bound can be given on the probability of $\sum_{i=1}^k X_i$ deviating
% significantly from its mean, because the probability of $\sum_{i=1}^k X_i$
% deviating from it's expectation by more than $t$ is at most the probability of
% $\sum_{i=1}^k Y_i$ deviating from it's mean by $t$.
% Formally we can write this as 
% \begin{corollary}
%   \label{cor:hoeffdingwreplacement}
%   Let $S$ be a finite set with $\min(S) \ge a, \max(S) \le b$, and let $X_i$
%   for $i=1,2\ldots, k$ be chosen uniformly at random from $S \setminus
%   \{X_1,\ldots, X_{i-1}\}$.
% Then 
%   $$P\left(\Big|\frac{1}{k} \sum_{i=1}^k (X_i - \E[X_i])\Big|\ge t\right) \le
%   2\exp\left(-\frac{2kt^2}{(b-a)^2}\right) $$
% \end{corollary}

% Hoeffding proved Corollary \ref{cor:hoeffdingwreplacement} in his seminal work
% \cite{who62} (the result follows from his Theorem 4, combined with Hoeffding's
% Inequality for independent random variables).
% The intuition behind Corollary \ref{cor:hoeffdingwreplacement} is that samples
% drawn without replacement should be more tightly concentrated around the mean
% than samples drawn with replacement.

% Another important, yet very trivial, corollary of Hoeffding's Inequality is the
% Chernoff Bound (i.e. Hoeffding's Inequality applied to binary random
% variables):
% \begin{corollary}
%   \label{cor:chernoffbound}
%   Let $X_i$ for $i=1,2,\ldots, k$ be independent identically distributed binary
%   random variables (i.e. $X_i\in \{0,1\}$). Then 

%   $$P\left(\Big|\frac{1}{k} \sum_{i=1}^k (X_i - \E[X_i])\Big|\ge t\right) \le
%   2\exp\left(-2kt^2 \right) $$
% \end{corollary}

% Call an emptying strategy $\Delta$\defn{-greedy-like} if it satisfies the
% following property: for any cup $c$, if there are
% at least $p$ cups containing fill greater than $\fil(c) + \Delta$, the emptier
% does not empty from cup $c$. Combinatorially the quantity $T$ is the threshold
% above which the filler ``notices" cups, and $\pm\Delta$ is the tolerance in cup
% fills within which the emptier is allowed to not be greedy.

% Of particular interest is the greedy emptier, which is $(0,0)$-greedy-like, and
% the smoothed greedy emptier, which is $(1, 0)$-greedy-like.

% \begin{proposition}
%   \label{prop:obliviousBase}
%   There exists an oblivious filling strategy in the variable-processor cup game
%   on $n$ cups that achieves backlog $\Omega(\log n)$ against a $(T,
%   \Delta)$-greedy-like emptier (where $T, \Delta \le O(1)$ are constants
%   known to the filler), with constant probability.
% \end{proposition}
% \begin{proof}
%   Let $A$, the \defn{anchor} set, be a subset of the cups chosen uniformly at
%   random from all subsets of size $n/2$ of the cups, and let $B$, the
%   \defn{non-anchor} set, consist of the rest of the cups ($|B| = n/2$). Let $h
%   = 2 T + 4$. After attaining average positive tilt at least $h$ in a constant
%   fraction of $A$, exploiting the fact that the emptier is greedy-like, the
%   filler can use this positive tilt to create a known set of cups each with
%   fill at least $h' = 1$. More specifically, the filling algorithm proceeds as
%   follows: 
%   \begin{itemize}
%     \item \textbf{Step 1:} 
%       Obtain large positive tilt in $A$. If at least half of the cups $c\in B$
%       have $\fil(c) \ge -384h$, then we can, with constant probability, achieve
%       a cup with fill $h$ in $B$ -- which we will then swap to $A$ -- by
%       playing a single-processor cup game on a constant-size ($\lceil e^{385h}
%       \rceil$ suffices) subset of $B$. 
%       On the other hand, if at least half of the cups in $B$ have fill less than
%       $-384h$, then the expectation of the positive tilt of a cup chosen
%       randomly is high; this property can be exploited to get high positive
%       tilt in the anchor set.

%       Because the filler is oblivious it cannot know which of these states it is in; 
%       thus the filler employs a hybrid of these strategies, switching between
%       them with certain probabilities, which works in both cases.
%   \item \textbf{Step 2:} Reduce the number of processors to a constant fraction
%     $c$ of $n$, where $c$ is chosen such that there must be a set of at most $nc$ unknown cups $S$ with 
%     $$\sum_{x\in S} \lfloor \tilt(x) / h \rfloor \ge nc.$$
%     Using this positive tilt, the filler can raise the fill of $nc$ known cups
%     to $h'$, because the emptier is greedy.
%   \item \textbf{Step 3:} Recurse on the $nc$ cups that are known to have fill
%     at least $h'$.
% \end{itemize}
% By performing $\Omega(\log n)$ levels of recursion, achieving constant backlog
% $h'\ge 1/2$ at each step (relative to the average fills), the filler achieves backlog
% $\Omega(\log n)$.

% The strategy as stated fails if fill is extremely concentrated in a very small
% number of cups; however, in this case the proposition is trivially satisfied.
% In particular, we call a cup \defn{overpowered} if it contains fill at least
% $h\sqrt{n}/(\log\log n)^{2/3}$. If there is ever an overpowered cup, then the
% proposition is trivially satisfied, as backlog is $\Omega(\poly(n))$. Note that
% the filler doesn't need to know which cup is overpowered because it will take
% $\Omega(\poly(n))$ rounds for the emptier to reduce the fill below $\poly(n)$.
% Hence, we can assume without loss of generality that no cup is ever
% overpowered. Furthermore, if there is ever a cup with fill less than
% $-h\sqrt{n}/(\log\log n)^{2/3}$ then, in order to make the absolute fill of this cup
% non-negative, the absolute average fill of all the cups must be at least
% $h\sqrt{n}/(\log\log n)^{2/3}$. Hence there would exist an overpowered cup. Thus we
% have that without loss of generality all cups have fill bounded in magnitude by
% $h\sqrt{n}/(\log\log n)^{2/3}$.

% Now we detail how to achieve Step 1.
% We set apart a constant fraction $\alpha n= n/1000$ of the cups in $A$, which
% we call the \defn{storage-block}, or simply $C$. Let $\gamma = (\lg\lg
% n)^{1/3}$; we will store between
% $\gamma -\gamma/2$ and $\gamma + \gamma/2$ sets of $2\beta = \alpha n / (\gamma +
% \gamma/2)$ randomly chosen cups at certain randomly chosen rounds.
% For each anchor cup $c$ we will perform a procedure called a \defn{swapping-process}. 
% With probability $\frac{\gamma}{n/2}$ the swapping-processes consists of what
% we term a \defn{storing-operation}; in a storing-operation the filler takes a 
% random subset of $\beta$ cups from $B$, and a random subset of $\beta$ cups
% from $A \setminus C$, and swap these cups into the storage-block.
% Note that, by a Chernoff bound, the probability that the number of
% swapping-processes where we perform a storing-operation lies within $\pm
% \gamma/2$ of its expectation $\gamma$ is at least $1-2e^{-n(\gamma/2)^2}$,
% which is better than exponentially small in $n$, and in particular much
% better than the $1-1/\polylog n$ probability of success that we need.
% Thus we assume that the number of swapping-processes that consist of a
% storing-operation is between $\gamma- \gamma/2$ and $\gamma+\gamma/2$.

% On the other hand, with probability $1-\frac{\gamma}{n/2}$ the swapping-process
% does not entail performing a storing-operation; in this case the
% swapping-process is composed of a substructure, repeated many times, which we
% call a \defn{round-block}, which is a set of consecutive rounds. At the beginning of
% such a swapping-process we choose a round-block $j \in [n^2]$ uniformly at
% random from all the round-blocks. The swapping-process proceeds for $n^2$
% round-blocks; on the $j$-th round-block we swap a cup into the anchor set.

% For each round-block $i \in [n^2]$, the filler selects a random subset $D_i\subset
% B$ of the non-anchor cups and plays a single processor cup game on $D_i$. In this
% single-processor cup game the filler employs the classic adaptive strategy for
% achieving backlog $\Omega(\log |B|)$ on a set of $|B|$ cups, however modified
% because it is an oblivious filler. In particular, the filler's strategy in the
% single-processor cup games is to distribute water equally among an \defn{active
% set} of cups, and then after the emptier removes water from some cup the filler
% removes a random cup from the active set. There is at least constant
% probability that this results in the active set having a single cup at the end,
% with fill that has increased by at least $1/|B| + 1/(|B|-1) + \ldots + 1/1 \ge
% \ln |B|$ since the start of the round-block.

% On most round-blocks -- all but the $j$-th -- the filler does nothing with the
% cup that it achieves in the active set at the end of the single processor cup
% game. However, on the $j$-th round-block the filler swaps the winner of the
% single processor cup game into the anchor set.

% We consider two cases:
% \begin{itemize}
%   \item \textbf{Case 1:} For at least $1/2$ of the swapping-processes, at
%     least $1/2$ of the cups $c \in B$ have $\fil(c) \ge -384h$.
%   \item \textbf{Case 2:} For at least $1/2$ of the swapping-processes, less
%     than $1/2$ of the cups $c \in B$ have $\fil(c) \ge -384h$.
% \end{itemize}
% We now prove that in either case we can achieve high positive tilt in $A$ with
% good probability.

% \begin{clm} \label{clm:reg} 
%   Let $q\ge \Omega(1)$ be an appropriately small constant ($q$ is a function of
%   $h\le O(1)$). In Case 1, with probability at least $1-e^{-nq^2/1024}$, we
%   achieve fill at least $h$ in at least $nq/16$ of the cups in $A$ (i.e. a
%   constant fraction of the cups in $A$). 
% \end{clm}
% \begin{proof}
%   Consider a swapping-process where the filler does not perform a
%   storing-operation where at least $1/2$ of the cups $c \in B$ have $\fil(c)
%   \ge -96h$. Note that by assumption there are at least $n/4 - \gamma\cdot 3/2$ such rounds.
 
%   Say the emptier \defn{neglects} the anchor set in a round-block if on at
%   least one round of the round-block the emptier does not empty from every
%   anchor cup. By playing the single-processor cup game for $n^2$ round-blocks,
%   with only one round-block when we actually swap a cup into the anchor set, we
%   strongly disincentive the emptier from neglecting the anchor set on more
%   than a constant fraction of the round-blocks. 

%   The emptier must have some function $I(i): [n^2] \to \{0,1\}$ that indicates whether or
%   not they will neglect the anchor set on round-block $i$ if the filler has not
%   already swapped. Note that the emptier may know when the filler performs a
%   swap, so whether or not the emptier neglects a round-block $i$ depends on
%   this information. However, $j$ is the only parameter of the swapping-process,
%   so there is no other information that the emptier can use to decide whether
%   or not to neglect a round-block. Note that $I$ could be generated randomly,
%   but it still must exist. 

%   If the emptier is willing to neglect the anchor set for at least $1/2$ of the
%   round-blocks, i.e. $\sum_{i=1}^{n^2} I(i) \ge n^2 / 2$, then with probability
%   at least $1/4$, $j \in ((3/4) n^2, n^2)$, in which case the emptier neglects
%   the anchor set on at least $n^2/4$ round-blocks ($I(k)$ must be $1$ for at
%   least $n^2/4$ of the first $(3/4)n^2$ round-blocks). Each time the emptier
%   neglects the anchor set the mass of the anchor set increases by at least $1$.
%   Thus the average fill of the anchor set will have increased by at least
%   $(n^2/2)/(n/2) \ge \Omega(n)$ over the entire swapping-process in this
%   case, implying that we achieve an overpowered cup and satisfy the proposition. 

%   Otherwise, there is at least a $1/2$ chance that the round-block $j$, which
%   is chosen uniformly at random from the round-blocks, when the filler performs
%   a swap into the anchor set occurs on a round-block with $I(j)=0$, indicating
%   that the emptier won't neglect the anchor set on round-block $j$. In this
%   case, the round-block was a legitimate single processor cup game on $D_j$,
%   the randomly chosen set of $\lceil e^{385h} \rceil$ cups on the $j$-th round.
%   Then we achieve fill increase of at least $\ln \lceil e^{385h} \rceil \ge 385h$
%   by the end of the round-block with probability at least $1/\lceil
%   e^{385h}\rceil!$ -- the probability that we correctly guess the sequence of
%   cups within the single processor cup game that the emptier empties from. 

%   The probability that the random set $D_j \subset B$ contains only cups that
%   are among the $n/4$ fullest cups in $B$ is $${n/2 \choose {\lceil e^{97h}
%   \rceil}} / {n \choose {\lceil e^{385h}\rceil}} = O(1).$$ Note that because, by
%   assumption, at least half of the cups $c \in B$ have $\fil(c) \ge -384h$, then
%   the $n/4$ fullest cups in $B$ must have fill at least $-384h$. If all cups $
%   c\in D_j$ have $\fil(c) \ge -384h$, then the fill of the cup in the active set
%   at the end of the round-block is at least $-384h + 385h = h$, if the filler
%   guesses the emptier's emptying sequence correctly.

%   Say that a swapping-process where at least half of the cups $c\in B$ have
%   $\fil(c) \ge -384h$ \defn{succeeds} if $D_j$ is a subset of the $n/4$ fullest
%   cups in $B$, and if the filler correctly guesses the emptier's emptying
%   sequence. Note that if a swapping-process succeeds, then the filler is able
%   to swap a cup with fill at least $h$ into $A$. We have shown that there is a
%   constant probability of a given swapping-process succeeding. Let $X_i$ be the
%   binary random variable indicating whether or not the $i$-th swapping process
%   where the filler does not perform a storing-operation where at least half of
%   the cups $c\in B$ have $\fil(c) \ge -384h$ succeeds. Let $q \ge \Omega(1)$ be
%   the probability of a swapping-process succeeding, i.e. $P(X_i=1)$. Note that
%   the random variables $X_i$ are clearly independent, and identically
%   distributed.

%   Clearly $$\E\left[\sum_{i=1}^{n/8} X_i\right] = qn/8.$$ Note that we do not
%   use all the $X_i$; we know there must be at least $n/4 - 3/2 \gamma$
%   swapping-processes that do not consist of a storing-operation, but only use
%   $n/8$ of the $X_i$. We make this choice because the particular constants that
%   we get do not matter, and because it simplifies the analysis.
%   By a Chernoff Bound (i.e. Hoeffding's Inequality applied to binary random variables),
%   $$P\left(\sum_{i=1}^{n/8} X_i\le nq/16\right) \le e^{-nq^2/1024}.$$ That is, the
%   probability that less than $nq/16$ of the anchor cups have fill at least $h$ is
%   exponentially small in $n$, as desired.

% \end{proof}

% \begin{clm}
%   \label{clm:xtreme}
%   In Case 2, with probability at least $1- 1/\polylog(n)$, we achieve positive
%   tilt $n \alpha \cdot h$ in the anchor set.
% \end{clm}

% \begin{proof}
%   Consider a swapping-process on which the filler does a storing-operation and
%   at least half of the cups $c \in B$ have $\fil(c) < -384h$. Then there is a
%   set of cups with no more than $-384h \cdot n/4 = -nh\cdot 96$.

%   If the storage-block $C$ already has positive tilt at least $nh\cdot 48 \ge
%   n\alpha \cdot h$ then the filler has already succeeded, as no water ever
%   exits the storage-block.

%   Otherwise, at least one of $A$ or $B$ must have large positive tilt in order
%   to offset the many cups in $B$ with fill less than $-96h$. In particular, the
%   positive tilt of $A \cup B \setminus C$ must be at least $nh\cdot 96 - nh\cdot 48 =
%   nh\cdot 48$. Let $D=B$ if $\tilt(B) > \tilt(A)$ and $D=A$ otherwise. Note that
%   $\tilt(D) \ge nh\cdot 24$. Because there are no overpowered cups, this positive
%   tilt is distributed among many cups. Note that if $X$ is a cup chosen
%   uniformly randomly from $D$ then $$\E[\tilt(X)] \ge h\cdot 48.$$ Let
%   $Y_1,Y_2,\ldots, Y_\beta$ be the positive tilts of a set of $\beta$ cups
%   drawn from $D$, with all subsets equally likely; equivalently, consider
%   $Y_1,\ldots, Y_\beta$ to be the positive tilts of $\beta$ cups sampled from
%   $D$, sampling without replacement. Recall that $\beta =
%   \frac{1}{2}\frac{\alpha n}{\gamma\cdot 3/2}$, $\gamma = (\lg \lg n)^{1/3}$.
%   We apply Hoeffding's Inequality for samples drawn with replacement (stated in
%   Corollary \ref{cor:hoeffdingwreplacement}) to $\sum_{i=1}^\beta Y_i$. Note
%   that $0\le Y_i \le h\sqrt{n}/(\log\log n)^{2/3}$, as positive tilt is
%   non-negative, and as there are no overpowered cups. 
%   Thus we have, 
%   \begin{align*}
%   P\left(\frac{1}{\beta} \sum_{i=1}^{\beta} (Y_i - \E[Y_i]) \le -h\cdot 24 \right) \le\\
%   \exp\left(-\frac{2\beta(h\cdot 24)^2}{(h\sqrt{n}/(\log\log n)^{2/3})^2}\right).
%   \end{align*}
%   Simplifying this gives,
%   $$P\left(\frac{1}{\beta}\sum_{i=1}^{\beta} Y_i \le h\cdot 24\right) \le \frac{1}{\polylog(n)}.$$

%   Now we will show that with probability at least $1-1/\polylog(n)$ there are
%   at least $\gamma/4$ swapping-processes on which the filler does a
%   storing-operation.
%   Recall that at least $\gamma/2$ storing-operations happen. Choose a random
%   set of $\gamma/2$ of the storing-operations that happen. Note that the
%   distribution of these sets will clearly be identical to the distribution we
%   would get if we simply selected a random subset of $\gamma/2$ of the
%   swapping-process, or equivalently, if we had sampled $\gamma/2$ of the
%   swapping-processes sampling without replacement. Let $Z_i$ be the indicator
%   random variable for whether or not the $i$-th of these swapping-processes occurs on a round
%   where at least half of the cups $c \in B$ have $\fil(c) < -384h$.
%   Clearly $\E\left[\sum_{i=1}^{\gamma/2} Z_i\right] \ge \gamma/4.$ 
%   Then a Chernoff bound gives that
%   $$P\left(\sum_{i=1}^{\gamma/2} Z_i \ge \gamma/8 \right) \ge 1-e^{-2(\gamma/2) (\gamma/8)^2},$$
%   and recalling that $\gamma=(\lg\lg n)^{1/3}$ this simplifies to 
%   $$P\left(\sum_{i=1}^{\gamma/2} Z_i \ge \gamma/8 \right) \ge 1-\frac{1}{\polylog(n)}.$$

%   Combining these, with probability at least
%   $$\left(1-\frac{1}{\polylog(n)}\right)\left(1-\frac{1}{\polylog(n)}\right) =
%   1-\frac{1}{\polylog(n)}$$ we achieve positive
%   tilt at least $\beta h\cdot 24$ in at least $\gamma/8$ sets of $\beta$ cups. In
%   total, this means that means we have positive tilt $(\beta h \cdot 24)(\gamma/8) =
%   \frac{\alpha n/2}{(3/2)\gamma}\gamma h \cdot{24}{8} = n\alpha h$ in the anchor set, as desired.

% \end{proof}

%   By Claim \ref{clm:reg} in Case 1 the filler achieves, with probability at least
%   $1-1/\polylog n$ (in fact with much better probability) fill at least $h$ in
%   some constant fraction $nc$ of the cups.

%   In Case 2 by Claim \ref{clm:xtreme} the filler achieves, with probability at least
%   $1-1/\polylog n$, positive tilt at least $nh\alaph$ in the storage-block,
%   which consists of $\alpha n$ cups. Then 
%   $$\sum_{x\in C} \lfloor \tilt(x) / (h/2) \rfloor \ge \sum_{x\in C} (\tilt(x) / (h/2) -1) = n\alpha.$$

%   Using the cups that have fill chunks of $h$, setting the number of processors to $1$, and
%   exploiting the greedy nature of the emptier, the filler can obtain high fill
%   in a set of $nc$ \emph{known} cups.

%   In particular, the filler chooses a set of $nc$ cups randomly.
%   With probability at least $1/2$ the average fill of $nc$ is positive by a
%   Hoeffding bound and the fact that 
%   OH CRAP THIS JUST BROKE. YOU COULD SMOOTH IT. BUT THATS NOT FUN.
%   The filler repeatedly distributes a unit of water equally among these $nc$ cups. 
%   The filler continues until the average fill of that set of cups has increased
%   by $h'$. The filler uses one processor because it doesn't know how many cups
%   the positive tilt is concentrated in. Then the filler recurses on the set of
%   $nc$ known cups with average fill.

%   Note that this transformation from a set with high positive tilt to a set of
%   known cups with high positive average fill is the only part of the proof of
%   Proposition \ref{prop:obliviousBase} that is specific to a greedy-like
%   emptier. Against a general emptier it is not true that the emptier will
%   necessarily focus on the set of cups with high positive tilt; an arbitrary
%   emptier can of course foil our attempts to achieve high fill in any fixed set
%   of $p$ cups, at a given setting of $p$. Extending Proposition
%   \ref{prop:obliviousBase} to apply to non-greedy-like emptiers is an important
%   open question.
% \end{proof}

% \begin{lemma}[The Oblivious Amplification Lemma]
%   \label{lem:obliviousAmplification}
%   Let $f$ be an oblivious filling strategy that achieves backlog $f(n)$ in the
%   variable-processor cup game on $n$ cups with constant probability (relative
%   to average fill, with negative fill allowed). Let $\delta \in (0,1)$ be a
%   parameter. Then, there exists an adaptive filling strategy that, with
%   constant probability, either achieves backlog $$f'(n) \ge
%   (1-\delta)\Big(f((1-\delta)n) + f((1-\delta)\delta n)\Big)$$ or achieves
%   backlog $\Omega(\poly(n))$ in the variable processor cup game on $n$
%   cups.
% \end{lemma}
% \begin{proof}
%   {\color{cyan}
%   Note that the statement of Lemma \ref{lem:obliviousAmplification} is very
%   similar to the statement of Lemma \ref{lem:adaptiveAmplification}.
%   We have made a few simplifications, such as not allowing more than $1$
%   level of recursion, for simplifying the proof, at no cost to the final
%   backlog that we will derive.
%   The more major deviation from the Adaptive Amplification Lemma, is of course
%   that the filler is oblivious in this case. This necessitates working with
%   functions that only succeed at achieving the desired backlog with certain
%   probabilities. 
%   Nevertheless, the proof is remarkably similar to the proof of Lemma
%   \ref{lem:adaptiveAmplification}. We now establish the Lemma.

%   First we establish some important facts.

%   Again, we call a cup \defn{overpowered} if it has fill at least $h\sqrt{n} /
%   \lg\lg n$. As in Proposition \ref{prop:obliviousBase}, without loss of
%   generality there are no overpowered cups, because existence of an overpowered
%   cup means that we already have $\poly(n)$ backlog.

%   Let a cup be \defn{verysad} if it has fill $< -h\sqrt{n}/\lg\lg n$.
%   If there is a verysad cup then the average fill must be at least
%   $h\sqrt{n}/\lg\lg n$ (because fill is non-negative absolutely). Thus there
%   must be an overpowered cup.

% \begin{clm}
%   WLOG $A,B$ have average fill $\ge -h/8$.
%   In particular, we can construct a subset of $n/2$
%   cups with average fill $\ge -h/8$ with high probability in $n$. 
% \end{clm}
% \begin{proof}

%   Recall the definition of an overpowered cup as a cup with fill $\ge nh / \lg \lg n$,
%   and the fact that WLOG there are no overpowered cups.
%   So, If we randomly pick $B$ then his means that we are pretty good. 
%   Formalizing this, let $X_i$ be the fill of the $n/2$-th randomly chosen cup
%   for $B$. Unfortunately these are not quite independent events.

%   Initial solution: no overpowered cups WLOG, so if we pick them randomly star holds
%   by Hoeffding's. (kinda, bc stuff isnt really independent, can probably swap
%   with replacement to fix this tho)
  
% \end{proof}
% \begin{clm}
%   What if $C$ needs to be big because we need big backlog? 
% \end{clm}
% \begin{proof}
%  this isn't a problem because the base case is the only case that needs to
%  explicitly deal with positive and negative fill.
% \end{proof}
% These concerns resolved, the exact same argument as in Proposition
% \ref{prop:obliviousBase} gives the desired result.
% }
% \end{proof}

% \begin{corollary}
%   \label{cor:obliviousPoly}
%   There is an oblivious filling strategy for the variable-processor cup game on
%   $n$ cups that achieves backlog at least $2^{\Omega(\sqrt{\log n})}$ in
%   running time $O(n)$ with constant probability.
% \end{corollary}
% \begin{proof}
%   Given the Oblivious Amplification Lemma we could try to apply the same
%   strategy as outlined in the proof of Corollary \ref{cor:adaptivePoly} 
%   to achieve backlog $\Omega(n^{1-\epsilon})$ for constant $\epsilon >0$ in time $2^{O(\log^2 n)}$.
%   Because of our definition of an overpowered cup as a cup with fill at least
%   $\tilde{\Omega}(\sqrt{n})$, we can't get quite as close to linear as an
%   adaptive filer could. However, the more pressing problem is that of running
%   time: randomized algorithms are traditionally supposed to have polynomial-running time.
%   By artificially reducing $n$, i.e. ignoring some portion of the cups, we can
%   get an algorithm that achieves high backlog, but in polynomial time.
%   In particular, we want to choose a subset of $n'$ of the cups to focus on,
%   where $2^{O(\log^2 n')} = O(n)$. An appropriate choice is $n' = 2^{\sqrt{\log n}}$.

%   With $n'$ chosen, we apply the exact same strategy as given in the paragraph
%   in the proof of Corollary on the $2^{O(\log^2 n)}$-time construction for
%   achieving backlog $\Omega(n^{1-\epsilon})$ for constant $\epsilon >0$, but using
%   repeated application of the Oblivious Amplification Lemma rather than the
%   Adaptive Amplification Lemma, which yields the disclaimer that the backlog is
%   only achieved with constant probability.
%   Thus, we achieve backlog $\Omega(n')$ in running time $2^{O(\log^2
%   n')}$. By design, expressing this in terms of $n$ the filler achieves 
%   backlog $2^{\Omega(\sqrt{\log n})}$ in running time $O(n)$.

%   For completeness we -- briefly (as they are nearly identical) -- present the
%   ideas from Proposition \ref{prop:constructive_nepsil} in the randomized
%   context.

%   Fix constant $\epsilon > 0$ and choose appropriate constant $\delta$, as
%   mandated by Claim \ref{clm:validchoices}. Choose constant $c$, according to
%   an inequality to be specified later. We aim to achieve backlog
%   $c(n')^{1-\epsilon}$.
%   As before, we define a sequence of functions. First,
%   $$f_0(k) = 
%   \begin{cases} 
%     \lg k, & k\geq 1, \\
%     0 & \text{else.}
%   \end{cases}$$
%   Then, we define $f_i$ as the amplification of $f_{i-1}$ for $i \ge 1$, where
%   amplification is as defined in the Oblivious Amplification Lemma. 
%   However, this time the filling strategy $f_i$ achieves backlog $f_i(k)$ on
%   $k$ cups only with constant probability.
%   As before we define a sequence $g_i$ as 
%   $$ g_i = \begin{cases}
%     \lceil 1/\delta \rceil \gg 1,  & i = 0,\\
%     \lceil g_{i-1}/(1-\delta)\rceil -1 & i  \ge 1.
%   \end{cases} $$
%   Claim \ref{clm:fikinduction}, which states that 
%   $$f_i(k) \ge ck^{1-\epsilon} \text{ for all } k < g_i,$$
%   holds with no modifications required.

%   Again, because $g_i$ is increasing, we achieve the desired backlog
%   $c(n')^{1-\epsilon}$ in finite time. In particular, applying identical
%   arguments to those in Corollary \ref{cor:adaptivePoly}, we find that the
%   running time is $2^{O(\log^2 n')}$.

%   As stated earlier, by design of $n'$, this means we get backlog
%   $2^{\Omega(\sqrt{\log n})}$ in time $O(n)$.

% \end{proof}

\section{Conclusion}
Many important open questions remain open.

\bibliographystyle{plain}
\bibliography{paper}
\end{document}
