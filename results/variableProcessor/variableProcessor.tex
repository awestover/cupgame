\documentclass[twocolumn]{article}[10pt]
\usepackage[left=1in, right=1in, top=1in, bottom=1in]{geometry}
%\usepackage[moderate, mathspacing=normal]{savetrees}

\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{xspace}

\newcommand{\defn}[1]{{\textit{\textbf{\boldmath #1}}}\xspace}
\renewcommand{\paragraph}[1]{\vspace{0.09in}\noindent{\bf \boldmath #1.}} 
\newcommand{\todo}[1]{{\color{red}\textbf{TODO:} #1}}

\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\Var}{\text{Var}}
\DeclareMathOperator{\img}{Im}
\DeclareMathOperator{\polylog}{\text{polylog}}
\DeclareMathOperator{\poly}{\text{poly}}

\DeclareMathOperator{\fil}{\text{fill}}
\newcommand{\alg}[1]{\textit{\text{alg}}({#1})}
\newcommand{\randalg}{randalg-1\xspace}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\paren}[1]{\left( #1 \right)}

\usepackage[capitalise,nameinlink,noabbrev]{cleveref}
\crefname{equation}{}{} % cref{eq:blah} only does (1) instead of Equation (1)
\crefname{enumi}{Step}{} % cref{eq:blah} only does (1) instead of Equation (1)

\newcommand{\contr}[0]{\[ \Rightarrow\!\Leftarrow \]}
\newcommand{\defeq}{\vcentcolon=}
\newcommand{\eqdef}{=\vcentcolon}

\newtheorem{fact}{Fact}
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}
\newtheorem{proposition}{Proposition}
\newtheorem{clm}{Claim}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{theorem}{Theorem}
\newtheorem{conjecture}{Conjecture}

\usepackage{authblk}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}
\fancyfoot[R]{\thepage}
\renewcommand{\headrulewidth}{0pt}

\title{Variable-Processor Cup Games}
\date{\vspace{-5ex}}

\author[1]{\small William Kuszmaul\thanks{Supported by a Hertz fellowship and a NSF GRFP fellowship}}
\author[1]{\small Alek Westover\thanks{Supported by MIT}}

\affil[ ]{\footnotesize MIT\textsuperscript{1}}
\affil[ ]{\textit{kuszmaul@mit.edu, alek.westover@gmail.com}}

\begin{document}
\maketitle
\abstract{ 
  In a \defn{cup game} two players, the \defn{filler} and the \defn{emptier},
  take turns adding and removing water from cups, subject to certain
  constraints. In the classic $p$-processor cup game the filler distributes
  $p$ units of water among the $n$ cups with at most $1$ unit of water to any
  particular cup, and the emptier chooses $p$ cups to remove at most one unit
  of water from. Analysis of the cup game is important for applications in
  processor scheduling, buffer management in networks, quality of service
  guarantees, and deamortization.

  We investigate a new variant of the classic $p$-processor cup game, which
  we call the \defn{variable-processor cup game}, in which the resources of the
  emptier and filler are variable. In particular, in the variable-processor cup
  game the filler is allowed to change $p$ at the beginning of each round. 
  Although the modification to allow variable resources seems small, we
  show that it drastically alters the game.

  We construct an adaptive filling strategy that achieves backlog
  $\Omega(n^{1-\varepsilon})$ for any constant $\varepsilon >0$ of our choice in
  running time $2^{O(\log^2 n)}$. This is enormous compared to the upper
  bound of $O(\log n)$ that holds in the classic $p$-processor cup game!
  We also present a simple adaptive filling strategy that is able to
  achieve backlog $\Omega(n)$ in extremely long games: it has running time
  $O(n!).$

  Furthermore, we demonstrate that this lower bound on backlog is tight: 
  using a novel set of invariants we prove that a greedy emptier never lets
  backlog exceed $O(n)$.

  We also construct an oblivious filling strategy that achieves backlog
  $\Omega(n^{1-\varepsilon})$ for $\varepsilon>0$ constant of our choice in time
  $2^{O(\log^2 n)}$ against any ``greedy-like" emptier with probability at least
  $1-2^{-\polylog(n)}$. Whereas classically randomization gives the emptier a
  large advantage, in the variable-processor cup game the lower bound is the same!
}
\thispagestyle{fancy}

\section{Introduction}\label{sec:intro}
\paragraph{Definition and Motivation}
The \defn{cup game} is a multi-round game in which the two players, the
\defn{filler} and the \defn{emptier}, take turns adding and removing water
from cups. On each round of the classic \defn{$p$-processor cup game} on $n$
cups, the filler first distributes $p$ units of water among
the $n$ cups with at most $1$ unit to any particular cup (without this
restriction the filler can trivially achieve unbounded backlog by placing all
of its fill in a single cup every round), and then the emptier 
removes at most $1$ unit of water from each of $p$ cups.\footnote{Note that negative
fill is not allowed, so if the emptier empties from a cup with fill below $1$
that cup's fill becomes $0$.} The game has been studied for \defn{adaptive}
fillers, i.e. fillers that can observe the emptier's actions, and for
\defn{oblivious} fillers, i.e. fillers that cannot observe the emptier's actions.

The cup game naturally arises in the study of processor-scheduling. The
incoming water added by the filler represents work added to the system at time
steps. At each time step after the new work comes in, each of $p$ processors
must be allocated to a task which they will achieve $1$ unit of progress on
before the next time step. The assignment of processors to tasks is modeled by
the emptier deciding which cups to empty from. The backlog of the system is the
largest amount of work left on any given task; in the cup game the
\defn{backlog} of the cups is the fill of the fullest cup at a given state. In
analyzing a cup game we aim to prove upper and lower bounds on backlog.

\paragraph{Previous Work}
The bounds on backlog are well known for the case where $p=1$, i.e. the
\defn{single-processor cup game}.
In the single-processor cup game an adaptive filler can achieve backlog
$\Omega(\log n)$ and a greedy emptier never lets backlog exceed $O(\log n)$. In
the randomized version of the single-processor cup game, i.e. when the filler
is oblivious, which can be interpreted as a smoothed analysis of the
deterministic version, the emptier never lets backlog exceed $O(\log \log n)$,
and a filler can achieve backlog $\Omega(\log\log n)$.

Recently Kuszmaul has established bounds on the case where $p>1$, i.e. the
\defn{multi-processor cup game} \cite{wku20}. Kuszmaul showed that a greedy
emptier never lets backlog exceed $O(\log n)$. He also proved a lower bound of
$\Omega(\log (n-p))$ on backlog. Recently we showed a lower bound of
$\Omega(\log n - \log (n-p))$. Combined, these lower bounds bounds imply a
lower bound of $\Omega(\log n)$. Kuszmaul also established an upper bound of
$O(\log\log n + \log p)$ against oblivious fillers, and a lower bound of
$\Omega(\log\log n)$. Tight bounds on backlog against an oblivious
filler are not yet known for large $p$.

\paragraph{The Variable-Processor Cup Game}
We investigate a new variant of the classic $p$-processor cup game which we call
the \defn{variable-processor cup game}. In the variable-processor cup game the
filler is allowed to change $p$ (the total amount of water that the filler
adds, and the emptier removes, from the cups per round) at the beginning of
each round. Note that we do not allow the resources of the filler and emptier
to vary separately; just like in the classic cup game we take the resources of
the filler and emptier to be identical.
This restriction is crucial; if
the filler has more resources than the emptier, then
the filler could trivially achieve unbounded backlog, as average fill will
increase by at least some positive constant at each round.
Taking the resources of the players to be identical makes the game balanced,
and hence interesting.

The variable-processor cup game models the natural situation
where many users are all on a server, and the number of
processors allocated to each user is variable as other users get
some portion of the processors.

A priori having variable resources offers neither player a clear advantage:
lower values of $p$ mean that the emptier is at more of a discretization
disadvantage but also mean that the filler can ``anchor" fewer   
cups. \footnote{A
useful part of many filling algorithms is maintaining an ``anchor" set of
``anchored" cups. The filler always places $1$ unit of water in each anchored
cup. This ensures that the fill of an anchored cup never decreases after it is
placed in the anchor set.} Furthermore, at any fixed value of $p$ upper bounds
have been proven. For instance, regardless of $p$ a greedy emptier prevents an
adaptive filler from having backlog greater than $O(\log n)$. Switching between
different values of $p$, all of which the filler cannot individually use to get
backlog larger than $O(\log n)$ is not obviously going to help
the filler achieve larger backlog. We hoped that the
variable-processor cup game could be simulated in the classic
multi-processor cup game, because the extra ability given to the
filler does not seem very strong. 

However, we show that attempts at simulating the variable-processor cup
game are futile because the variable-processor cup game
is vastly different from the classic multi-processor cup game. 

\paragraph{Outline and Results}
In \cref{sec:prelims} we establish the conventions and
notations we will use to discuss the variable-processor cup game. 

In \cref{sec:adaptive} we provide an inductive proof of a
lower bound on backlog with an adaptive filler.
\cref{thm:adaptivePoly} states that a filler can achieve backlog
$\Omega(n^{1-\varepsilon})$ for any constant $\varepsilon > 0$ in
quasi-polynomial running time. \cref{prop:factorialTimeAlg} also provides an extremal strategy
that achieves backlog $\Omega(n)$ in incredibly long games: it
has $O(n!)$ running time.

In \cref{sec:upperBound} we prove a novel invariant maintained
by the greedy emptier. In particular \cref{thm:invariant} establishes
that a greedy emptier keeps the average fill of the $k$ fullest cups at most
$2n-k$. In particular this implies (setting $k=1$) that a greedy emptier
prevents backlog from exceeding $O(n)$. 

The lower bound and upper bound agree; our analysis is tight for adaptive fillers!

In \cref{sec:oblivious} we prove a lower bound on backlog with an oblivious filler. 
\cref{thm:obliviousPoly} states that an oblivious filler can achieve
backlog $\Omega(n^{1-\varepsilon})$ for any constant $\varepsilon > 0$ in
quasi-polynomial time with probability at least $1-2^{-\polylog(n)}$.
\cref{thm:obliviousPoly} only applies to a certain class of emptiers:
``greedy-like emptiers". Nonetheless, this class of emptiers is very
interesting; it contains the emptiers that are used in upper bound proofs.
It is shocking that randomization doesn't help the emptier in this game;
being oblivious seems like a large disadvantage for the filler!

\section{Preliminaries}\label{sec:prelims}
The cup game consists of a sequence of rounds. On the $t$-th round, the state
starts as $S_t$. The filler chooses the number of processors $p_t$ for the
round. Then the filler distributes $p_t$ units of water among the cups (with at
most $1$ unit of water to any particular cup). After this, the game is in an
intermediate state, which we call state $I_t$. Then the emptier chooses $p_t$
cups to empty at most $1$ unit of water from. Note that if the fill of a cup
that the emptier empties from is less than $1$ the emptier reduces the fill of
this cup to $0$ by emptying from it; we say that the emptier \defn{zeroes out}
a cup at round $t$ if the emptier empties, on round $t$, from a cup with fill
at state $I_t$ that is less than $1$. Note that on any round where the emptier
zeroes out a cup the emptier has removed less fill than the filler has added;
hence the average fill will increase. This concludes the round; the state of
the game is now $S_{t+1}$.

Denote the fill of a cup $c$ by $\fil(c)$. 
Let the \defn{mass} of a set of cups $X$ be $m(X) = \sum_{c\in X} \fil(c)$. 
Denote the average fill of a set of cups $X$ by $\mu(X)$. Note that $\mu(X) |X| = m(X)$.

Let the \defn{rank} of a cup at a given state be its position in a list of the
cups sorted by fill at the given state, breaking ties arbitrarily but
consistently. For example, the fullest cup at a state has rank $1$, and the
least full cup has rank $n$. Let $[n] = \{1,2,\ldots, n\}$, let
$i+[n] = \{i+1, i+2, \ldots, i+n\}$.

Many of our lower bound proofs will adopt the convention of
allowing for negative fill. We call this the \defn{negative-fill
cup game}. Specifically, in the negative-fill cup game, when the
emptier empties from a cup its fill always decreases by exactly
$1$: there is no zeroing out. Negative-fill can be interpreted as
fill below some average fill. Measuring fill like this is
important however, as our lower bound results are used
recursively, building on the average fill already achieved. Note
that it is strictly easier for the filler to achieve high backlog
when cups can zero out, because then some of the emptier's
resources are wasted. On the other hand, during the upper bound
proof we show that a greedy emptier maintains the desired
invariants even if cups zero out. This is crucial as the game is
harder for the emptier when cups can zero out.
Some results are proved for the variable-processor negative-fill
cup game, and some results are proved for the single-processor
negative-fill cup game.

\section{Adaptive Filler Lower Bound}\label{sec:adaptive}

In this section we give a $2^{\polylog n}$-time filling strategy
that achieves backlog $n^{1 - \varepsilon}$ for any positive
constant $\varepsilon$. 
We also give a $O(n!)$-time filling strategy that achieves
backlog $\Omega(n)$.

We begin with a simple proposition that gives backlog $1/2$ for two cups.
\begin{proposition}
  \label{prop:adaptiveBase}
  Consider an instance of the negative-fill $1$-processor cup
  game on $2$ cups, and let the cups start in any state where the
  average fill is $0$. There is an $O(1)$-step adaptive filling
  strategy that achieves backlog at least $1/2$.
\end{proposition}
\begin{proof}
  Let the fills of the $2$ cups start as $x$ and $-x$ for some $x\ge
  0$. If $x\ge 1/2$ the algorithm need not do anything. Otherwise, the filling
  strategy adds $1/2 - x$ fill to the cup with fill $x$, and adds
  $1/2 + x$ fill to the cup with fill $-x$. This results in $2$
  cups both having fill $1/2$; the emptier then empties from one
  of these, and leaves a cup with fill $1/2$, as desired.
\end{proof}

% We begin by modifying the proof of the classic lower bound for
% the single-processor cup game to work with a cup configuration
% that includes negative fills; allowing for negative fills will be
% important when applying the result in later constructions. 
% \begin{proposition}
% \label{prop:adaptiveBaseAlternate}
%   Consider an instance of the negative-fill $1$-processor cup
%   game on $n$ cups, and let the cups start in any state where the
%   average fill is $0$. There is an $O(n)$-step adaptive filling
%   strategy that achieves backlog at least
%   $\frac{1}{4}(\ln (n/2) - 1)$.
% \end{proposition}
% \begin{proof}
%   Let $h = \frac{1}{4}(\ln (n/2) -1)$ be the desired fill. Once a cup with fill at
%   least $h$ is achieved the filler stops, and the algorithm is done.  
  
%   We claim that, at the beginning of the game, either the
%   algorithm is already done, or there are at least $n / 2$ cups
%   containing fills greater than $-2h$. If the filling process is
%   not yet complete then $\fil(c) < h$ for all cups $c$, and thus
%   the mass of the cups with non-negative fills is less than $hn$.
%   Assume for contradiction that at least $n / 2$ cups have fills
%   $-2h$ or smaller. The mass of those cups is less than or equal
%   to $-hn$. Since the mass of the cups with non-negative fills is
%   less than $hn$, it follows that the total mass of the cups is
%   negative, a contradiction. 

%   We now describe the filler's strategy. If the algorithm is not
%   already done at the beginning of the game, then at least $n /
%   2$ cups must have fills greater than $-2h$. At the beginning of
%   the algorithm, $n / 2$ such cups are labeled as \defn{active
%   cups}. In each of step of the algorithm, the filler distributes
%   $1$ unit of water evenly among the active cups. The emptier
%   then removes water from some cup $c$. Finally, the filler
%   reduces the number of active cups by $1$, removing cup $c$ if
%   it was active, and otherwise removing an arbitrary cup. Now
%   consider the state of the final active cup after $n / 2  - 1$
%   steps. This cup's fill has increased by 
%   $$1/(n/2) + 1/(n/2 - 1) + \cdots + 1/2 \ge \ln (n/2) -1 = 4h.$$ 
%   This cup's fill started as at least $-2h$. Thus this cup now
%   has fill at least $2h$, as desired.
% \end{proof}

Next we prove the \defn{Amplification Lemma}.
\begin{lemma}[Adaptive Amplification Lemma]\label{lem:adaptiveAmplification}
  Let $\delta\in(0,1)$ be a parameter.
  Let $\alg{f}$ be an adaptive filling strategy that 
  achieves backlog $f(n) < n$ in the negative-fill variable-processor cup game
  on $n$ cups in running time $T(n)$ starting from any initial
  cup state where the average fill is $0$.

  Then there exists an adaptive filling strategy $\alg{f'}$ that
  achieves backlog $f'(n)$ satisfying 
  $$f'(n) \ge (1-\delta)f(\floor{(1-\delta)n}) + f(\ceil{\delta n}) $$
  and $f'(n) \ge f(n)$
  in the negative-fill variable-processor cup game on $n$ cups in running time 
  $$T'(n) \le n^2 \delta \cdot T(\floor{(1-\delta)n}) + T(\ceil{\delta n})$$
  starting from any initial cup state where the average fill is $0$.
\end{lemma}

Before proving the Amplification Lemma, we briefly motivate it. 
We call $\alg{f'}$, the filling strategy created by the Amplification
Lemma, the \defn{amplification} of $\alg{f}$.
As suggested by the name, $\alg{f'}$ will be able to achieve
higher backlog than $\alg{f}$. In particular, we
will show that by starting with a filling strategy $\alg{f_0}$ for achieving
constant backlog and then recursively forming a sufficiently
long sequence of filling strategies $\alg{f_0}, \alg{f_1},
\ldots, \alg{f_{i_*}}$ with
$\alg{f_{i+1}}$ the amplification of $\alg{f_i}$, we eventually
get a filling strategy for achieving $\poly(n)$ backlog.
  
\begin{proof}[Proof of Amplification Lemma]
The algorithm defaults to using $\alg{f}$ if $f(n) \ge
(1-\delta)f(\floor{(1-\delta)n}) + f(\ceil{\delta n})$; in this
case using $\alg{f}$
achieves the desired backlog in the desired running time. In the
rest of the proof, we describe our strategy for achieving backlog
$(1-\delta)f(\floor{(1-\delta)n}) + f(\ceil{\delta n})$. 

  Let $A$, the \defn{anchor set}, be initialized to consist of
  the $\ceil{n\delta}$ fullest cups, and let $B$ the
  \defn{non-anchor set} be initialized to consist of the rest of
  the cups (so $|B| = \floor{(1-\delta)n}$). Let $h =
  (1-\delta)f(\floor{(1-\delta)n}).$

  The filler's strategy is roughly as follows: \\
  \textbf{Step 1:} Get $\mu(A) \ge h$ by using $\alg{f}$
  repeatedly on $B$ to achieve cups with fill at least $\mu(B) +
  f(|B|)$ in $B$ and then swapping these into $A$.\\
  \textbf{Step 2:} Use $\alg{f}$ once on $A$ to obtain some cup
  with fill $\mu(A)+f(|A|)$.\\
  Note that in order to use $\alg{f}$ on subsets of the cups the
  filler will need to vary $p$.

  We now describe how to achieve Step 1, which is
  complicated by the fact that the emptier may attempt to
  prevent the filler from achieving high fill in a cup
  in $B$.

  The filling strategy always places $1$ unit of water in each
  anchor cup. This ensures that no cups in the anchor set ever
  have their fill decrease. If the emptier wishes to keep the
  average fill of the anchor cups from increasing, then emptier
  must empty from every anchor cup on each step. If the emptier
  fails to do this on a given round, then we say that the emptier
  has \defn{neglected} the anchor cups. 

  We say that the filler \defn{applies} $\alg{f}$ to $B$ if it
  follows the filling strategy $\alg{f}$ on $B$ while placing $1$
  unit of water in each anchor cup. An application of $\alg{f}$ to
  $B$ is said to be \defn{successful} if $A$ is never neglected
  during the application of $\alg{f}$ to $B$. The filler uses a
  procedure that we call a \defn{swapping-process} to achieve the
  desired average fill in $A$. In a swapping-process, the filler
  repeatedly applies $\alg{f}$ to $B$ until a successful
  application occurs, and then takes the cup generated by
  $\alg{f}$ within $B$ on this successful application with fill at
  least $\mu(B) + f(|B|)$ and swaps it with the least full cup in
  $A$. If the average fill in $A$ ever reaches $h$, then the
  algorithm immediately halts (even if it is in the middle of a
  swapping-process) and is complete.
  
  Note that $$\mu(A) \cdot |A| + \mu(B)\cdot |B| = 0,$$ so
  $$\mu(A) = - \mu(B) \cdot
  \frac{\floor{(1-\delta)n}}{\ceil{\delta n}} \ge -
  \frac{1-\delta}{\delta} \mu(B).$$ Thus, if at any
  point $B$ has average fill lower than $-h \cdot
  \delta/(1-\delta)$, then $A$ has average fill at least $h$, so
  the algorithm is finished. Thus we can assume in our analysis that
  \begin{equation}
    \mu(B) \ge -h\cdot\delta/(1-\delta).
  \label{eq:Batleast}
  \end{equation}
  We will now show that during each swapping process, the filler
  applies $\alg{f}$ to $B$ at most $h n \delta + 1$ times. 
  Each time the emptier neglects the anchor set, the mass of the
  anchor set increases by $1$. If the emptier neglects the anchor set $h
  n\delta + 1$ times, then the average fill in the anchor set increases by
  more than $h$, so the desired average fill is achieved in the
  anchor set. Thus the swapping process consists of at most
  $hn\delta + 1$ applications of $\alg{f}$.  

  Consider the fill of a cup $c$ swapped into $A$ at the end of a
  swapping-process. Cup $c$'s fill is at least $\mu(B) + f(|B|)$,
  which by \eqref{eq:Batleast} is at least
  $$-h \cdot \frac{\delta}{1-\delta} + f(\floor{n (1-\delta)}) =
  (1-\delta)f(\floor{n (1-\delta)}) = h.$$ 
  Thus the algorithm for Step 1 succeeds within $|A| =
  \ceil{\delta n}$ swapping-processes, since at the end of the $|A|$-th
  swapping process every cup in $A$ has fill at least $h$, or
  the algorithm halted before $|A|$ swapping-processes because it
  already achieved $\mu(A) \ge h$. 
  
  Now the filler performs Step 2, i.e. the filler applies
  $\alg{f}$ to $A$, and hence achieves a cup with fill at least 
  $$\mu(A) + f(|A|) \ge (1-\delta)f(\floor{(1-\delta)n)}) + f(\ceil{\delta n}),$$
  as desired.

  Now we analyze the running time of the filling strategy
  $\alg{f'}$. First, recall that in Step 1 $\alg{f'}$ calls $\alg{f}$ on a
  set of size $\floor{(1-\delta)n}$ as many as $hn\delta +1$ times.
  Because we mandate that $h < n$, Step 1 contributes no more
  than $(n\cdot n\delta) \cdot T(|B|)$ to the running time.
  Step 2 requires applying $\alg{f}$ to $|A|$ cups one time, and hence
  contributes $T(|A|)$ to the running time. Summing these we have
  $$T'(n) \le n^2\delta \cdot T(\floor{(1-\delta)n}) + T(\ceil{\delta n}).$$

\end{proof}

We next show that by recursively using the Amplification Lemma we
can achieve backlog $n^{1 - \varepsilon}$.
\begin{theorem}
  \label{thm:adaptivePoly}
  There is an adaptive filling strategy for the variable-processor cup game on
  $n$ cups that achieves backlog $\Omega(n^{1-\varepsilon})$ for any constant
  $\varepsilon > 0$ of our choice in running time $2^{O(\log^2 n)}$.
\end{theorem}
\begin{proof}
  Take constant $\varepsilon \in (0,1/2)$. Let $c, \delta$ be
  parameters, with $c\in (0,1), 0 < \delta \ll 1/2$, these will
  be chosen later as functions of $\varepsilon$.
  We show how to achieve backlog at least $cn^{1-\varepsilon}-1$.

  By \cref{prop:adaptiveBase} there exists a constant
  $n_0$ such that a filler can achieve backlog $1$
  on $n_0$ cups (e.g., $n_0 = 1000$ works). Let $\alg{f_0}$ by
  the filling strategy described in \cref{prop:adaptiveBase},
  where $f_0(k)
  \ge 1$ for all $k\ge n_0$. 

  Next, using the Amplification Lemma we recursively construct
  $\alg{f_{i+1}}$ as the amplification of $\alg{f_{i}}$ for $i\ge 0$. 

  Define a sequence $g_i$ with 
  $$ g_i = \begin{cases}
    \ceil{16/\delta},  & i = 0,\\
    \floor{g_{i-1}/(1-\delta)} & i \ge 1
  \end{cases} $$

  We claim the following regarding this construction:
  \begin{clm}
    \label{clm:fikinduction}
    For all $i\ge0$,
    \begin{equation}
      f_i(k) \ge ck^{1-\varepsilon}-1\,\, \text{ for all }\,\, k\in [g_{i}].
    \label{eqn:fikinduction}
    \end{equation}
  \end{clm}
  \begin{proof}
  We prove \cref{clm:fikinduction} by induction on $i$.
  For $i=0$, the base case, \eqref{eqn:fikinduction} can
  be made true by taking $c$ and $\delta$ sufficiently small.
  In particular, we we choose $c=\Theta(1)$ small enough to make 
  $c n_0^{1-\varepsilon} -1 \le 0$, which implies
  \eqref{eqn:fikinduction} holds for $k \in [n_0]$ by
  monotonicity of $ck^{1-\varepsilon}-1$; we also choose $\delta$
  small enough to make $g_0 \ge n_0$, and we choose $c$ small
  enough to make $c g_0^{1-\varepsilon} -1 \le f_0(g_0) = 1$, which
  implies \eqref{eqn:fikinduction} holds for $k\in [n_0, g_0]$ by
  monotonicity of $ck^{1-\varepsilon}-1$. \footnote{Note
  that it is important here that $\varepsilon$ and
  $\delta$ are constants, that way $c$ is also a constant.}

  As our inductive hypothesis we assume
  \eqref{eqn:fikinduction} for $f_i$; we aim to show that 
  \eqref{eqn:fikinduction} holds for $f_{i+1}$. Note that, by
  design of $g_i$, if $k \le g_{i+1}$ then $\floor{k\cdot (1-\delta)} \le g_i$.
  Consider any $k\in [g_{i+1}]$. First we deal with the trivial
  case where $k \le g_0$. In this case 
  $$f_{i+1}(k) \ge f_i(k) \ge \cdots \ge f_0(k) \ge ck^{1-\varepsilon} -1.$$

  Now we consider the case where $k \ge g_0$.
  Since $f_{i+1}$ is the amplification of $f_i$ we have
  $$f_{i+1}(k) \ge (1-\delta) f_i(\floor{(1-\delta)k}) + f_i(\ceil{\delta k}).$$
  By our inductive hypothesis, which applies as $\ceil{\delta k}\le g_i, \floor{k\cdot (1-\delta)} \le g_i$, we have
  $$f_{i+1}(k) \ge (1-\delta) (c \cdot\floor{(1-\delta)k}^{1-\varepsilon}-1) + c\ceil{\delta k}^{1-\varepsilon} - 1. $$
  Dropping the floor and ceiling, incurring a $-1$ for dropping the floor, we have
  $$f_{i+1}(k) \ge (1-\delta) (c \cdot ((1-\delta)k-1)^{1-\varepsilon}-1) + c (\delta k)^{1-\varepsilon} - 1.$$
  Because $(x-1)^{1-\varepsilon} \ge x^{1-\varepsilon} -1$, due to the
  fact that $x\mapsto x^{1-\varepsilon}$ is a sub-linear
  sub-additive function, we have 
  $$f_{i+1}(k) \ge (1-\delta) c \cdot (((1-\delta)k)^{1-\varepsilon}-2) + c(\delta k)^{1-\varepsilon}-1.$$
  Moving the $ck^{1-\varepsilon}$ to the front we have
  $$ f_{i+1}(k) \ge ck^{1-\varepsilon} \cdot\left((1-\delta)^{2-\varepsilon} + \delta^{1-\varepsilon} - \frac{2(1-\delta)}{k^{1-\varepsilon}} \right) -1.$$
  Because $(1-\delta)^{2-\varepsilon} \ge 1-(2-\varepsilon)\delta$, a fact called Bernoulli's Identity, we have
  $$f_{i+1}(k) \ge ck^{1-\varepsilon} \cdot\left(1-(2-\varepsilon)\delta + \delta^{1-\varepsilon} - \frac{2(1-\delta)}{k^{1-\varepsilon}} \right)-1.$$
  Of course $-2(1-\delta) \ge -2$, so 
  $$f_{i+1}(k) \ge ck^{1-\varepsilon} \cdot\left(1-(2-\varepsilon)\delta + \delta^{1-\varepsilon} - \frac{2}{k^{1-\varepsilon}} \right) -1.$$
  Because 
  $$-2/k^{1-\varepsilon} \ge -2/g_0^{1-\varepsilon} \ge
  -2(\delta/16)^{1-\varepsilon} \ge -\delta^{1-\varepsilon}/2,$$ which follows from our choice of $g_0 = \ceil{16/\delta}$ and the restriction
  $\varepsilon<1/2$, we have
  $$f_{i+1}(k) \ge ck^{1-\varepsilon} \cdot\left(1-(2-\varepsilon)\delta + \delta^{1-\varepsilon} - (1/2)\delta^{1-\varepsilon} \right)-1.$$
  Finally, combining terms we have
  $$f_{i+1}(k) \ge  ck^{1-\varepsilon} \cdot\left(1-(2-\varepsilon)\delta + (1/2)\delta^{1-\varepsilon}\right)-1. $$

  Because $\delta^{1-\varepsilon}$ dominates $\delta$ for
  sufficiently small $\delta$, there is a choice of
  $\delta=\Theta(1)$ such that 
  $$1-(2-\varepsilon)\delta + (1/2)\delta^{1-\varepsilon} \ge 1.$$ 
  Taking $\delta$ to be this
  small we have,
  $$f_{i+1}(k) \ge ck^{1-\varepsilon}-1,$$
  completing the proof. We remark that the choices of $c, \delta$
  are the same for every $i$ in the inductive proof, and depend
  only on $\varepsilon$. 
  \end{proof}

  To complete the proof, we will show that $g_i$ grows exponentially in $i$. Thus,
  after there exists $i_* \le O(\log n)$ such that
  $g_{i_*} \ge n$, and hence we have an algorithm $\alg{f_{i_*}}$
  that achieves backlog $cn^{1-\varepsilon}-1$ on $n$ cups, as
  desired.
  
  We lower bound the sequence $g_i$ with another sequence $g_i'$
  defined as 
  $$g_i'=\begin{cases}
    4/\delta, & i=0\\
    g_{i-1}' / (1-\delta) -1, & i> 0.
  \end{cases}$$
  Solving this recurrence, we find 
  $$g_i' = \frac{4-(1-\delta)^2}{\delta} \frac{1}{(1-\delta)^i}
  \ge \frac{1}{(1-\delta)^i},$$
  which clearly exhibits exponential growth. 
  In particular, let $i_* = \ceil{\log_{1/(1-\delta)} n}$. Then,
  $$ g_{i_*} \ge g_{i_*}' \ge n,$$ as desired.

  Let the running time of $f_i(n)$ be $T_i(n)$. From the Amplification Lemma we have following recurrence bounding $T_i(n)$:
  \begin{align*}
  T_i(n) &\le n^2\delta \cdot T_{i-1}(\floor{(1-\delta)n}) +
  T_{i-1}(\ceil{\delta n}) \\
  &\le 2n^2T_{i-1}(\floor{(1-\delta)n}).
  \end{align*}
  It follows that $\alg{f_{i_*}}$, recalling that $i_* \le O(\log n)$, has running time
  $$T_{i_*}(n) \le (2n^2)^{O(\log n)} \le 2^{O(\log^2 n)}$$
  as desired.

\end{proof}

Now we provide a very simple construction that can achieve backlog $\Omega(n)$
in very long games. The construction can be interpreted as the same
argument as in \cref{thm:adaptivePoly} but with an extremal setting of
$\delta$ to $\Theta(1/n)$. \footnote{Or more precisely, setting
$\delta$ in each level of recursion to be $\Theta(1 / n)$, where
$n$ is the subproblem size; note in particular that $\delta$
changes between levels of recursion, which was not the case in
the proof of \cref{thm:adaptivePoly}.}

\begin{proposition}
  \label{prop:factorialTimeAlg}
  There is an adaptive filling strategy that
  achieves backlog $\Omega(n)$ in time $O(n!)$.
\end{proposition}
\begin{proof}
  We start, as in the proof of \cref{thm:adaptivePoly}, with an
  algorithm $\alg{f_0}$ for
  achieving backlog $f_0(k) \ge 1$ on $k\ge n_0$ cups, which is
  possible by \cref{prop:adaptiveBase}. 
  For $i > 0$ we construct $\alg{f_{i}}$ as the
  amplification of $\alg{f_{i-1}}$ using the 
  Amplification Lemma with parameter $\delta = 1/(i+1)$. 

  We claim the following regarding this construction:
  \begin{clm}
    \label{clm:yayactuallygetn}
  For all $i\ge 0$,
  \begin{equation}
    \label{eq:omegaNpfinduction}
    f_i((i+1)\cdot n_0) \ge \sum_{j=0}^i \left(1-\frac{j}{i+1}\right).
  \end{equation}
  \end{clm}
  \begin{proof}
  We prove \cref{clm:yayactuallygetn} by induction on $i$. When $i=0$, the base case, \eqref{eq:omegaNpfinduction} becomes 
  $f_{0}(n_0) \ge 1$ which is true. Assuming
  \eqref{eq:omegaNpfinduction} for $f_{i-1}$, we now show
  \eqref{eq:omegaNpfinduction} holds for $f_{i}$.
  Because $f_{i}$ is the amplification of $f_{i-1}$ with $\delta = 1/(i+1)$, we have by the Amplification Lemma
  $$f_{i}((i+1)\cdot n_0) \ge \left(1 - \frac{1}{i+1}\right) f_{i-1}(i\cdot n_0) + f_{i-1}(n_0).$$
  Since $f_{i-1}(n_0) \ge f_0(n_0) \ge 1$ we have
  $$f_{i}((i+1)\cdot n_0) \ge \left(1 - \frac{1}{i+1}\right) f_{i-1}(i\cdot n_0) + 1.$$
  Using the inductive hypothesis we have
  $$f_{i}((i+1)\cdot n_0) \ge \left(1 - \frac{1}{i+1}\right)\sum_{j=0}^{i-1} \left(1-\frac{j}{i}\right) + 1.$$
  Note that 
  \begin{align*}
    \left(1 - \frac{1}{i+1}\right)\cdot \left(1-\frac{j}{i}\right) &= \frac{i}{i+1} \cdot \frac{i-j}{i} \\
  &= \frac{i-j}{i+1}\\
  &= 1 - \frac{j+1}{i+1}.
  \end{align*}
  Thus we have
  $$f_{i}((i+1)\cdot n_0) \ge \sum_{j=1}^{i} \left(1-\frac{j}{i+1}\right) + 1 = \sum_{j=0}^{i} \left(1-\frac{j}{i+1}\right),$$
  as desired.
  \end{proof}

  Let $i_* = \floor{n/n_0}-1$, which by design satisfies $(i_*+1)n_0 \le n$.
  By \cref{clm:yayactuallygetn} we have
  $$f_{i_*}((i_*+1)\cdot n_0) \ge \sum_{j=0}^{i_*} \left(1 - \frac{j}{i_*+1} \right) = i_*/2 + 1.$$
  As $i_* = \Theta(n)$, we have thus shown that $\alg{f_{i_*}}$ can achieve backlog $\Omega(n)$ on $n$ cups.

    Let $T_i$ be the running time of $\alg{f_i}$.
  The recurrence for the running running time of $f_{i_*}$ is 
  $$T_i(n) \le n \cdot n_0T_{i-1}(n-n_0)+O(1).$$
  Clearly $T_{i_*}(n) \le O(n!)$.

  % This algorithm can be interpreted very simply. To achieve large backlog on
  % $n$ cups we create an anchor set $A$ of $n_0$ cups and a set $B$ of $n-n_0$
  % cups; We recursively apply our strategy to $B$ for each cup in $A$. In
  % order for the average fill difference between $A$ and $B$ to be $f(n-n_0)$,
  % $\mu(A)$ must rise by $\frac{n-n_0}{n}$ of this difference whereas $\mu(B)$
  % must sink by $\frac{n_0}{n}$ of this difference. Hence we achieve average
  % fill $\frac{n-n_0}{n}f(n-n_0)$ in $A$. Then, using the strategy from
  % \cref{prop:adaptiveBase} we can achieve backlog $1$ on these cups. 
\end{proof}


\section{Upper Bound}\label{sec:upperBound}

In this section we analyze the \defn{greedy emptier}, which always empties
from the $p$ fullest cups. We prove in \cref{cor:upperbound} that the
greedy emptier prevents backlog from exceeding $O(n)$. 

In order to analyze the greedy emptier, we establish a system of invariants
that hold at every step of the game. 

Let $\mu_S(X)$ and $m_S(X)$ denote the average fill and the mass, respectively,
of a set of cups $X$ at state $S$ (e.g. $S=S_t$ or $S=I_t$).\footnote{Note that
  in the lower bound proofs (i.e. \cref{sec:adaptive} and 
  \cref{sec:oblivious}) when we use the notation $m$ (for mass) and $\mu$ (for
average fill), we omit the subscript indicating the state at which the
properties are measured. In those proofs the state is implicitly clear.
However, in this section it will be useful to make the state $S$ explicit in
the notation.} Let $S(\{r_1, \ldots, r_m\})$ denote the set of cups of ranks
$r_1, r_2, \ldots, r_m$ at state $S$. We will use concatenation of sets to
denote unions, i.e. $AB = A\cup B$. 

The main result of the section is the following theorem.  
\begin{theorem}
  \label{thm:invariant}
  In the variable-processor cup game on $n$ cups, the greedy emptier maintains, at every step $t$,
  the invariants
  \begin{equation}
    \label{eq:invariants}
      \mu_{S_t}(S_t([k])) \le 2n-k
  \end{equation}
  for all  $k \in [n]$.
\end{theorem}

By applying \cref{thm:invariant} to the case of $k = 1$, we arrive at a bound on backlog:
\begin{corollary}
  On a game with $n$ cups, the greedy emptying strategy achieves backlog $O(n)$.
  \label{cor:upperbound}
\end{corollary}

\begin{proof}[Proof of \cref{thm:invariant}]
We prove the invariants by induction on $t$.
The invariants hold trivially for $t=1$ (the base case for the inductive proof): 
the cups start empty so $\mu_{S_1}(S_1([k])) = 0 \le 2n-k$ for all $k \in [n]$.

Fix a round $t \ge 1$, and any $k \in [n]$. We assume the invariants for all
values of $k' \in[n]$ for state $S_t$ (we will only explicitly use two of the
invariants for each $k$, but the invariants that we need depend on the
choice of $p_t$ by the filler) and show that
the invariant on the $k$ fullest cups holds on round $t+1$, i.e. that
$$\mu_{S_{t+1}}(S_{t+1}([k])) \le 2n-k.$$

Note that because the emptier is greedy it always empties from the cups
$I_t([p_t])$. Let $A$, with $a=|A|$, be $A = I_t([\min(k, p_t)]) \cap
S_{t+1}([k])$; $A$ consists of the cups that are among the $k$ fullest cups in
$I_t$, are emptied from, and are among the $k$ fullest cups in $S_{t+1}$. Let
$B$, with $b=|B|$, be $I_t([\min(k, p_t)]) \setminus A$; $B$ consists of the
cups that are among the $k$ fullest cups in state $I_t$, are emptied from, and
are not among the $k$ fullest cups in $S_{t+1}$. Let $C = I_t(a+b+[k-a])$, with
$c=k-a = |C|$; $C$ consists of the cups with ranks $a + b + 1, \ldots, k + b$
in state $I_t$. The set $C$ is defined so that $S_{t+1}([k]) = AC$, since once
the cups in $B$ are emptied from, the cups in $B$ are not among the $k$ fullest
cups, so cups in $C$ take their places among the $k$ fullest cups.

Note that $k-a \ge 0$ as $a+b \le k$, and also $|ABC| = k+b \le n$, because by
definition the $b$ cups in $B$ must not be among the $k$ fullest cups in state
$S_{t+1}$ so there are at least $k+b$ cups. 
Note that $a + b = \min(k, p_t)$. We also have that $A = I_t([a])$ and $B =
I_t(a+[b])$, as every cup in $A$ must have higher fill than all cups in $B$ in
order to remain above the cups in $B$ after $1$ unit of water is removed from
all cups in $AB$.

We now establish the following claim, which we call the \defn{interchangeability of cups}:
\begin{clm}
  \label{clm:interchangable}
  There exists a cup state $S_t'$ such that: (a) $S_t'$ satisfies the
  invariants \eqref{eq:invariants}, (b) $S_t'(r) = I_t(r)$ for all ranks
  $r\in[n]$, and (c) the filler can legally place water into cups in order to
  transform $S_t'$ into $I_t$. 
\end{clm}
\begin{proof}
  Fix $r \in [n]$. We will show that $S_t$ can be transformed into a state
  $S_t^r$ by relabelling only cups with ranks in $[r]$ such that (a) $S_t^r$
  satisfies the invariants \eqref{eq:invariants}, (b) $S_t^r([r]) = I_t([r])$
  and (c) the filler can legally place water into cups in order to transform
  $S_t^r$ into $I_t$.

Say there are cups $x, y$ with $x\in S_t([r]) \setminus I_t([r]), y \in
 I_t([r])\setminus S_t([r])$. Let the fills of cups $x,y$ at state $S_t$
 be $f_x, f_y$; note that 
 \begin{equation}
     f_x > f_y.
     \label{eq:fxfy}
 \end{equation} Let the amount of fill that the filler
 adds to these cups be $\Delta_x, \Delta_y \in [0,1]$; note that 
 \begin{equation}
 f_x +\Delta_x <f_y + \Delta_y.
 \label{eq:fxdxfydy}
 \end{equation}
 
Define a new state $S_t'$ where cup $x$ has fill $f_y$ and cup $y$ has fill
$f_x$. Note that the filler can transform state $S_t'$ into state $I_t$ by
placing water into cups as before, except changing the amount of water placed
into cups $x$ and $y$ to be  $f_x-f_y+\Delta_x$ and $f_y-f_x + \Delta_y$,
respectively.

In order to verify that the transformation from $S_t'$ to $I_t$ is a valid step
for the filler, one must check three conditions. First, the amount of water
placed by the filler is unchanged: this is because $(f_x-f_y + \Delta_x) +
(f_y-f_x+\Delta_y) = \Delta_x + \Delta_y$. Second, the fills placed in cups $x$
and $y$ are at most $1$: this is because $f_x-f_y+\Delta_x<\Delta_y \le 1$ (by
\eqref{eq:fxdxfydy}) and $f_y-f_x + \Delta_x < \Delta_x \le 1$ (by
\eqref{eq:fxfy}). Third, the fills placed in cups $x$ and $y$ are non-negative:
this is because $f_x-f_y + \Delta_x > \Delta_x \ge 0$ (by \eqref{eq:fxfy})
and $f_y-f_x+\Delta_y > \Delta_x \ge 0$ (by
\eqref{eq:fxdxfydy}). 

We can repeatedly apply this process to swap each cup in $I_t([r])\setminus
S_t([r])$ into being in $S_t'([r])$. At
the end of this process we will have some state $S_t^r$ for which
$S_t^r([r]) = I_t([r])$. Note that $S_t^r$ is simply a relabeling of $S_t$,
hence it must satisfy the same invariants \eqref{eq:invariants} satisfied by
$S_t$. Further, $S_t^r$ can be transformed into $I_t$ by a valid filling step.

Now we repeatedly apply this process, in descending order of ranks. 
In particular, we have the following process: create a sequence of states by
starting with $S_t^{n-1}$, and to get to state $S_t^{r}$ from state $S_t^{r+1}$
apply the process described above. 
Note that $S_t^{n-1}$ satisfies $S_t^{n-1}([n-1]) = I_t([n-1])$ and thus also
$S_t^{n-1}(n) = I_t(n)$.
If $S_t^{r+1}$ satisfies $S_t^{r+1}(r') = I_t(r')$ for all $r'>r+1$ then
$S_t^r$ satisfies $S_t^r(r') = I_t(r')$ for all $r > r$, because the transition
from $S_t^{r+1}$ to $S_t^r$ has not changed the labels of any cups with ranks
in $(r+1, n]$, but the transition does enforce $S_t^r([r]) = I_t([r])$, and
consequently $S_t^r(r+1) = I_t(r+1)$.
We continue with the sequential process until arriving at state $S_t^1$ in
which we have $S_t^1(r) = I_t(r)$ for all $r$.
Throughout the process each $S_t^r$ has satisfied the invariants
\eqref{eq:invariants}, so $S_t^1$ satisfies the invariants
\eqref{eq:invariants}. Further, throughout the process from each $S_t^r$ it is
possible to legally place water into cups in order to transform $S_t^r$ into
$I_t$.

Hence $S_t^1$ satisfies all the properties desired, and the proof of 
\cref{clm:interchangable} is complete.

\end{proof}

\cref{clm:interchangable} tells us that we may assume without loss of
generality that $S_t(r) = I_t(r)$ for each rank $r \in [n]$. We will make
this assumption for the rest of the proof. 

In order to complete the proof of the theorem, we break it into three cases. 

\begin{clm}
  If some cup in $A$ zeroes out in round $t$, then the invariant
  $\mu_{S_{t+1}}(S_{t+1}([k])) \le 2n-k$ holds.
\end{clm}
\begin{proof}
  Say a cup in $A$ zeroes out in step $t$. 
  Of course
  $$m_{S_{t+1}}(I_t([a-1])) \le (a-1)(2n-(a-1))$$
  because the $a-1$ fullest cups must have satisfied the invariant (with $k = a - 1$) on round
  $t$. Moreover, because $\fil_{S_{t+1}}(I_{t+1}(a)) = 0$
  $$m_{S_{t+1}}(I_t([a])) = m_{S_{t+1}}(I_t([a-1])).$$
  Combining the above equations, we get that
  $$m_{S_{t+1}}(A) \le (a-1)(2n-(a-1)).$$
  Furthermore, the fill of all cups in $C$ must be at most $1$ at state $I_t$ to be
  less than the fill of the cup in $A$ that zeroed out. Thus, 
  \begin{align*}
      m_{S_{t+1}}(S_{t+1}([k])) & = m_{S_{t + 1}}(AC)\\ 
                                & \le (a-1)(2n-(a-1))+k-a\\
                                &= a(2n-a) +a -2n+a-1 + k -a\\
                                &= a(2n-a) + (k-n) + (a-n) -1\\
                                &< a(2n-a)
  \end{align*}
  as desired. As $k$ increases from $1$ to $n$, $k(2n-k)$ strictly increases (it is a
  quadratic in $k$ that achieves its maximum value at $k=n$).
  Thus $a(2n-a) \le k(2n-k)$ because $a\le k$.
  Therefore,
  $$m_{S_{t+1}}(S_{t+1}([k])) \le k(2n-k).$$
\end{proof}

\begin{clm}
  If no cups in $A$ zero out in round $t$ and $b=0$, then the invariant
  $\mu_{S_{t+1}}(S_{t+1}([k])) \le 2n-k$ holds.
\end{clm}
\begin{proof}
If $b=0$, then $S_{t+1}([k]) = S_t([k])$. 
During round $t$ the emptier removes $a$ units of fill from the cups in $S_t([k])$,
specifically the cups in $A$. The filler cannot have added more than $k$ fill
to these cups, because it can add at most $1$ fill to any given cup. Also, the
filler cannot have added more than $p_t$ fill to the cups because this is the
total amount of fill that the filler is allowed to add. Hence the filler adds
at most $\min(p_t, k) = a+b=a+0=a$ fill to these cups.
Thus the invariant holds:
$$m_{S_{t+1}}(S_{t+1}([k])) \le m_{S_t}(S_t([k]))+a-a \le k(2n-k).$$
\end{proof}

The remaining case, in which no cups in $A$ zero out and $b > 0$ is the most technically interesting.
\begin{clm}
  If no cups in $A$ zero out on round $t$ and $b > 0$, then the invariant
  $\mu_{S_{t+1}}(S_{t+1}([k])) \le 2n-k$ holds.
\end{clm}
\begin{proof}
Because $b>0$ and $a+b \le k$ we have that $a
< k$, and $c = k-a > 0$. Recall that $S_{t+1}([k]) = AC$, so the mass of the
$k$ fullest cups at $S_{t+1}$ is the mass of $AC$ at $S_t$ plus any water added
to cups in $AC$ by the filler, minus any water removed from cups in $AC$ by the
emptier. The emptier removes exactly $a$ units of water from $AC$.
The filler adds no more than $p_t$ units of water to $AC$ (because the filler
adds at most $p_t$ total units of water per round) and the filler also
adds no more than $k = |AC|$ units of water to $AC$ (because the filler adds
at most $1$ unit of water to each of the $k$ cups in $AC$).
Thus, the filler adds no more than $a+b = \min(p_t, k)$ units of water to $AC$.
Combining these observations we have:
\begin{equation}
m_{S_{t+1}}(S_{t+1}([k])) \le m_{S_t}(AC) + b.
\label{eq:emptiereptiessomestufffillerfillssomestuff}
\end{equation}

% This is easy to bound if $m_{S_t}(C) \le m_{S_t}(BC) - b$, because 
% $$m_{S_t}(A) + m_{S_t}(BC)  = m_{S_t}(ABC) \le m_{S_t}([k])$$
% which would imply the invariant for $S_{t+1}$, $k$.
% If $\mu_{S_t}(C)$ is not significantly less than $\mu_{S_t}(BC)$ we have more difficulty.
The key insight necessary to bound this is to notice that larger values for
$m_{S_t}(A)$ correspond to smaller values for $m_{S_t}(C)$ because of the
invariants; the higher fill in $A$ \defn{pushes down} the fill that $C$ can
have. By capturing the pushing-down relationship combinatorially we will achieve the desired inequality.

We can upper bound $m_{S_t}(C)$ by 
\begin{align*}
m_{S_t}(C) & \le \frac{c}{b+c}m_{S_t}(BC) \\
&= \frac{c}{b+c}(m_{S_t}(ABC) - m_{S_t}(A))
\end{align*}
 because
$\mu_{S_t}(C) \le \mu_{S_t}(B)$ without loss of generality by the
interchangeability of cups.
Thus we have 
\begin{align}
  m_{S_t}(AC) &\le m_{S_t}(A) + \frac{c}{b+c}m_{S_t}(BC)\label{eqn:BCdiscounted}\\
  &= \frac{c}{b+c}m_{S_t}(ABC) + \frac{b}{b+c}m_{S_t}(A)\label{eqn:redistributeA}.
\end{align}

Note that the expression in \eqref{eqn:redistributeA} is monotonically
increasing in both $\mu_{S_t}(ABC)$ and $\mu_{S_t}(A)$. Thus, by numerically
replacing both average fills with their extremal values, $2n-|ABC|$ and
$2n-|A|$. At this point the claim can be verified by straightforward (but quite
messy) algebra (and by combining
\eqref{eq:emptiereptiessomestufffillerfillssomestuff} with
\eqref{eqn:redistributeA}). We instead give a more intuitive argument, in which
we examine the right side of \eqref{eqn:BCdiscounted} combinatorially.

 Consider a new configuration of fills $F$ achieved by starting with state
 $S_t$, and moving water from $BC$ into $A$ until $\mu_{F}(A) = 2n-|A|$.
 \footnote{Note that whether or not $F$ satisfies the invariants is
 irrelevant.} This transformation increases (strictly increases if and only if
 we move a non-zero amount of water) the right side of
 \eqref{eqn:BCdiscounted}. In particular, if mass $\Delta \ge 0$ fill is moved
 from $BC$ to $A$, then the right side of \eqref{eqn:BCdiscounted} increases by
 $\frac{b}{b+c} \Delta \ge 0$. Note that the fact that moving water from $BC$
 into $A$ increases the right side of \eqref{eqn:BCdiscounted} formally
 captures the way the system of invariants being proven forces a tradeoff
 between the fill in $A$ and the fill in $BC$---that is, higher fill in $A$
 pushes down the fill that $BC$ (and consequently $C$) can have.

  Since $\mu_F(A)$ is above $\mu_{F}(ABC)$, the greater than average fill of
  $A$ must be counter-balanced by the lower than average fill of $BC$. In
  particular we must have
  $$(\mu_F(A) - \mu_F(ABC))|A| = (\mu_F(ABC) -\mu_F(BC))|BC|.$$
  Note that 
  \begin{align*}
  & \mu_F(A) -\mu_F(ABC) \\
  &= (2n-|A|) - \mu_F(ABC) \\
  &\ge (2n-|A|) - (2n-|ABC|) \\
  &= |BC|.    
  \end{align*}
  Hence we must have 
  $$\mu_F(ABC) - \mu_F(BC) \ge |A|.$$
  Thus 
  \begin{equation}
      \mu_F(BC) \le \mu_F(ABC) - |A| \le 2n-|ABC| -|A|.
      \label{eq:BCispusheddown}
  \end{equation}
  Combing \eqref{eqn:BCdiscounted} with the fact that the transformation from
  $S_t$ to $F$ only increases the right side of \eqref{eqn:BCdiscounted}, along
  with \eqref{eq:BCispusheddown}, we have the following bound:
  \begin{align}
    m_{S_t}(AC)
  &\le m_{F}(A) + c\mu_{F}(BC) \nonumber \\
  &\le a(2n-a) + c(2n-|ABC|-a) \nonumber \\
  &\le (a+c)(2n-a) - c(a+c+b) \nonumber \\
  &\le (a+c)(2n-a-c) - cb. \label{eq:eqnwithcb}
  \end{align}
  
By \eqref{eq:emptiereptiessomestufffillerfillssomestuff} and \eqref{eq:eqnwithcb}, we have that
\begin{align*}
    m_{S_{t+1}}(S_{t + 1}([k])) & \le m_{S_t}(AC) + b \\
                                & \le (a+c)(2n-a-c) - cb + b \\
                                & = k(2n-k) - cb + b \\
                                & \le k(2n-k),
\end{align*}
where the final inequality uses the fact that $c \ge 1$. This completes the proof of the claim. 
  
\end{proof}

We have shown the invariant holds for arbitrary $k$, so given that the
invariants all hold at state $S_t$ they also must all hold at state $S_{t+1}$.
Thus, by induction we have the invariant for all rounds $t\in\mathbb{N}$.
\end{proof}



\section{Oblivious Filler Lower Bound}\label{sec:oblivious}
In this section we prove that, surprisingly, an oblivious filler
can achieve backlog $n^{1-\varepsilon}$, although only against a
certain class of ``greedy-like" emptiers.

% First we highlight the concentration inequalities that we will need in the analysis. 

% The following theorem is known as Hoeffding's Inequality:
% \begin{theorem}
%   Let $X_i$ for $i=1,2,\ldots, k$ be independent bounded random variables with
%   $X_i \in [a,b]$ for all $i$. Then,
%   $$\Pr\left(\Big|\frac{1}{k} \sum_{i=1}^k (X_i - \E[X_i])\Big|\ge t\right) \le
%   2\exp\left(-\frac{2kt^2}{(b-a)^2}\right) $$
% \end{theorem}
% There are also several useful corollaries of Hoeffding's Inequality. 
% Firstly, the Chernoff Bound, i.e. Hoeffding's Inequality applied to binary
% random variables, is a trivial corollary.
% A more interesting corollary is that Hoeffding's Inequality applies to random
% variables drawn without replacement from a finite population.
% Let $S$ be a finite population, let $X_i$ for $i=1,2\ldots, k$ be chosen
% uniformly at random from $S \setminus \{X_1,\ldots, X_{i-1}\}$, and let $Y_i$
% for $i=1,2,\ldots, k$ be chosen uniformly at random from $S$.
% Note that $\{X_1,\ldots, X_k\}$ represents a sample of $S$ chosen without
% replacement, whereas $\{Y_1,\ldots, Y_k\}$ represents a sample with
% replacement. Because the $Y_i$ are independent random variables
% Hoeffding's Inequality provides a bound on the probability of $\sum_{i=1}^k
% Y_i$ deviating from its mean by more than $t$.
% The same bound can be given on the probability of $\sum_{i=1}^k X_i$ deviating
% from its mean by more than $t$, because the probability of $\sum_{i=1}^k X_i$
% deviating from its mean by more than $t$ is at most the probability of
% $\sum_{i=1}^k Y_i$ deviating from it's mean by $t$.
% Formally we can write this as 
% \begin{corollary}
%   \label{cor:hoeffdingwreplacement}
%   Let $S$ be a finite set with $\min(S) \ge a, \max(S) \le b$, and let $X_i$
%   for $i=1,2\ldots, k$ be chosen uniformly at random from $S \setminus
%   \{X_1,\ldots, X_{i-1}\}$.
% Then 
%   $$\Pr\left(\Big|\frac{1}{k} \sum_{i=1}^k (X_i - \E[X_i])\Big|\ge t\right) \le
%   2\exp\left(-\frac{2kt^2}{(b-a)^2}\right) $$
% \end{corollary}
% Hoeffding proved \cref{cor:hoeffdingwreplacement} in his seminal work
% \cite{who62} (the result follows from his Theorem 4, combined with Hoeffding's
% Inequality for independent random variables).
% This result is intuitive as samples drawn without replacement should be more
% tightly concentrated around the mean than samples drawn with replacement, which
% are more free to vary.

% We now proceed with our analysis of oblivious lower bounds.

We call a cup configuration $M$\defn{-flat} if every cup has fill
in $[-M, M]$. We say an emptier is $\Delta$\defn{-greedy-like}
if, whenever there are two cups with fills that differ
by at least $\Delta$, the emptier never empties from the less full
cup without also emptying from the more full cup. That is, if
there are cups $c_1, c_2$ with $\fil(c_1) > \fil(c_2) + \Delta$,
then a $\Delta$-greedy-like emptier doesn't empty from $c_2$ on
this round unless it also empties from $c_1$ on this round.
Note that a perfectly greedy
emptier is $0$-greedy-like. We call an emptier \defn{greedy-like} if it is
$\Delta$-greedy-like for $\Delta \le O(1)$.
In the randomized setting we are only able to prove lower bounds for backlog
against greedy-like emptiers; whether or not our results can be extended to a
more general class of emptiers is an interesting open question. 
Nonetheless, greedy-like emptiers are of great interest because
all the known randomized algorithm for the cup game are
$O(1)$-greedy-like \cite{wku20}\cite{mbe19}.

We now prove a crucial property of greedy-like emptiers: 
\begin{proposition}
  \label{prop:greedylikeisflat}
  Consider an $M$-flat cup configuration in the negative-fill variable-processor cup
  game on $n$ cups with average fill $0$.
  An oblivious filler can achieve a $2(2+\Delta)$-flat configuration of cups against a $\Delta$-greedy-like
  emptier in running time $2M$.
\end{proposition}
\begin{proof}
  The filler sets $p=n/2$ and distributes fill equally amongst
  all cups at every round, placing $1/2$ fill in each cup.
  Let $\ell_t = \min_{c\in S_t} \fil_{S_t}(c)$, $u_t=\max_{c\in S_t} \fil_{S_t}(c)$. Let
  $L_t$ be the set of cups $c$ with $\fil_{S_t}(c) \le l_t+2+\Delta$, and let
  $U_t$ be the set of cups $c$ with $\fil_{S_t}(c) \ge u_t-2-\Delta$.
  
  Note the following regarding $U_t$ (symmetric properties for $L_t$ also hold):\\
  \textbf{Observation 1}: 
  If any cup with fill in $[u_t-\Delta-2, u_t-\Delta-1]$ is emptied from then all cups
  with fills in $[u_t-1, u_t]$ must be emptied from because the emptier is
  $\Delta$-greedy-like. \\
  \textbf{Observation 2}:
  If there are more than $n/2$ cups outside of $U_t$, that is
  cups with fills in $[\ell_t, u_t-2-\Delta]$, then all cups in
  $[u_t-2, u_t]$ must be emptied from because the emptier is
  $\Delta$-greedy-like.

  Now we prove a key property of the sets $U_t$ and $L_t$: once a cup is in
  $U_t$ or $L_t$ it is always in $U_{t'}, L_{t'}$ for all $t' > t$. This
  follows immediately from the following claim:
  \begin{clm}
    \label{clm:dontlosestuff}
    $$U_{t} \subseteq U_{t+1}, L_t \subseteq L_{t+1}.$$
  \end{clm}
  \begin{proof}
    Consider a cup $c\in U_t$.

    If $c$ is not emptied from, i.e. $\fil(c)$ has increased by $1/2$, then
    clearly $c \in U_{t+1}$, because backlog has increased by at most $1/2$, so
    the fill of $c$ must still be within $2+\Delta$ of the backlog on round $t+1$. 

    On the other hand, if $c$ is emptied from, i.e. $\fil(c)$ has decreased by
    $1/2$, we consider two cases.\\
    \textbf{Case 1:} If $\fil_{S_t}(c) \ge u_t-\Delta -1$, then
    $\fil_{S_t}(c)$ is at least $1$ above the bottom of the
    interval defining which cups belong to $U_t$. The backlog
    increases by at most $1/2$ and the fill of $c$ decreases by $1/2$, so
    $\fil_{S_{t+1}}(c)$ is at least $1-1/2-1/2 = 0$ above the bottom of the
    interval, i.e. still in the interval. \\
    % We can also express this in terms
    % of equations: $u_{t+1} \le u_t+1/2$, so
    %   $$\fil_{S_{t+1}}(c) \ge u_t-\Delta-1 - 1/2\ge u_{t+1}-\Delta-2.$$
    \textbf{Case 2:} On the other hand, if $\fil_{S_t}(c) < u_t-\Delta-1$, then every cup
        with fill in $[u_t-1, u_t]$ must have been emptied
        from by Observation 1. The fullest cup at round $t+1$ is the same as the fullest cup on
        round $t$, because the fills of all cups with fill in
        $[u_t-1, u_t]$ have decreased by $1/2$, and no cup with fill less than
        $u_t-1$ had fill increase by more than $1/2$. Hence $u_{t+1} = u_t -1/2$.
        Because both the fill of $c$ and the backlog have both
        decreased by $1/2$, the distance between them is still at
        most $\Delta+2$, hence $c\in U_{t+1}$.\\
    The argument for why $L_t \subseteq L_{t+1}$ is symmetric.
  \end{proof}

  Now that we have shown that $L_t$ and $U_t$ never lose cups, we will show
  that they each eventually gain more than $n/2$ cups:

  \begin{clm}
    \label{clm:smallthenbigger}
    As long as $|U_t| \le n/2$ we have $u_{t+1} = u_t -1/2$. Identically, as
    long as $|L_t| \le n/2$ we have $\ell_{t+1} = \ell_t+ 1/2$.
  \end{clm}
  \begin{proof}
    If there are more than $n/2$ cups outside of $U_t$, then by
    Observation 2, the emptier must empty from
    every cup with fill at least $u_t-2$. Thus $u_{t+1} = u_t -1/2$: no cup
    with fill less than $u_t-2$ could have become the fullest cup, and the
    previous fullest cup has lost $1/2$ units of fill. 

    The proof is symmetric for $L_t$.
  \end{proof}

  By \cref{clm:smallthenbigger} we see that both $|U_t|$ and $|L_t|$ must
  eventually exceed $n/2$ at some times $t_u, t_\ell \le 2M$, by the assumption
  that the initial configuration is $M$-flat. Since by
  \cref{clm:dontlosestuff} $|U_{t+1}|\ge |U_t|$ and $|L_{t+1}|
  \ge |L_t|$, we have that there is some round $t_0 =\max(t_u, t_\ell) \le 2M$ on which both
  $|U_{t_0}|$ and $|L_{t_0}|$ exceed $n/2$. Then $U_{t_0} \cap L_{t_0} \neq
  \varnothing$. Furthermore, the sets must intersect for all $t_0 \le t \le 2M$. 
  In order for the sets to intersect it must be that the intervals
  $[u_t-2-\Delta, u_t]$ and $[\ell_t, \ell_t+2+\Delta]$ intersect. Hence we have that 
  $$\ell_t+2+\Delta \ge u_t-2-\Delta.$$ Since $u_t \ge 0$ and $\ell_t \le 0$
  this implies that all cups have fill in $[-2(2+\Delta), 2(2+\Delta)]$.

\end{proof}

Given a $\Delta$-greedy-like filler, let $R_\Delta = \lceil 2(2+\Delta)
\rceil.$ \footnote{It is convenient to have this be an integer, and there is no
drawback to taking a slightly larger $R_\Delta$ than necessary. In fact, this
value of $R_\Delta$ is already not tight.}
By \cref{prop:greedylikeisflat}, if a filler is given a $M$-flat
configuration of cups they can achieve a $R_\Delta$-flat configuration of cups.

Next we describe a simple oblivious filling strategy that will be used as a
subroutine in \cref{lem:obliviousManyUnknownCups}; this strategy is very
well-known, and similar versions of it can be found in
\cite{ mbe19, mbe15, die91, wku20}.
\begin{proposition}
  \label{prop:obliviousTerribleProbability}
  Consider an $R$-flat cup configuration in the negative-fill
  single-processor cup game on $n$ cups with average fill $0$.
  There is an oblivious filling strategy that
  achieves fill at least $-R + \sum_{i=2}^{n} 1/i$ in a randomly chosen
  cup with probability at least $1/n!$. Further, this filling strategy
  guarantees that the chosen cup has fill at most $R +
  \sum_{i=2}^{n} 1/i$. This filling strategy
  has running time $O(n)$.
\end{proposition}
\begin{proof}
  The filler maintains an \defn{active set}, initialized to being
  all of the cups. Every round the filler distributes $1$ unit of
  fill equally among all cups in the active set. Then the emptier
  removes $1$ unit of fill from some cup. Finally, the filler
  removes a cup uniformly at random from the active set. This
  continues until a single cup $c$ remains in the active set. 
  Consider the probability that $c$ has never been emptied
  from. On the $i$-th step of this process, i.e. when the size of
  the active set is $n-i+1$, consider the cup the emptier empties
  from. If this cup is in the active-set, with probability at
  least $1/(n-i+1)$ the filler removes it from the active set.
  If the cup is not in the active set, then it is irrelevant.
  Hence with probability at least $1/n!$ the final
  cup in the active set, $c$, has never been emptied from.
  In this case, $c$ will have gained fill $\sum_{i=2}^n 1/i$
  as claimed. Because $c$ started with fill at
  least $-R$, $c$ now has fill at least $-R+ \sum_{i=2}^n 1/i$. 

  Further, $c$ has fill at most $R + \sum_{i=2}^n 1/i$ (which
  is achieved if the cup was never emptied from over the course
  of the $O(n)$ rounds, and started with fill $R$). 

\end{proof}

Now we are equipped to prove the following lemma, which shows
that we can force a constant fraction of the cups to have high fill
fill; using this lemma and exploiting the greedy-like nature of
the emptier we can get a known cup with high fill
(we show this in \cref{lem:obliviousBase}).
\begin{lemma}
  \label{lem:obliviousManyUnknownCups}
  Let $\Delta \le O(1)$, let $h \le O(1)$ with $h \ge 16+16\Delta$, let
  $n$ be at least a sufficiently large constant
  determined by $h$ and $\Delta$, and let $M \le \poly(n)$.
  Consider an $M$-flat cup configuration in the negative-fill
  variable-processor cup game on $n$ cups with average fill $0$.
  Let $A$ be a chosen subset of $n/32$ cups, and let $B$ consist
  of the rest of the cups ($|B| = n\cdot 31/32$).

  There is an oblivious filling strategy that makes an unknown
  set of $\Theta(n)$ cups in $A$ have fill at least $h$ with
  probability at least $1-2^{-\Omega(n)}$ in running time
  $\poly(n)$ against a $\Delta$-greedy-like emptier.
  The filling strategy also guarantees that $\mu(B) \ge -h/2$.
\end{lemma}
\begin{proof}
  We refer to $A$ as the \defn{anchor} set, and $B$ as the
  \defn{non-anchor} set.
  Throughout the proof the filler uses $p=|A|+1$.

We denote by \randalg the oblivious single-processor filling
strategy given by \cref{prop:obliviousTerribleProbability}. We
say that the filler \defn{applies} \randalg to a set of cups $D
\subset B$ if the filler uses \randalg on $D$ while placing $1$
unit of fill in each anchor cup. 

We now describe the filler's strategy.

The filler starts by flattening the cups, using the flattening
procedure from \cref{prop:greedylikeisflat}. The filling strategy
always places $1$ unit of water in each anchor cup. The filler
then performs a series of $|A|$ \defn{swapping-processes}, one
per anchor cup, which are procedures that the filler uses to get
a new cup---which will sometimes have high fill---in $A$. On each
swapping-process the filler applies \randalg $|A|\cdot c_\Delta$
times ($c_\Delta=\Theta(1)$ to be specified as a function of
$\Delta$) to arbitrarily chosen constant-size sets $D \subset B$ with $|D| =
\ceil{e^{2h+1}}$. At the start of each swapping-process the
filler chooses a random index $j \in [|A|\cdot c_\Delta]$; on the
$j$-th application of \randalg the filler swaps the cup given
by \randalg with the cup in the anchor set associated with this
swapping-process. Before each application of \randalg the filler flattens $B$. 

We remark that although this construction is somewhat similar to
the construction in \cref{lem:adaptiveAmplification}, there is a
major difference: in the adaptive lower bound construction the
filler halts after achieving the desired average fill in the
anchor set, whereas the oblivious filler cannot halt but rather
must rely on flattening to guarantee that each application of
\randalg has constant probability of generating a cup with high
fill.

We proceed to analyze the algorithm.

We say that the emptier \defn{neglects} the anchor set on a round if it does not empty from each anchor cup. We say that an application
of \randalg to $D\subset B$ is \defn{successful} if the emptier does not
neglect the anchor set during any round of the application. We
define $d = \sum_{i=2}^{|D|} 1/i$ (recall that $|D| =
\ceil{e^{2h+1}}$). Note that by \cref{prop:obliviousTerribleProbability} on any successful
application of \randalg there is a $1/|D|!$ chance of getting a
cup with fill at least $\mu(B) -R_\Delta + d$. We say that a swapping-process is \defn{good} if it swaps a cup with fill at least
$\mu(B)-R_\Delta + d$ into the anchor set.

\begin{clm}
  \label{clm:muBdoesntSinkTooLow}
  Throughout the entire process
  $$\mu(B) \ge -h/2.$$
\end{clm}
\begin{proof}
  %   mu(B) can change in 2 ways:
  %     - neglect; this can only happen if $mu(B)$ isn't so bad
  %     - swaps; this causes a mass change of about $d$ by almost
  %     flatness of $B \cup A\setminus A_0$. $B$ can take it
  %     because it's much bigger than $A$.

  At the start $\mu(B)$ is at least $-R_\Delta |A|/|B|$ due to flattening
  of all of the cups.

  There are two ways that $\mu(B)$ can decrease: $\mu(B)$
  decreases when the emptier neglects the anchor-set, and
  when a good swap occurs. 

  Because the emptier is greedy-like, the emptier must empty from
  a cup $c\in A$ if the fill of $c$ is more than $\Delta$ greater
  than the most full cup in $B$. Within each swapping-process no
  cup in $B$ ever is raised to have fill above $\mu(B) + R_\Delta
  + d$ by \cref{prop:obliviousTerribleProbability} (and because $B$ is flattened before the filler applies \randalg to $B$). Thus, no cup in $A$ has fill greater than $\mu(B) + d + R_\Delta + \Delta$
  must be emptied from. If $\mu(A) \le \mu(B) + d +
  R_\Delta + \Delta$ then
  $$\mu(B) = -\frac{|A|}{|B|}\mu(A) \ge
  -\frac{|A|}{|B|}\left(\mu(B) + d + R_\Delta + \Delta\right).$$
  Rearranging this we have
  $$\mu(B) \ge -\frac{1}{30}(d + R_\Delta + \Delta) \ge -h/4.$$

\end{proof}

\begin{clm}
  \label{clm:emptierCantNeglectAnchorTooMuch}
  The emptier can neglect the anchor set no more than 
  $$r = (1+|A|/|B|)(|D| + 2R_\Delta) + R_\Delta + \Delta$$
  times per swapping-process.
\end{clm}
\begin{proof}
  % mu(A) doesn't sink too low, because it only sinks on swapping
  % processes and those can't be arbitrarily bad for it 
  % thus too much neglect by the emptier violates greedy-likeness

  We claim that $\mu(B)$ does not rise very high, and $\mu(A)$
  does not sink very low. The only time that $\mu(A)$ can
  decrease is due to a swap. Thus, by lower bounding the average
  fill of $A$ and upper bounding the average fill of $B$ we can
  bound the number of times that the emptier can neglect the
  anchor set per swapping-process: emptying more than a certain
  number of times would cause all cups in $A$ to have fill more
  than $\Delta$ higher than the highest cup in $B$, which is
  contrary to the emptier's greedy nature.

  It is clear that $\mu(A) \ge -|D| -2R_\Delta$ always holds,
  as no cup is ever transferred out of $B$ with fill less than
  $\mu(B) - R_\Delta -|D_i|$. Correspondingly we have for
  $\mu(B)$ that $$\mu(B) \le \frac{|A|}{|B|}(|D| + 2R_\Delta).$$

  The emptier can neglect the anchor set no more than $|A|r$
  times because doing so would increase the mass of the anchor
  set by $r$, and consequently make each cup in $A$ have fill
  high enough that the emptier, being $\Delta$-greedy-like would
  be forced to empty from that cup.
  
\end{proof}

\begin{clm}
With probability at least $1-2^{-\Omega(n)}$, the filler achieves fill
at least $h$ in at least $\Theta(n)$ of the cups in $A$. 
\end{clm}
\begin{proof}
  By \cref{prop:obliviousTerribleProbability} using \randalg on
  $|D| = \lceil e^{2h+1} \rceil$ gives the filler a cup that
  has fill at least $\mu(B) + d-R_\Delta$ with probability
  $1/|D|!$. By \cref{clm:muBdoesntSinkTooLow} we have that
  $\mu(B) \ge -h/2$, so with probability $1/|D|!$ this generated
  cup has fill at least $h$ if it wasn't neglected.

  By \cref{clm:emptierCantNeglectAnchorTooMuch} there is a choice
  of $c_\Delta$ large enough that the probability of this cup
  having been neglected is at most $1/2$. In particular, we
  choose $c_\Delta = 4r|D|!$. By applying \randalg $|A|\cdot
  c_\Delta$ times we have by a Chernoff bound that with
  exponentially good probability in $|A|\cdot c_\Delta =
  \Theta(n)$ there are at least $2|A|r$ applications where the
  filler would succeed if the emptier doesn't neglect the anchor
  set. As shown, the emptier cannot
  neglect the anchor set more than $|A|r$ times. Hence, there
  is at least a $(1/2)/|D|!$ chance that on the $j$-th
  application of \randalg the emptier doesn't neglect the anchor
  set and the filler correctly guesses the emptier's emptying
  sequence. Thus, overall, there is at least a constant
  probability of achieving fill $h$ in a cup in $A$.

  Say that a swapping-process is \defn{victorious} if the filler
  is able to swap a cup with fill at least $h$ into $A$. The
  events that swapping-processes are victorious are independent
  events; each happens with constant probability. Hence by a
  Chernoff bound with exponentially good probability in $n$ at
  least a constant fraction of them succeed, as desired.

\end{proof}

We now briefly analyze the running time of the filling strategy.
There are $|A|$ swapping-processes. Each swapping-process
consists of $|A|\cdot c_\Delta$ applications of \randalg, and
the flattening procedure before each application. 
Clearly this all takes $\poly(n)$ time, as desired.
  
\end{proof}

Finally, using \cref{lem:obliviousManyUnknownCups} we can show in
\cref{lem:obliviousBase} that an oblivious filler can achieve
constant backlog. We remark that \cref{lem:obliviousBase} plays a
similar role in the proof of the lower bound on backlog as
\cref{prop:adaptiveBase} does in the adaptive case, but is vastly
more complicated to prove (in particular,
\cref{prop:adaptiveBase} is trivial).
\begin{lemma}
  \label{lem:obliviousBase}
  Let $H \le O(1)$, let $\Delta \le O(1)$, let $n$ be at
  least a sufficiently large constant determined by $H$ and
  $\Delta$, and let $M \le \poly(n)$. 
  Consider an $M$-flat cup configuration in the negative-fill variable-processor cup
  game on $n$ cups with average fill $0$.
  Given this configuration, an oblivious filler can achieve fill $H$
  in a chosen cup in running time $\poly(n)$ against a
  $\Delta$-greedy-like emptier with probability at least $1-2^{-\Omega(n)}.$
\end{lemma}
\begin{proof}
  The filler starts by performing the procedure detailed in
  \ref{lem:obliviousManyUnknownCups}, using $h = H\cdot
  16(1+\Delta)$. Let the number of cups which must now exist with
  fill $h$ be of size $nc = \Theta(n)$.

  The filler reduces the number of processors to $p=nc$. 
  Now the filler exploits the filler's greedy-like nature to
  to get fill $H$ in a set $S\subset B$ of $nc$ chosen cups.

  The filler places $1$ unit of fill into each cup in $S$.
  Because the emptier is greedy-like it must focus on the $nc$
  cups in $A$ with fill at least $h$ until the cups in $S$ have
  sufficiently high fill. In particular, $(5/8)h$ rounds suffice.
  Over $(5/8)h$ rounds the $nc$ high cups in $A$ cannot have
  their fill decrease below $(3/8)h \ge h/8 + \Delta$. Hence, any
  cups with fills less than $h/8$ must not be emptied from during
  these rounds. The fills of the cups in $S$ must start
  as at least $-h/2$. After $(5/8)h$ rounds the fills of the cups
  in $S$ are at least $h/8$, because throughout this process the
  emptier cannot have emptied from them until they got fill at
  least $h/8$, and if they are never emptied from then they
  achieve fill $h/8$.

  Thus the filling strategy achieves backlog $h/8 \ge H$ in some
  known cup (in fact in all cups in $S$, but a single cup
  suffices), as desired.

\end{proof}

Next we prove the \defn{Oblivious Amplification Lemma}. The idea
is quite similar to that of the Adaptive Amplification Lemma, but the 
proof is somewhat more complicated because the filler is oblivious.
\begin{lemma}[Oblivious Amplification Lemma]
  \label{lem:obliviousAmplification} 
  Let $0 < \delta \ll 1/2, 1/2\ll \phi < 1$ be constant
  parameters, and let $\eta \in \mathbb{N}$ be a function of $\phi$. 
  Let $\Delta \le O(1)$, $M, M' \ge R_\Delta$. 
  Let $\alg{f}$ be an oblivious filling strategy that achieves
  backlog $f(n)$ in the negative-fill variable-processor cup game
  on $n$ cups with probability at least $1-2^{-\Omega(n)}$ in
  running time $T(n) \le \poly(n)$ when given a $M$-flat
  configuration, against a $\Delta$-greedy-like emptier.

  There exists an oblivious filling strategy $\alg{f'}$ that
  achieves backlog $f'(n)$ satisfying 
  $$f'(n) \ge (1-\delta)(\phi-1/(\delta n)) (f(\floor{(1-\delta)n})-R_\Delta) + f(\ceil{\delta n})$$ 
  and $f'(n) \ge f(n)$, in the negative-fill
  variable-processor cup game on $n$ cups with probability at
  least $1-2^{-\Omega(n)}$ in running time $$T'(n) \le O(M') +
  6 \delta n^{\eta+1} T(\floor{(1-\delta)n}) + T(\ceil{\delta n})$$
  when given a $M'$-flat configuration of cups against a
  $\Delta$-greedy-like emptier.
\end{lemma}
\begin{proof}
The algorithm defaults to using $\alg{f}$ on all the cups if doing
so results in greater backlog than the strategy that we will
outline in the rest of the proof; in this case applying $\alg{f}$
to all the cups trivially achieves the desired backlog in the
desired running time. We now outline the filler's strategy if this is not the case.

  The filler starts by flattening all the cups, using the flattening procedure
  detailed in \cref{prop:greedylikeisflat}. 

  Let $A$, the \defn{anchor} set, be a subset of $\ceil{\delta n}$ cups
  chosen arbitrarily, and let $B$, the \defn{non-anchor} set,
  consist of the rest of the cups ($|B| = \floor{(1-\delta)n}$). Note
  that the average fill of $A$ and $B$ both must start as at
  least $-R_\Delta$ due to the flattening. 

  The filler's strategy is essentially as follows:\\
  \textbf{Step 1:} Using $\alg{f}$ repeatedly on $B$, achieve a
  cup with fill $\mu(B) + f(|B|)$ in $B$ and then swap this cup into $A$. \\
  \textbf{Step 2:} Use $\alg{f}$ once on $A$ to obtain a cup in
  $A$ with fill $\mu(A) + f(|A|)$.\\
  Note that in order to use $\alg{f}$ on subsets of the cups the filler will need to vary $p$.

  We now describe how to achieve Step 1, which is complicated by
  the fact that the emptier may attempt to prevent the filler
  from achieving high fill in a cup in $B$, and further by the
  fact that the filler, being oblivious, can not know if the
  emptier has done this. In particular, Step 1 may not succeed
  time, but we show that with exponentially good probability is
  works almost every time.

  The filler's strategy will be to always place $1$ fill in each cup in the
  anchor-set while applying $\alg{f}$ to $B$.

  For each cup in $A$ the filler performs a procedure called a
  \defn{swapping-process}. Let $A_0$ be initialized to
  $\varnothing$; during each swapping-process the filler will get
  some cup in $B$ to have high fill (with very good probability),
  and then swap this cup into $A$, and place the cup in $A_0$ too.
  We say that the filler \defn{applies}
  $\alg{f}$ to $B$ if it follows the filling strategy $\alg{f}$ on
  $B$ while placing $1$ unit of fill in each anchor cup; during a
  swapping-process the filler repeatedly applies $\alg{f}$ to $B$,
  flattening $B \cup (A\setminus A_0)$ and then flattening $B$
  too before each application.
  We say that the emptier \defn{neglects} the anchor set on a
  round if the emptier does not empty from every anchor cup on
  this round. The mass of the anchor set increases by at least
  $1$ each round that the anchor set is neglected. An application
  of $\alg{f}$ to $B$ is said to be \defn{successful} if $A$ is
  never neglected during the application of $\alg{f}$ to $B$. We
  say that a swapping-process is \defn{successful} if the application of
  $\alg{f}$ on which the filler swaps a cup into $A$ is a
  successful application of $\alg{f}$.

  Let $\mu_\Delta = 2R_\Delta + \Delta$; the emptier, being
  $\Delta$-greedy-like, cannot neglect the anchor set more than
  $n\delta\mu_\Delta$ times. Thus, by making each
  swapping-process consist of $n^{\eta}$ applications of $\alg{f}$
  to $B$ and then choosing a single application among these
  (uniformly at random) after which to swap a cup into $A$ (and
  we also place the cup in $A_0$; $A_0$ consists of all cups in
  $A$ that were swapped into $A$ from $B$), we guarantee that
  with probability at least $n\delta\mu_\Delta/n^{\eta}$ this swap
  occurs at the end of a successful application of $\alg{f}$ to $B$. 

  If an application of $\alg{f}$ is successful, then with
  probability at least $1-2^{-\Omega(n)}$ it generates a cup with
  fill $f(|B|) + \mu(B)$ in $B$, because equal resources were put
  into $B$ on each round while $\alg{f}$ was used, and the cup
  state started as $R_\Delta$-flat (relative to $\mu(B)$) and
  hence also started as $M$-flat (as $M\ge R_\Delta$).

  Now we aim to show that $\mu(A)$ is large; we do so by showing
  that $\mu(B)$ is small (i.e. very negative). Because the
  probability of an application of $\alg{f}$ being successful is
  only $1-1/\poly(n)$, which is in particular not as good as the
  $1-2^{-\Omega(n)}$ that we will guarantee, we will not be able
  to actually assume that every such application of $\alg{f}$ is
  successful. However, (as we will show later) we can guarantee
  that at least a constant fraction $\phi$ of the
  swapping-processes are successful with
  exponentially good probability.

  The filler swaps $\delta n$ cups into $B$. 
  Consider how $\mu(B \cup A\setminus A_0)$ changes when a new
  cup is swapped into $A$ and placed in $A_0$. Let initial value
  of $\mu(B \cup A\setminus A_0)$ be $\mu_0$. Say that
  initially $|A_0| = i$ (i.e. $i$ swapping processes have occured
  so far). If the swapping-process is successful then the swapped cup has
  fill at least $\mu_0 - R_\Delta + f(|B|)$. Hence the new
  average fill of $B \cup A\setminus A_0$ after the swap is
  $$\frac{\mu_0\cdot (n-i) - (\mu_0 - R_\Delta + f(|B|))}{n-i-1} =
  \mu_0 - \frac{f(|B|) - R_\Delta}{n-i-1}.$$
  This recurrence relation allows us to find the value of
  $\mu(B \cup A\setminus A_0) = \mu(B)$ after $|A|$ swapping
  processes (i.e. once $A\setminus A_0 = \varnothing$):
  $$\mu(B) \le -\sum_{i=1}^{|A|\phi} \frac{f(|B|)-R_\Delta}{n-i}.$$
  Now we bound $H_{n-1} - H_{n-|A|\phi-1}$ where $H_i$ is the $i$-th harmonic number.
  Using the fact that 
  $$H_n = \ln n + \gamma + 1/(2n) - 1/(12 n^2) + 1/(120 n^4) - \ldots$$
  we have,
  \begin{align*}
    &H_{n-1} - H_{n-|A|\phi-1}\\
  &\ge \ln \frac{n-1}{n-|A|\phi-1} - \frac{1}{2(n-|A|\phi-1)}\\
  &\ge \ln \frac{n}{n-|A|\phi} - \frac{1}{n}\\
  &= \ln \frac{n}{n-\ceil{\delta n}\phi} - \frac{1}{n}\\
  &\ge \ln \frac{1}{1-\delta\phi} - \frac{1}{n}\\
  &\ge \delta\phi - \frac{1}{n}.
  \end{align*}

  Hence we have, 
  \begin{equation}
    \label{eq:nastyobliviousamplificationlemmastep1backlog}
  \mu(A) \ge
  \frac{(1-\delta)}{\delta}\paren{\delta\phi-\frac{1}{n}}(f(|B|)-R_\Delta).
  \end{equation}

  % {\color{red} 
  % so we're going to go for a new amplification lemma here that looks something like 

  % $$f'(n) \ge (1-\delta)^4 f(\floor{(1-\delta)n}) + f(\ceil{\delta n}).$$
  % In order to get this we choose $\phi \ge 1-\delta$ and 
  % make sure that $n\ge \delta^2$ and that $f(|B|) \ge
  % R_\Delta/\delta$ (note: this requires getting more than $1$
  % backlog in the base case, but still constant, so it's fine).

  % The asymptotic analysis still works out; it looks basically
  % like this: $$(1-\delta)^4c((1-\delta)n)^{1-\varepsilon} + c(\delta
  % n)^{1-\varepsilon} \ge cn^{1-\varepsilon}(1-(5-\varepsilon)\delta +
  % \delta^{1-\varepsilon}) \ge cn^{1-\varepsilon}$$ for sufficiently
  % small $\delta$.

  % This is pretty much what has to happen. It's not so bad.
  % so long as $f(\floor{(1-\delta)n}) \ge R_\Delta/\delta$ and $n\ge 1/\delta^2$
  % }

  % For sake of simplicity, assume for a moment that the cups in
  % $A$ start having $0$ fill, and that the emptier never
  % neglects $A$. Then, each swapping-process results in a cup
  % with fill $\mu(B)+ f(|B|)$ being swapped from $B$ with a cup
  % in $A$ that has $0$ fill; hence here the average fill of $B$
  % decreases from $\mu(B)$ to 
  % $$\frac{|B|-1}{|B|} \mu(B) + f(|B|) / |B|.$$
  % We start with $\mu(B)=0$, and list a sequence of lower bounds for $\mu(B)$ after a few swaps into $A$:
  % $$0, -\frac{f(|B|)}{|B|}, -\frac{f(|B|)}{|B|} \left(\frac{|B|-1}{|B|} +1 \right),$$
  % $$-\frac{f(|B|)}{|B|} \left(\left(\frac{|B|-1}{|B|}\right)^2 + \frac{|B|-1}{|B|} +1 \right).$$
  % Continuing on for $|A|$ swaps we find that by the end of this process $\mu(B)$ is at most 
  % $$-\frac{f(|B|)}{|B|}\left( \frac{\left(\frac{|B|-1}{|B|}\right)^{|A|}- 1}{\frac{|B|-1}{|B|} - 1} \right) \ge -\frac{|A|}{|B|}f(|B|).$$
  % Hence every cup ever swapped into $A$ has fill at least
  % least
  % \begin{align*}
  % -\frac{|A|}{|B|}f(|B|) + f(|B|) &\\
  % &= -\frac{\ceil{\delta n}}{\floor{(1-\delta) n}} f(|B|) + f(|B|) \\
  % &\ge (1-\delta/(1-\delta)) f(|B|) \\
  % &= h.
  % \end{align*}

  % If, in which case the mass
  % transfered from $B$ to $A$ would be $\delta n f((1-\delta) n)$.
  % In order for their to be an increase in the difference of the
  % average fills of $A$ and $B$ by this amount $B$ would have had
  % to contribute $|A|/n = \delta$ of the difference, with $A$
  % contributing $|B|/n=(1-\delta)$ of the difference. Hence the
  % average fill of $A$ would have actually only increased by
  % $(1-\delta) f((1-\delta)n)$.

  Now we establish that we can guarantee that $\phi |A|$ of the
  $|A|$ swapping-process succeed for any choice of $\phi =
  \Theta(1)$ by sufficiently large choice of $\eta$, i.e. by performing
  enough applications of $\alg{f}$ within each swapping-process.
  Recall that by construction of $\mu_\Delta$ the emptier cannot
  neglect the anchor set on more than $n\delta \mu_\Delta$
  applications of $\alg{f}$ to $B$. 
  %There are $n^\eta |A| \ge n^{\eta+1}\delta$ applications of $\alg{f}$ to $B$. 

  Let $X_i$ be the random variable that indicates the event that
  the $i$-th swapping-process was not successful; note that the
  $X_i$ are independent, because the filler's random choices of
  which applications of $\alg{f}$ within each swapping-process on
  which to swap a cup into the anchor set are independent.
  We have, for any constant $\phi$,
  % {\color{red} OK, so this part is a bit messed up. It's the right idea, but as it stands it's not doing so good. Specifically, here is what's messed up with what I'm doing here: a) events aren't independent, b) emptier can force a specific swapping-process to fail with higher probability. maybe a and b are fixable by bloating $\eta$.}
  \begin{align*}
  \Pr\left[\left|\frac{1}{|A|}\sum_{i=1}^{|A|}X_i - \frac{n\delta\mu_\Delta}{n^{\eta}}\right| \ge 1-2\phi \right] 
  &\le 2e^{-2|A|(1-2\phi)^2} \\
  &\le 2^{-\Omega(n)}.
  \end{align*}
  By appropriately large choice for $\eta \le O(1)$, $$n\delta\mu_\Delta / n^\eta
  \le \phi$$ no matter how small $w \ge \Omega(1)$ is chosen. In particular this
  implies that $$\Pr\left[\sum_{i=1}^{|A|} X_i \ge |A|(1-\phi)\right] \ge 1-2^{\Omega(n)}.$$
  That is, with exponentially good probability $|A|\phi$ of the swapping processes succeed.
  Taking a union bound over all applications of $\alg{f}$ we have
  that there is exponentially good probability that all
  applications of $\alg{f}$ succeeded. Thus, with exponentially
  good probability, by \eqref{eq:nastyobliviousamplificationlemmastep1backlog}, Step 1 achieves
  backlog $$(1-\delta)(\phi-1/(\delta n)(f(\floor{(1-\delta)n}-R_\Delta)$$

  % This is essentially the backlog that we aimed to achieve in $A$, however, 
  % It is almost clear that the desired backlog is achieved; if every swapping
  % process succeeded then we would achieve fill $(1-\delta)
  % f((1-\delta)\delta^\ell n)$ in each cup in the anchor set at each level of
  % recursion hence achieving backlog $$(1-\delta)\sum_{\ell=0}^L
  % f(n\delta^\ell(1-\delta))$$ overall. However each swapping process has some
  % (very small) probability of failing; we computed probability of failure this
  % to be at most $\delta \mu_\Delta / n^\eta.$ Consider the probability that
  % more than a constant fraction $w = \Theta(1)$ of the $s = \sum_{\ell=0}^L
  % n\delta^{\ell+1}$ swapping-processes fail. Let $X_i$ be the random variable
  % indicating whether the $i$-th swapping-process succeeds (note: this is
  % swapping-processes on all levels of recursion), and let $X=\sum_{i=1}^s X_i$.
  % Clearly $\E[X] = s(1-\delta\mu_\Delta/n^\eta)$. Success of the
  % swapping-processes are not independent events: a swapping-process is in-fact
  % more likely to succeed given that previous swapping-processes have failed.
  % Hence we can upper bound the probability of more than a $w$-fraction of the
  % swapping-processes failing by a Chernoff Bound: $$\Pr\left(\frac{1}{s}X \ge
  % \frac{1}{s}\E[X] - w/2\right) \ge 1-2e^{-s w^2/2} \ge 1-2^{\Omega(n)}$$ By
  % appropriately large choice for $\eta \le O(1)$, $$\delta\mu_\Delta /n^\eta
  % \le w/2$$ no matter how small $w \ge \Omega(1)$ is chosen. In particular this
  % implies that $\Pr[X \ge s(1-w)] \ge 1-2^{\Omega(n)}$.

  % Now we will define $\phi$ such that success of $s(1-w)$ of the
  % swapping-processes guarantees backlog $$\phi \cdot (1-\delta) \sum_{\ell=0}^L
  % f(n\delta^\ell(1-\delta)).$$ In the worst case the failed swapping-processes
  % bring very negative cups into the anchor-set, potentially as negative as
  % $-\delta f((1-\delta)\delta^\ell n)$ on the $\ell$-th level of recursion.
  % However, clearly this is equivalent to removing at most $2$ cups worth of
  % mass from the anchor set. Overall we thus remove at most $2w$ cups worth of
  % mass from the anchor set. Hence choosing $\phi = 1-2w$ works.
  % Noting that the constant $w > 0$ was arbitrary we have that $\phi$ can be
  % made any constant arbitrarily close to $1$.

  % In order to achieve this backlog however, not only does the filler need to be
  % able to swap over $s(1-w)$ cups on rounds where the emptier neglects the
  % anchor set, but no applications of $f$ can fail; failure happens with
  % probability $2^{-n\delta^\ell(1-\delta) q}$ for an application of $f$ to
  % $n\delta^\ell(1-\delta)$ cups. Taking a union bound over the $\poly(n)$
  % applications of $f$ clearly still gets probability failure at most
  % $2^{-\Omega(n)}$.

  To achieve Step 2 the filler simply applies $\alg{f}$ to $A$.
  This clearly achieves backlog 
  $$f(|A|) = f(\ceil{\delta n})$$
  with exponentially good probability.
 
  Since both Step 1 and Step 2 succeed with exponentially good
  probability, the entire process succeeds with exponentially
  good probability.

  We now analyze the running time of $\alg(f')$.
  The initial smoothing takes time $O(M')$. Step 1 entails
  $n^{\eta}\cdot (n\delta)$ swapping-processes, each of which
  takes time $f(|B|)$. Due to flattening at the beginning of each
  application of $\alg{f}$ the running time may be increased by a
  multiplicative factor of at most $6$. Step 2 takes time
  $T(|A|)$. Adding these times we have that the running time
  $T'(n)$ of $\alg{f'}$ is
  $$T'(n) \le O(M') + 6 \delta n^{\eta+1} T(\floor{(1-\delta)n}) + T(\ceil{\delta n}).$$

  Having proved that $\alg{f'}$ achieves the desired backlog
  with the desired probability in the desired running time, the
  proof is now complete.

\end{proof}

Finally we prove that an oblivious filler can achieve backlog
$n^{1-\varepsilon}$. 
% in the variable-processor cup game on $n$ cups, where $\varepsilon = \Theta(1)$ 
The proof is very similar to the proof of
\cref{thm:adaptivePoly}, but more complicated because in the
oblivious case we must guarantee that the result holds with good
probability, and also more complicated because the Oblivious
Amplification Lemma is more complicated than the Adaptive
Amplification Lemma. We remark that it is quite remarkable that
an oblivious filler is still able to achieve $\poly(n)$ backlog, just as
an adaptive filler can, because intuitively being oblivious is a
large disadvantage.

\begin{theorem}
  \label{thm:obliviousPoly}
  There is an oblivious filling strategy for the
  variable-processor cup game on $n$ cups that achieves backlog
  at least $\Omega(n^{1-\varepsilon})$ for any constant $\varepsilon
  >0$ in running time $2^{O(\log^2 n)}$ with probability at least
  $1-2^{-\Omega(n)}$ against any $\Delta$-greedy-like emptier for
  $\Delta \le O(1)$.
\end{theorem}
\begin{proof}
  Take constant $\varepsilon \in (0, 1/2)$.
  We aim to achieve backlog $(n/n_b)^{1-\varepsilon}-1$ for some constant $n_b$ on $n$ cups.
  Let $\delta, \phi$ be constants, chosen as functions of $\epsilon$.

  By \cref{lem:obliviousBase} there is an oblivious filling
  strategy that achieves backlog $\Omega(1)$ on $n$ cups with
  exponentially good probability in $n$; we call this algorithm
  $\alg{f_0}$.
  However, unlike in the proof of \cref{thm:adaptivePoly}, we
  obviously cannot use the base case with a constant number of
  cups: doing so would completely destroy our probability of
  success! Because the running time of our algorithm will be
  $2^{\polylog(n)}$, we will be required to take a union bound
  over $2^{\polylog(n)}$ events. By making the size of our base
  case $n_b = \polylog(n)$ we get that the probability of the
  algorithm failing in the base case is at most
  $2^{-\polylog(n)}$. Then, taking a union bound over
  $2^{\polylog(n)}$ events can give us the desired probability.
  By \cref{lem:obliviousBase} $\alg{f_0}$ achieves backlog
  $f_0(k) \ge H \ge \Omega(1)$ for all $k \ge n_b$, for some
  constant $H \ge \Omega(1)$ to be determined ($H$ is a function
  of $\delta$).

  Then we construct $f_{i+1}$ as the amplification of $f_i$ using
  \cref{lem:obliviousAmplification}.

  Define a sequence $g_i$ as 
  $$g_i =
  \begin{cases}
    n_b\ceil{16/\delta}, & i=0\\
    \floor{ g_{i-1}/(1-\delta) }, & i\ge 1 
  \end{cases}.$$

  We claim the following regarding our construction:
  \begin{clm}
    \label{clm:fikinductionagain}
    \begin{equation}
      f_i(k) \ge (k/n_b)^{1-\varepsilon} - 1 \text{ for all } k \le g_i. \label{eqn:fikinductionAGAIN}
    \end{equation}
  \end{clm}
  \begin{proof}
  We prove \cref{clm:fikinductionagain} by induction on $i$. 

  First we derive a simpler (more loose) form of the lower bound
  on $\alg{f'}$'s backlog in terms of $\alg{f}$'s backlog that
  hold if  $\floor{(1-\delta)n} \ge n_b$. We choose $n_b=
  \polylog(n)$ making $n_b > 1/\delta^2$ and hence also $\delta >
  1/(\delta n_b)$; this means that there is a choice of $\phi \in
  (1/2, 1)$ making $\phi - 1/(\delta n_b) > 1-\delta$. Note that
  for any $n\ge n_b$ this same $\phi$ satisfies $$(1-\delta) \le
  \phi - \frac{1}{\delta n_b} \le \phi - \frac{1}{ \delta n}.$$
  We choose $\phi = 1-\delta + 1/(\delta n_b)$. Further, we
  choose $H \ge \Omega(1)$ to make $$ H - R_\Delta \ge
  (1-\delta)H.$$ This ensures that $$f_0(\floor{(1-\delta) n}) -
  R_\Delta \ge (1-\delta)f_0(\floor{(1-\delta)n})$$ so long as
  $\floor{(1-\delta)n} \ge n_b$. Combining this, we have that if
  $\floor{(1-\delta)n}\ge n_b$ then 
  \begin{equation}
    \label{eq:simpleramplemmaobliviousforthmpf}
  f'(n) \ge (1-\delta)^3 f(\floor{(1-\delta)n}) + f(\ceil{\delta n}).
  \end{equation}
  We also choose $H$ large enough so that $H \ge
  (g_0/n_b)^{1-\epsilon}-1 = \ceil{16/\delta}^{1-\epsilon}-1$.

  When $i=0$, the base case of our induction,
  \eqref{eqn:fikinductionAGAIN} is trivially true as
  $(k/n_b)^{1-\epsilon} - 1 \le H$ by definition of $H$ for $k\le g_0$.

  Assume \eqref{eqn:fikinductionAGAIN} for $f_i$, consider $f_{i+1}$. 

  Note that, by design of $g_i$, if $k \le g_{i+1}$ then $\floor{k\cdot (1-\delta)} \le g_i$.
  Consider any $k\in [g_{i+1}]$. 

  First we deal with the trivial
  case where $k \le g_0$. In this case
  $$f_{i+1}(k) \ge f_i(k) \ge \cdots \ge f_0(k) \ge (k/n_b)^{1-\varepsilon} -1.$$

  Now we consider $k \ge g_0$. Note that in this case $\floor{(1-\delta)k} \ge n_b$.
  Since $f_{i+1}$ is the amplification of $f_i$, and $k$ is sufficiently large, we have by \eqref{eq:simpleramplemmaobliviousforthmpf} that
  $$f_{i+1}(k) \ge (1-\delta)^3 f_i(\floor{(1-\delta)k}) + f_i(\ceil{\delta k}).$$
  By our inductive hypothesis, which applies as $\ceil{\delta k}\le g_i, \floor{k\cdot (1-\delta)} \le g_i$, we have
  $$f_{i+1}(k) \ge (1-\delta)^3 (\floor{(1-\delta)k/n_b}^{1-\varepsilon}-1) + \ceil{\delta k/n_b}^{1-\varepsilon} - 1. $$
  Dropping the floor and ceiling, incurring a $-1$ for dropping the floor, we have
  $$f_{i+1}(k) \ge (1-\delta)^3 (((1-\delta)k/n_b-1)^{1-\varepsilon}-1) + (\delta k/n_b)^{1-\varepsilon} - 1.$$
  Because $(x-1)^{1-\varepsilon} \ge x^{1-\varepsilon} -1$, due to the
  fact that $x\mapsto x^{1-\varepsilon}$ is a sub-linear
  sub-additive function, we have 
  $$f_{i+1}(k) \ge (1-\delta)^3 (((1-\delta)k/n_b)^{1-\varepsilon}-2) + (\delta k/n_b)^{1-\varepsilon}-1.$$
  Moving the $(k/n_b)^{1-\varepsilon}$ to the front we have
  $$ f_{i+1}(k) \ge (k/n_b)^{1-\varepsilon} \cdot\left((1-\delta)^{4-\varepsilon} + \delta^{1-\varepsilon} - \frac{2(1-\delta)^3}{(k/n_b)^{1-\varepsilon}} \right) -1.$$
  Because $(1-\delta)^{4-\varepsilon} \ge 1-(4-\varepsilon)\delta$, a fact called Bernoulli's Identity, we have
  $$f_{i+1}(k) \ge (k/n_b)^{1-\varepsilon} \cdot\left(1-(4-\varepsilon)\delta + \delta^{1-\varepsilon} - \frac{2(1-\delta)^3}{(k/n_b)^{1-\varepsilon}} \right)-1.$$
  Of course $-2(1-\delta)^3 \ge -2$, so 
  $$f_{i+1}(k) \ge (k/n_b)^{1-\varepsilon} \cdot\left(1-(2-\varepsilon)\delta + \delta^{1-\varepsilon} - 2/(k/n_b)^{1-\varepsilon} \right) -1.$$
  Because $$-2/(k/n_b)^{1-\varepsilon} \ge -2/(g_0/n_b)^{1-\varepsilon} \ge
  -2(\delta/16)^{1-\varepsilon} \ge -\delta^{1-\varepsilon}/2,$$
  which follows from our choice of $g_0 = \ceil{8/\delta} n_b$ and the restriction
  $\varepsilon<1/2$, we have 
  $$f_{i+1}(k) \ge (k/n_b)^{1-\varepsilon} \cdot\left(1-(4-\varepsilon)\delta + \delta^{1-\varepsilon} - (1/2)\delta^{1-\varepsilon} \right)-1.$$
  Finally, combining terms we have
  $$f_{i+1}(k) \ge  (k/n_b)^{1-\varepsilon} \cdot\left(1-(4-\varepsilon)\delta + (1/2)\delta^{1-\varepsilon}\right)-1. $$

  Because $\delta^{1-\varepsilon}$ dominates $\delta$ for
  sufficiently small $\delta$, there is a choice of
  $\delta=\Theta(1)$ such that 
  $$1-(4-\varepsilon)\delta + (1/2)\delta^{1-\varepsilon} \ge 1.$$ 
  Taking $\delta$ to be this small we have,
  $$f_{i+1}(k) \ge (k/n_b)^{1-\varepsilon}-1,$$
  completing the proof. 
  \end{proof}

  The sequence $g_i$ is $n_b$ times the sequence $g_i$ from
  the proof of \cref{thm:adaptivePoly}; we thus have that $g_{i_*}
  \ge n$ for some $i_* \le O(\log n)$.
  Hence $\alg{f_{i_*}}$ achieves backlog 
  $$f_{i_*}(n) \ge (n/n_b)^{1-\varepsilon}-1.$$
  As $n_b \le \polylog(n)$ we have
  $$f_{i_*}(n) \ge \Omega(n^{1-\varepsilon}),$$ as desired.

  Let the running time of $f_i(n)$ be $T_i(n)$. From the Amplification Lemma we have following recurrence bounding $T_i(n)$:
  \begin{align*}
    T_i(n) &\le 6n^{\eta+1} \delta \cdot T_{i-1}(\floor{(1-\delta)n}) +
  T_{i-1}(\ceil{\delta n}) \\
  &\le 7n^{\eta+1}T_{i-1}(\floor{(1-\delta)n}).
  \end{align*}
  It follows that $\alg{f_{i_*}}$, recalling that $i_* \le O(\log n)$, has running time
  $$T_{i_*}(n) \le (7n^{\eta+1})^{O(\log n)} \le 2^{O(\log^2 n)}$$
  as desired.

  As noted, because the running time is $2^{\polylog(n)}$ and the
  base case size is $n_b\ge \polylog(n)$, a union bound
  guarantees the probability of success is at least
  $1-2^{-\polylog(n)}$.
\end{proof}

% Im not sure this is true anymore:
% \section{oblivious lower bound part 2}
% in fact, our results (probably) even hold for $\Delta \le O(\log \log n)$
% you just need to modify the proposition, the lemma doesn't care too much
% modify the proposition to *only need one of them to succeed*.

\section{Conclusion}
Many important open questions remain open. Can our oblivious cup game results
be improved, e.g. by expanding them to apply to a broader class of emptiers?
Can the classic oblivious multi-processor cup-game be tightly analyzed?
These are interesting questions.

\bibliographystyle{plain}
\bibliography{paper}
\end{document}
