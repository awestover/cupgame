\documentclass[twocolumn]{article}[11pt]
\usepackage[left=1in, right=1in, top=1in, bottom=1in]{geometry}

\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{xcolor}

\newcommand{\defn}[1]{{\textit{\textbf{\boldmath #1}}}}
\renewcommand{\paragraph}[1]{\vspace{0.09in}\noindent{\bf \boldmath #1.}} 
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\Var}{\text{Var}}
\DeclareMathOperator{\img}{Im}
\DeclareMathOperator{\polylog}{\text{polylog}}
\DeclareMathOperator{\poly}{\text{poly}}
\DeclareMathOperator{\st}{\text{ such that }}
\DeclareMathOperator{\tilt}{\text{tilt}}
\DeclareMathOperator{\fil}{\text{fill}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\newcommand{\contr}[0]{\[ \Rightarrow\!\Leftarrow \]}
\newcommand{\defeq}{\vcentcolon=}
\newcommand{\eqdef}{=\vcentcolon}

\newtheorem{fact}{Fact}
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}
\newtheorem{proposition}{Proposition}
\newtheorem{clm}{Claim}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{theorem}{Theorem}
\newtheorem{conjecture}{Conjecture}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}
\fancyfoot[R]{\thepage}
\renewcommand{\headrulewidth}{0pt}

\title{Variable-Processor Cup Games}
\author{Alek Westover}

\begin{document}
\maketitle

\section{Introduction}
The cup game is a classic game in computer science that models work-scheduling.
In the cup game a filler and an emptier take turns adding and removing water
(i.e. work) to the cups. We investigate a variant of the vanilla multiprocessor
cup game which we call the \defn{variable-processor cup game} in which the
filler is allowed to change the number of processors $p$ (the amount of water
that the filler can add and the number of cups from which the emptier can
remove water. This is a natural extension of the vanilla multi-processor cup
game to when the resources available are variable. Note that although the
restriction that the filler and emptier's resources vary together may seem
artificial, this is the only way to conduct the analysis; the rationale behind
giving the emptier and filler equal resources in the classical vanilla
multi-processor cup game is that this is the only way to achieve upper and
lower bounds. The equivalent rational holds for the motivation of the
variable-processor cup game. Analysis of this game does provide information
about how real-world systems will behave.

A priori the fact that the number of processors can vary offers neither the
filler nor the emptier a clear advantage: lower values of $p$ mean that the
emptier is at more of a discretization disadvantage but also mean that the
filler can anchor fewer cups.  We hoped that the variable-processor cup game
could be simulated in the vanilla multiprocessor cup game, because the extra
ability given to the filler does not seem very strong. The new version of the
cup game arose as we tried to get a bound of $\Omega(\log p)$ backlog in the
multiprocessor game against an oblivious filler, which would combine with
previous results to give us a lower bound that matches our upper bound:
$O(\log\log n + \log p)$. In Proposition \ref{prop:obliviousBase} we prove that
there is an oblivious filling strategy in the variable-processor cup game on
$n$ cups that achieve backlog $\Omega(\log n)$ as desired. \footnote{Note that
  we have $\Omega(\log n)$ in this proposition instead of $\Omega(\log p)$
  because the filler can increase the number of processors, so it increases the
  number of processors to $n-1$ to start. A nearly identical construction could
  be used to show that backlog $\Omega(\log p_{\max})$ can be achieved, where
  the number of processors starts at $p_{\max}$ and the filler does not ever
  increase the number of processors. However, using $p_{\max} = n$ is natural
  in the variable-processor cup game, so we do not consider the game with 
the restriction that the filler can not increase the number of processors above
some $p_{\max} < n$.}

However, we also show that attempts at simulating the variable-processor cup
game are futile because the variable-processor cup game
is--surprisingly--fundamentally different from the multiprocessor cup game, and
thus impossible to simulate. This follows as a corollary of an
\defn{Amplification Lemma} for both the adaptive and oblivious filler.
Section \ref{sec:adaptive} and Section \ref{sec:oblivious} follow the structure:
\begin{enumerate}
  \item Proposition: Base case of inductive argument in corollary
  \item Lemma: Amplification Lemma, allows for inductive step in inductive argument
  \item Corollary: Repeatedly amplify the base case backlog to get very large backlog
\end{enumerate}
We proceed with our results.

\section{Adaptive Lower Bound}\label{sec:adaptive}
\begin{proposition}
\label{prop:adaptiveBase}
  There exists an adaptive filling strategy for the variable-processor cup game
  on $n$ cups that achieves backlog at least $\frac{1}{4}\ln (n/2)$, where fill
  is relative to the average fill of the cups, with negative fill allowed.
\end{proposition}
\begin{proof}
  Let $h = \frac{1}{4}\ln (n/2)$ be the desired fill. Once a cup with fill at
  least $h$ is achieved the filler stops, the process completed. Denote the
  fill of a cup $i$ by $\fil(i)$. Let the \defn{positive tilt} of a cup $i$ be
  $\tilt_+(i) = \max(0, \fil(i))$, and let the positive tilt of a set $S$ of
  cups be $\sum_{i\in S} \tilt_+(i)$. Let the \defn{mass} of a set of cups $S$
  be $m(S) = \sum_{i\in S} \fil(i)$. Denote the average fill of a set of cups $S$ as 
  $\mu(S) = m(S) / |S|$. Let $A$ consist of the $n/2$ fullest cups, and
  $B$ consist of the rest of the cups.

  If the process is not yet complete, that is $\fil(i) < h$ for all cups $i$,
  then $\tilt_+(A\cup B) < h\cdot n$. Assume for
  sake of contradiction that there are more than $n/2$ cups $i$ with $\fil(i)
  \le -2h$. The mass of those cups would be less than $-hn $, but there isn't
  enough positive tilt to oppose this, a contradiction. Hence there are at most
  $n/2$ cups $i$ with $\fil(i) \le -2h$. 

  We set the number of processors equal to $1$ and play a single processor cup
  game on $n/2$ cups that have fill at least $-2h$ (which must exist) for $n/2
  -1$ steps. We initialize our ``active set" to be $A$, noting that $\fil(i)
  \ge -2h$ for all cups $i\in A$, and remove $1$ cup from the active set at
  each step.
  At each step the filler distributes water equally among the cups in its
  active set. Then, the emptier will choose some cup to empty from. If this cup
  is in the active set the filler removes it from the active set. Otherwise, the
  filler chooses an arbitrary cup to remove from the active set.

  After $n/2-1$ steps the active set will consist of a single cup. This cup's
  fill has increased by $1/(n/2) + 1/(n/2 - 1) + \cdots + 1/2 + 1/1
  \ge \ln n/2 = 4h$. Thus such a cup has fill at least $2h$ now, so the
  proposition is satisfied.
\end{proof}

\begin{lemma}[The Adaptive Amplification Lemma]\label{lem:adaptiveAmplification}
  Let $f$ be an adaptive filling strategy that achieves backlog $f(n)$ in the
  variable-processor cup game on $n$ cups (relative to average fill, with
  negative fill allowed).
  Let $n_0 \in \mathbb{N}$ be a constant such that $\frac{1}{4} \ln (n_0/2) \ge
  1$. Let $\delta\in(0,1)$ be constant, and let $M\in\mathbb{N}$ be a constant
  such that $n_0 \le (1-\delta)\delta^M n \le n_0/\delta$.

  Then, there exists an adaptive filling strategy that achieves backlog
  $$f'(n) \ge \max\left(1, (1-\delta)\sum_{\ell= 0}^{M} f((1-\delta)\delta^\ell n)\right)$$
  in the variable processor cup game on $n\ge n_0$ cups.
\end{lemma}
\begin{proof}
  The basic idea of this analysis is as follows:
  \begin{enumerate}
    \item Using $f$ repeatedly, achieve average fill at least $(1-\delta)
      f(n(1-\delta))$ in a set of $n\delta$ cups. 
    \item Reduce the number of processors to $n\delta$.
    \item Recurse on the $n\delta$ cups with high average fill.
  \end{enumerate}

  Let $A$ the \defn{anchor set} be initialized to consist of the $n\delta$
  fullest cups, and let $B$ the \defn{non-anchor set} be initialized to consist
  of the rest of the cups (so $|B| = (1-\delta)n$).
  Let $n_\ell = n\delta^{\ell-1}$, $h_\ell = (1-\delta)f(n_\ell(1-\delta))$;
  the filler will achieve a set of at least $n_\ell \delta$ cups with average
  fill at least $h_\ell$ on the $\ell$-th
  level of recursion. On the $\ell$-th level of recursion $|A| = \delta\cdot
  n_\ell, |B| = (1-\delta)\cdot n_\ell$.

  We now elaborate on how to achieve Step 1.
  Our filling strategy always places $1$ unit of water in each anchor cup. This
  ensures that average fill in the anchor set is non-decreasing.

  On the $\ell$-th level of recursion we will repeatedly apply $f$ to
  $B$, and then take the cup generated by $f$ within $B$ to have large backlog
  and swap it with a cup in $A$ until $A$ has the desired average fill. 
  Note that $$\mu(A) \cdot |A| +\mu(B)\cdot |B| = 0$$
  so $$\mu(A) = - \mu(B) \cdot (1-\delta)/ \delta.$$
  Thus, if at any point in this process $B$ has average fill lower than $-h_\ell
  \cdot \delta/(1-\delta)$,
  then anchor set has average fill at least $h_\ell$, so the process is
  finished. So long as $B$ has average fill at least $-h_\ell\cdot
  \delta/(1-\delta)$ we will apply $f$ to $B$.
  
  It is somewhat complicated to apply $f$ to $B$ however, because we need to
  guarantee that in the steps that the algorithm takes while applying $f$ the
  emptier always empties the same amount of water from $B$ as the filler fills
  $B$ with. This might not be the case if the emptier does not empty from each
  anchor cup at each step. Say that the emptier \defn{neglects} the anchor set
  on an application of $f$ if there is some step during the application of $f$
  in which the emptier does not empty from some anchor cup.

  We will apply $f$ to $B$ at most $h_\ell n_\ell\delta + 1$ times, and at the
  end of an application of $f$ we only swap the generated cup into $A$ if the
  emptier has not neglected the anchor set during the application of $f$.

  Note that each time the emptier neglects the anchor set the mass of the
  anchor set increases by $1$. If the emptier neglects the anchor set $h_\ell
  n_\ell\delta + 1$ times, then the average fill in the anchor set increases by
  more than $h_\ell$, so the desired average fill is achieved in the anchor set.

  Otherwise, there must have been an application of $f$ for which the emptier
  did not neglect the anchor set. We only swap a cup into the anchor set if
  this is the case. In this case we achieve fill 
  $$-h_\ell \cdot \delta/(1-\delta) + f(n_\ell (1-\delta)) = (1-\delta)f(n_\ell
  (1-\delta)) = h_\ell$$
  in a non-anchor cup, and swap it with the smallest cup in the anchor set.

  We achieve average fill $h_\ell$ in the anchor set for $M$ levels of
  recursion. Note that as $n\ge n_0$ we can always simply use Proposition
  \ref{prop:adaptiveBase} to achieve backlog $1$. We will revert to this option
  if it gives larger fill than we get by repeatedly applying $f$.
\end{proof}

\begin{corollary}
  \label{cor:adaptivePoly}
  There is an adaptive filling strategy for the variable-processor cup game on
  $n$ cups that achieves backlog $\Omega(n^{1-\epsilon})$ for any constant
  $\epsilon \in (0,1)$, in running time $2^{O(\log^2 n)}$.
\end{corollary}
\begin{proof}$ $\\
  \paragraph{Basic Idea}
  Let
  $$f_0(k) = 
  \begin{cases} 
    \lg k, & k\geq 1, \\
    0 & \text{else.}
  \end{cases}$$
  Note that we can achieve backlog $f_0(k)$ on $k$ cups by Proposition \ref{prop:adaptiveBase}.
  Let $f_{m+1} $ be the result of applying the Amplification Lemma to $f_m$ with $\delta=1/2$. 
  The function $f_{\lg n^{1/9}}(k)$ satisfies 
  \begin{equation}\label{eqn:amppppp}
  \text{for } k \geq n,\,\, f_{\lg n^{1/9}}(k) \geq 2^{\lg n^{1/9}} \lg k.
  \end{equation}
  In particular, using $f_{\lg n^{1/9}}(n)$ (applying the function to all of
  the cups) we achieve backlog $\Omega(n^{1/9}\lg n) \ge \Omega(\poly(n))$
  as desired.
  To prove Equation \ref{eqn:amppppp}, we prove the following lower bound for $f_m$ by induction:
  $$f_m(k) \geq 2^m \lg k, \text{ for } k \geq (2^9)^m.$$
  The base case follows from the definition of $f_0$. Assuming the property for
  $f_m$, we get the following by Lemma \ref{lem:adaptiveAmplification}:
  $ \text{for } k > (2^9)^{m+1},$
  \begin{align*}
  &f_{m+1}(k) \\
  &\ge \frac{1}{2}(f_m(k/2) + f_m(k/4) + \cdots + f_m(k/2^9) + \cdots)\\
  &\geq \frac{1}{2}(f_m(k/2) + f_m(k/4) + \cdots + f_m(k/2^9))\\
  &\geq \frac{1}{2}2^m(\lg (k/2) + \lg(k/4) + \cdots + \lg(k/2^9))\\
  &\geq \frac{1}{2}2^m(9\lg (k) - \frac{9 \cdot 10}{2}) \\
  &\geq 2^{m+1} \lg(k) ,
  \end{align*}
  as desired. Hence the inductive claim holds, which establishes that $f_{\lg
  n^{1/9}}$ satisfies the desired condition, which proves that backlog can be
  made $\Omega(\poly(n))$.

  \paragraph{Running Time Analysis}
  The recursive construction requires quite a lot of steps, in fact a
  super-polynomial number of steps. If we consider the tree that represents
  computation of $f_{\log n^{1/\alpha}}(n)$ we see that each node will have at
  most $\alpha$ (some constant, e.g. $\alpha = 9$, $\alpha$ is the number of
  terms that we keep in the sum) children (the children of $f_k(c)$ are
  $f_{k-1}(c/2), f_{k-1}(c/4), \ldots f_{k-1}(c/2^\alpha)$), and the depth of
  the tree is $\log n^{1/\alpha}$. Say that the running time at the node
  $f_{\log n^{1/\alpha}}(n)$ is $T(n)$. Then because $f_{k}(n)$ must call each
  of $f_{k-1}(n/2^i)$ $n/2^i$ times for $1\le i \le \alpha$, we have that $
  T(n) \le \frac{\alpha n}{2}T(n/2)$. This recurrence yields $T(n) \le
  \poly(n)^{\log n} = O(2^{\log^2 n})$ for the running time.

  \paragraph{Generalizing Our Approach}
  Generalizing our approach we can achieve a (slightly) better polynomial
  lower bound on backlog. In our construction the point after which we had a
  bound for $f_m$ grew further out by a factor of $2^9$ each time. Instead of
  $2^9$ we now use $2^\alpha$ for some $\alpha \in \mathbb{N}$, and can find a
  better value of $\alpha$. The value of $\alpha$ dictates how many
  iterations we can perform: we can perform $\lg n^{1/\alpha}$ iterations.
  The parameter $\alpha$ also dictates the multiplicative factor that we gain
  upon going from $f_m$ to $f_{m+1}$. For $\alpha = 9$ this was $2$. In general
  it turns out to be $\frac{\alpha -1}{4}$.  Hence, we can achieve backlog
  $\Omega\left(\left(\frac{\alpha -1}{4}\right)^{\lg n^{1/\alpha}}\lg
  n\right)$. This optimizes at $\alpha = 13$, to backlog
  $\Omega(n^{\frac{\lg 3}{13}}\log n) \approx \Omega(n^{0.122}\log n)$. 

  We can further improve over this. Note that in the proof that
  $f_{m+1}$ gains a factor of $2$ over $f_m$ given above, we lower bound
  $9\lg k - 9\cdot 10 /2$ with $2\lg k$. Usually however this is very
  loose: for small $m$ a significant portion of the $9 \lg k$ is annihilated
  by the constant $1+2+\cdots+9$ (or in general $\alpha \lg k$ and
  $1+2+\cdots + \alpha$), but for larger values of $m$ because $k$ must be
  large we can get larger factors between steps, in theory factors arbitrarily
  close to $\alpha$. If we could gain a factor of $\alpha$ at each step, then
  the backlog achievable would be $\Omega(\alpha^{\lg{n^{1/\alpha}}}\log n)=
  \Omega(n^{(\lg{\alpha})/\alpha} \log n)$ which optimizes (over the
  naturals)
  at $\alpha = 3$ to $n^{(\lg 3)/3} \approx n^{0.528}$. However, we can't
  actually gain a factor of $\alpha$ each time because of the subtracted
  constant. But, for any $\epsilon >0$ we can achieve a $\alpha - \epsilon$
  factor increase each time (for sufficiently large $m$). Of course $\epsilon$
  can't be made arbitrarily small because $m$ can't be made arbitrarily large,
  and the ``cut off" $m$ where we start achieving the $\alpha - \epsilon$
  factor increase must be a constant (not dependent on $n$). When the cutoff
  $m$, or equivalently $\epsilon$, is constant then we can achieve backlog
  $\Omega((\alpha - \epsilon)^{\lg{n^{1/\alpha}}}\log n)=
  \Omega(n^{(\lg(\alpha - \epsilon))/\alpha} \log n)$. For instance, with
  this method we can get backlog $\Omega(\sqrt{n})$ for appropriate $\epsilon,
  \alpha$ choice, or $\tilde{\Omega}(n^{(\lg (3 - \epsilon))/3})$ for any
  constant $\epsilon >0$. 

  \paragraph{Existential Improvement}
  We now (non-constructively) demonstrate the existence of a filling strategy
  that achieves backlog $c n^{1-\epsilon}$ for constant $\epsilon \in (0,1)$
  and $c \ll 1$.

  Let $f^*(n)$ be the supremum over all filling strategies of the fill achievable on $n$ cups.
  Clearly $f^*(n)$ satisfies the Amplification Lemma, i.e.
  $$f^*(n) \ge (1-\delta)\sum_{\ell=0}^M f^*((1-\delta)\delta^\ell n).$$
  Assume for the sake of deriving a contradiction that there is some $n$ such
  that $f^*(n) < cn^{1-\epsilon}$, let $n_*$ be the minimum such $n$.

  Then we have 
  $$cn_*^{1-\epsilon} > f^*(n_*) \ge (1-\delta)\sum_{\ell=0}^M f^*((1-\delta)\delta^\ell n_*).$$
  However, 
  \begin{align*}
  &(1-\delta)\sum_{\ell=0}^M f^*((1-\delta)\delta^\ell n_*) \\
  &\ge cn_*^{1-\epsilon}(1-\delta)\sum_{\ell=0}^M((1-\delta)\delta^\ell)^{1-\epsilon}\\
  &\ge cn_*^{1-\epsilon}(1-\delta) \frac{(1-\delta)^{1-\epsilon}}{1-\delta^{1-\epsilon}}.
  \end{align*}
  We will now show that there is an appropriate choice of $\delta \in (0,1)$
  such that $$\frac{(1-\delta)^{2-\epsilon}}{1-\delta^{1-\epsilon}} \ge 1,$$
  which contradicts the assumption that $c n_*^{1-\epsilon} > f^*(n_*)$.
  Rearranging, we desire $$(1-\delta)^{2-\epsilon} + \delta^{1-\epsilon}\ge 1.$$
  For any $\epsilon$ we will show that there is an appropriate choice of
  $\delta\ll 1$ satisfying this inequality.

  Consider the Taylor series for $(1-\delta)^{2-\epsilon}$:
  $$(1-\delta)^{2-\epsilon} = 1 - (2-\epsilon)\delta - O(\delta^2).$$
  By taking $\delta$ sufficiently small, the $O(\delta^2)$ term becomes
  negligible compared to the $(\alpha+1)\delta$ term. In particular, say that
  the $O(\delta^2)$ term is less than $c \delta^2$ for some constant $c$.
  Taking $\delta$ small enough such that $\delta^2 c < \delta$, we have that
  $(1-\delta)^{2-\epsilon} > 1-(2-\epsilon)\delta - \delta$.
 
  So, to find a $\delta$ where $g(\delta) \ge 1$ it suffices to find a $\delta$ with 
  $$\delta^{1-\epsilon} \ge (3-\epsilon)\delta.$$
  The equality is achieved at $\delta = (\frac{1}{3-\epsilon})^{1/\epsilon}$.

  This establishes the existence of a filling strategy that achieves backlog
  $\Omega(n^{1-\epsilon})$.

  \paragraph{Modifying the Existential Argument to achieve backlog $n^{1-\epsilon}$ in finite time}
  We can modify the existential argument to get a guarantee on how long it will take to achieve the desired backlog.
  Fix an $\epsilon > 0$, and choose a $\delta\in(0,1)$ satisfying $(1-\delta)^{2-\epsilon} / 1-\delta^{1-\epsilon} \ge 1$.
  Fix $c \ll 1$. Say we aim to achieve backlog at least $cn^{1-\epsilon}$.
  Note that the choice of $\delta$ is motivated by the fact that
  $$(1-\delta)\sum ((1-\delta)\delta^i)^{1-\epsilon} = \frac{(1-\delta)^{2-\epsilon}}{1-\delta^{1-\epsilon}},$$
  and, as in the existential argument it will be useful to assert that this quantity is at least $1$.
  {\color{red} ok I'm kind of worried about things not being integers being a problem.}
  We start with 
  $$f_0(k) = 
  \begin{cases} 
    \lg k, & k\geq 1, \\
    0 & \text{else.}
  \end{cases}$$
  Then we construct $f_n$ as the amplification of $f_{n-1}$. 
  We claim the following regarding this construction:
  $$f_\ell(k) \ge cn^{1-\epsilon} \text{ for all } k>n/(1-\delta)^\ell.$$
  This is clearly true in the base case with $f_0$.
  If $f_\ell(k) \ge cn^{1-\epsilon}$ for all $k$ then we are already done.
  Otherwise, let $k_*+1$ be the smallest $k$ such that $f_\ell(k) < cn^{1-\epsilon}$. Note that by assumption we have $k_* > n/(1-\delta)^\ell$.
  Now consider the amplification $f_{\ell+1}$ of $f_\ell$.
  \begin{align*}
    f_{\ell+1}(k_*/(1-\delta)) &\\
    &\ge (1-\delta)\sum f_\ell((1-\delta)\delta^in)\\
    &\ge cn^{1-\epsilon}\frac{(1-\delta)^{2-\epsilon}}{1-\delta^{1-\epsilon}}\\
    &\ge cn^{1-\epsilon}.
  \end{align*}
  This is as desired. 
  Thus, by taking $f_{(\log n) /\log (1/(1-\delta))}$ we achieve backlog $cn^{1-\epsilon}$.


  \paragraph{Achieving backlog $\Omega(n^{\lg 3/2})$}
  Recall the recursive procedure that we use in the proof of the Amplification
  Lemma: to achieve the desired fill we must call $f(n/2^\ell)$ for
  $\ell = 0,1,2,\ldots$. As $f_{m+1}$ recursively calls $f_m$, there is even more recursion.

  Let $\#(m, i)$ denote the number of times ${f_m(n/2^i)}$ occurs
  in the recursive construction. Let there be $M = \lg (n/2)$  levels of
  recursion. The first level in the tree has $\#(M, i)=1$ for all $i$. Note
  that we have $$\#(m-1, i) = \sum_{j > i} \#(m, j)$$
  for any level $m$, because any expression $f_m(n/2^j)$ will
  call $f_{m-1}(n/2^i)$ for $j>i$.

  This is very reminiscent of the hockey stick identity:
  $${n \choose i} = \sum_{i-1\le j\le n-1} {j \choose i-1}.$$

  In fact we claim that if you look at it right (i.e. sideways) the $\#(m,
  i)$'s form Pascal's triangle!
  Specifically the bijection is 
  $$\#(m,i) = {i \choose M-m}.$$

  This is true because of the Hockey Stick Identity and the base case
  like $\#(M, i)=1$ for all $i$. We induct on the diagonals of Pascal's
  triangle. The inductive hypothesis is that $\#(m, i) = {i \choose M-m}$ for
  all $i$ for some $m$. Then by the Hockey Stick Identity we get 
  \begin{align*}
  &\#(m-1, i) = \sum_{j>i} \#(m,j) \\
  &= \sum_{j>i} {j \choose M-m} = {i \choose M-(m-1)}
  \end{align*}
  as desired.

  We can also prove this with a simple combinatorial argument: there is a
  bijection between terms of the form $f_{M-m}(n/2^{m+i-m})$ and integer
  partitions of $i-m$ into $m$ integers, as you must divide up the array
  subdivisions among the different levels of recursion. This demonstrates that
  $$\#(m, i) = {i-m+m \choose M-m} = {i \choose M-m}.$$

  We know that $f_m(n/2^M) \ge 1$ by design in Lemma
  \ref{lem:adaptiveAmplification}, so to determine the total backlog we add up
  the occurrences of $f_m(n/2^M)$ on each level, weighted by the
  $1/2$ decay factor. Then the backlog we get is $$\sum_{i=0}^M {M \choose
  i}\frac{1}{2^i} = (3/2)^{M} = n^{\lg(3/2)}.$$
  This is optimal for $\delta= 1/2$.

  \textbf{Constructively achieving backlog $\Omega(n^{1-\epsilon})$}
  The existential proof that backlog $\Omega(n^{1-\epsilon})$ suggests that we
  will need to take $\delta \ll 1$ to achieve this backlog. The analysis from
  the case $\delta = 1/2$ doesn't immediately apply here; that analysis was
  significantly simplified by the fact that $\delta = 1-\delta$ for $\delta =
  1/2$. However, we use some similar ideas.


\end{proof}

\section{Adaptive Upper Bounds}\label{sec:adaptiveUpperBound}
Let $[n] = \{1,2,\ldots, n\}$, let $i+[n] = \{i+1, i+2, \ldots, i+n\}$.
The cup game consists of many successive rounds. On the $t$-th round the state
starts as $S_t$. The filler chooses the number of processors $p_t$ for the round. 
Then the filler distributes $p_t$ units of water among the cups (with at most
$1$ unit of water to any particular cup). After this, we are at an intermediate
state in the $t$-th round, which we call state $I_t$. Then the emptier chooses
$p_t$ cups to empty $1$ unit of water from. After this the round is over, and
the state is $S_{t+1}$.

Let the rank of a cup at a given state be its position in a sorted list of the
cups, breaking ties arbitrarily but consistently. For example, the fullest cup
at a state has rank $1$, and the least full cup has rank $n$.
Let $\mu_S(X), m_S(X)$ denote the average fill and mass of a set of cups $X$
respectively at state $S$ ($S$ could be $S_t$ or $I_t$ for any $t\in\mathbb{N}$)
\footnote{Note that previously when we used the notation $m, \mu$ for mass and
average fill, we left off the subscript indicating the state at which the
properties were measured. Previously it was sufficient to leave the round
implicit as it was understandable from context, however in this Section the
state is crucial, and needs to be explicit in the notation.}.
Let $S_t(\{r_1, \ldots, r_m\})$ and $I_t(\{r_1,\ldots, r_m\})$ denote the cups
of ranks $r_1, r_2, \ldots, r_m$ at states $S_t$ and $I_t$ respectively.
We establish the following Lemma:

\begin{lemma}
  The greedy emptier maintains the invariant $\mu_{S_t}(S_t([k])) \le n-k$ for
  all $t\in\mathbb{N}, k \le n$. In particular, for $k=1$, this means that the
  emptier never lets backlog exceed $O(n)$.
\end{lemma}
\begin{proof}
First note that the invariant is trivial when $k=n$, as the average fill of the
set of all cups is by definition $0$.

We will prove the invariant by induction on $t$.
The invariant holds trivially for $t=1$ (the base case of our recurrence): 
the cups start empty so $\mu_{S_1}(S_1([k])) = 0 \le n-k$.

Fix a round $t \ge 1$. We assume all the invariants for state $S_t$ (we will
only use two of the invariants, but the invariants that we need depend on the
choice of $p_t$ by the filler, so we need all of them) and show that
$\mu_{S_{t+1}}(S_{t+1}([k])) \le n-k$. 

Note that as the emptier is greedy it always empties from the cups $I_t([p_t])$.

Let $A$, with $a=|A|$, be $A = I_t([\min(k, p_t)]) \cap S_{t+1}([k])$, that is, $A$
consists of cups among the $k$ fullest cups in $I_t$ that were emptied from and
ended up in the $k$ fullest cups in $S_{t+1}$.
Let $B$, with $b=|B|$, be $I_t([\min(k, p_t)]) \setminus A$, that is $B$ consists of
the cups among the $k$ fullest cups at state $I_t$ that the emptier empties
from that do not end up in the $k$ fullest cups in $S_{t+1}$. 
Let $C = I_t(a+b+[k-a])$, with $c=k-a = |C|$ (Note that $k-a\ge 0$ as $a+b \le k$). 

Note that $a+ b = \min(k, p_t)$.
Note that $A = I_t([a])$ and $B = I_t(a+[b])$, as every cup in $A$
must have higher fill than all cups in $B$ in order to remain above the cups in
$B$ after $1$ unit of water is removed from all cups in $A\cup B$.
Further, note that $S_{t+1}([k]) = A \cup C$, because once the cups in $B$
are emptied from cups in $C$ take their place among the $k$ fullest cups.

With these definitions made, we proceed to prove the Lemma.

First we prove the following key property, which we call the \defn{switcheroo-ability of cups}.
The property is: without loss of generality $S_t([a+b]) = I_t([a+b])$.
\begin{proof}
  Say there are cups $x, y$ with $x\in S_t([a+b]) \setminus I_t([a+b]), y \in
  I_t([a+b])\setminus S_t([a+b])$. Let the fills of cups $x,y$ at state $S_t$
  be $f_x, f_y$; note that $f_x > f_y$. Let the amount of fill that the emptier
  adds to these cups be $\Delta_x, \Delta_y \le 1$; note that $f_x +\Delta_x <
  f_y + \Delta_y$.

Define a new state $S_t'$ where cup $x$ has fill $f_y$ and cup $y$ has fill $f_x$. 
Let the amount of water that the filler places in these cups from the new state be
$f_x-f_y+\Delta_x$ and $f_y-f_x + \Delta_y$ for cups $x,y$ respectively.
Note that this is valid as $f_y-f_x + \Delta_y\le 1$ and $f_x-f_y+\Delta_x < 1$
which is true because, $f_x-f_y+\Delta_x<\Delta_y \le 1$ and $f_y-f_x + \Delta_x < \Delta_x \le 1$.

We can repeatedly apply this process to swap each cup in $I_t([a+b])\setminus
S_t([a+b])$ into being one of the $a+b$ fullest cups in the new state $S_t'$.
At the end of this process we will have some ``fake" state $S_t^f$. Note that
$S_t^f$ must satisfy the invariant if $S_t$ satisfied the invariant, because we
are essentially just renaming variables, or in other words swapping the fill of
certain cups.

It is without loss of generality that we start in state $S_t^f$ because from
state $I_t$ we could equally well have come from state $S_t$ or state $S_t^f$.
\end{proof}

Now we proceed with the proof of the Lemma.

First we consider the case $b=0$. If $b=0$, then $S_{t+1}([k]) = S_t([k])$. 
The emptier has removed $a$ units of fill from the cups in $S_t([k])$
(specifically the cups in $A$), and the filler has distributed at most $a$
units of among the cups in $S_t([k])$. Thus the invariant holds:
$$m_{S_{t+1}}(S_{t+1}([k])) \le m_{S_t}(S_t([k]))+a-a \le k(n-k).$$

Now consider $b\neq 0$. In particular, note that this implies $a < k$ as $a+b
\le k$. Recall that $S_{t+1}([k]) = A \cup C$, so the mass of the $k$ fullest
cups at $S_{t+1}$ is the mass of $A\cup C$ at $S_t$ plus any water added to
cups in $A\cup C$ by the filler, minus any water removed by the emptier. 
The emptier removes exactly $a$ units of water from $A\cup C$, and the filler
adds at most $a+b \le p_t$ (recall $a+b = \min(p_t, k)$) units of water to $A\cup C$.
Thus:
$$m_{S_{t+1}}(S_{t+1}([k])) \le m_{S_t}(A) + m_{S_t}(C) + b.$$
This is easy to bound if $m_{S_t}(C) \le m_{S_t}(B\cup C) - b$, becuase 
$$m_{S_t}(A) + m_{S_t}(B\cup C)  = m_{S_t}(A\cup B\cup C) \le m_{S_t}([k])$$
which would imply the invariant for $S_{t+1}$, $k$.
If $\mu_{S_t}(C)$ is not significantly less than $\mu_{S_t}(B\cup C)$ we have more difficulty.
The key insight is to notice that larger values for $m_{S_t}(A)$ correspond to
smaller values for $m_{S_t}(C)$ becase of the invariants; the higher fill in
$A$ \defn{pushes down} the fill that $C$ can have.
By quantifying exactly how much higher fill in $A$ pushes down fill in $C$ we
can arrive at the desired invariant.
We can upper bound $\mu(C)$ by $\frac{c}{b+c}m_{S_t}(BC) = (m_{S_t}(ABC) - m_{S_t}(A))\frac{c}{b+c}$ as
$\mu_{S_t}(C) \le \mu_{S_t}(B)$ (we established that this was without loss of
generality because switcheroo-ing is possible).
Thus, we have 
$$m_{S_t}(A) + m_{S_t}(C) \le \frac{c}{b+c}m_{S_t}(ABC) + \frac{b}{b+c}m_{S_t}(A).$$
Now we set $\mu_{S_t}(ABC)$ and $\mu_{S_t}(A)$ extremally, that is
$\mu_{S_t}(ABC) = n-|ABC|$ and $\mu_{S_t}(A) = n-|A|$.
At this point the inequality can be verified by straightforward algebra,
however this is not elegant; instead, we combinatorially interpret the sum.
Consider $\mu_{S_t}(BC)$. By setting $A$ extremally we have raised its average
fill $|BC|$ above $n-|ABC|$, the average fill of $ABC$. If we initially had
equal water level in all cups, then to equalize an increase in $\mu_{S_t}(A)$
of $|BC|$, there would need to be a corresponding decrease in the average fill
of $B\cup C$ by $|A|$.
Thus we have $$\mu_{S_t}(BC) \le n-|ABC|-|A|.$$
Thus we have the following bound:
\begin{align*}
  m_{S_t}(A) + m_{S_t}(C)&\\
&\le m_{S_t}(A) + c\mu_{S_t}(BC)\\
&\le a(n-a) + c(n-|ABC|-a)\\
&(a+c)(n-a) - c(a+c+b)\\
&(a+c)(n-a-c) - cb.
\end{align*}
Recall that we were considering $b> 0, c \ge 1$ (we previously handled the case
where $b=0$, and if $b>0$ then $c=k-a\ge b\ge 0$).
Hence we have 
$$m_{S_t}(A) + m_{S_t}(C) \le k(n-k) -b$$
So 
$$m_{S_t}(A) + m_{S_t}(C)+b \le k(n-k).$$
As shown previously the left hand side of the above expression is an upper bound for $m_{S_{t+1}}([k])$.
Hence the invariant holds.


% explain the last part better:

% set them numerically, 
% then lets just imagine this configuration to see what’s going on combinatorially.
% say explicitly that it might not satisfy the invariants.  

% b/(b+c) (a+b+c)(n-a-b-c) + b/(b+c) a (n-a) = 
% a(n − a) + c(n − |ABC| − a)

% maybe just say: given a fixed value of m(ABC) might as well just push the water into A cuz m(BC) has that nasty c/(b+c) < 1 thing. this is a bit simpler. 



\textbf{Conclusion:}\\
The proof was for arbitrary $k$, so given that the invariants all hold at state
$S_t$ they also must all hold at state $S_{t+1}$.
Thus, by induction we have the invariant for all rounds $t\in\mathbb{N}$.
\end{proof}
\clearpage


\section{Oblivious Lower Bounds}\label{sec:oblivious}

An important theorem that we use repeatedly in our analysis is Hoeffding's Inequality:
\begin{theorem}[Hoeffding's Inequality]
  Let $X_i$ be independent bounded random variables with $X_i \in [a,b]$. Then,
  $$P\left(\Big|\frac{1}{n} \sum_{i=1}^n (X_i - \E[X_i])\Big|\ge t\right) \le
  2\exp\left(-\frac{2nt^2}{(b-a)^2}\right) $$
\end{theorem}
Hoeffding also proved that this is true even if $X_i$ are drawn without
replacement from some finite population. This is intuitive as drawing without
replacement clearly has less variance than sampling with replacement, i.e.
sampling without replacement should be more tightly concentrated around the
mean than sampling with replacement. This is a corollary of his Theorem 4, see
page 28 of his seminal work \cite{who62}.

Call an emptying strategy $(\ell, \delta)$\defn{-greedy-like} if is satisfies
the following property when the number of processors is $p$: for any cup
$i$, if $\fil(i) + \delta > \ell$, and there are at least $p$ cups containing fill
greater than $\fil(i) + \delta$, the emptier does not empty from cup $i$.
Of particular interest is the smoothed greedy emptier, which is $(1, 0)$-greedy-like.

\begin{proposition}
  \label{prop:obliviousBase}
  There exists an oblivious filling strategy in the variable-processor cup game
  on $n$ cups that achieves backlog $\Omega(\log n)$ against a $(\ell,
  \delta)$-greedy-like emptier (where $\ell, \delta \le O(1)$ are constants
  known to the filler), with probability at least $1-1/\polylog(n)$.
\end{proposition}
\begin{proof}
  Let $A$, the \defn{anchor} set, be a subset of the cups chosen uniformly at
  random from all subsets of size $n/2$ of the cups, and let $B$, the
  \defn{non-anchor} set, consist of the rest of the cups ($|B| = n/2$). 
  Let $h = 2 \ell + g $ where $g$ is a sufficiently large constant. At each
  level of our recursive procedure we will achieve fill $h$ in some fraction of
  the cups in $A$, and because the emptier is greedy, we can turn this into a
  known set of cups with fill at least $h' = \ell + (g+\delta)/2$.
  Our strategy to achieve backlog $\Omega(\log n)$ overall is roughly as follows:
  \begin{itemize}
    \item \textbf{Step 1:} 
      Obtain large positive tilt in $B$, either by repeatedly making cups in $B$ have a constant probability of having
      fill at least $h$ and then transferring these cups into $A$, or by
      exploiting high expected positive tilt.
  \item \textbf{Step 2:} Reduce the number of processors to a constant fraction $nc$ of $n$ and
    raise the fill of $nc$ cups to $h'$. This step relies on the emptier being
    greedy.
  \item \textbf{Step 3:} Recurse on the $nc$ cups that are known to have fill at least $h'$.
\end{itemize}
We can perform $\Omega(\log n)$ levels of recursion, achieving constant backlog
at each step (relative to average fill); doing so yields backlog $\Omega(\log
n)$.

Now we detail how to achieve Step 1.
For each anchor cup $i$ we will perform a \defn{switching-process}.
First we choose an index $j \in [n^2]$; the process proceeds for $n^2$
\defn{rounds}, $j$ is the index of the switching-process at which we will
switch a cup into the anchor set.
On each of the $n^2$ rounds, the filler selects a random subset $C\subset B$ of
the non-anchor cups and plays a single processor cup game on $C$.
On most rounds, all rounds except the $j$-th the filler does nothing with the
cup that it achieves at the end of the single processor cup game.
On round $j$ with $1/2$ probability the filler swaps the winner of the single processor
cup game into the anchor set, and with $1/2$ probability the filler swaps a random cup
from $B$ into the anchor set.

We say that a cup is \defn{overpowered} if it contains fill $\ge
\sqrt{\frac{nh}{\log\log n}}$. If there is ever an overpowered cup, then the
proposition is trivially satisfied. Note that we don't need to know which cup
is overpowered because it will take $\Omega(\poly(n))$ rounds for the emptier
to reduce the fill below $\poly(n)$. Hence, we can assume without loss
of generality that no cup is ever overpowered.

We consider two cases:
\begin{itemize}
  \item \textbf{Case 1:} For at least $1/2$ of the switching-processes, at
    least $1/2$ of the cups $i \in B$ have $\fil(i) \ge -h$.
  \item \textbf{Case 2:} For at least $1/2$ of the switching-processes, less
    than $1/2$ of the cups $i \in B$ have $\fil(i) \ge -h$.
\end{itemize}

\begin{clm}
  \label{clm:reg} In Case 1, with probability at least $1-e^{-\Omega(n)}$, we
  achieve fill at least $h$ in a constant fraction of the cups in $A$, which in
  particular implies that we can achieve positive tilt $nhk$ for some known
  constant $k \in (0,1)$ ($k$ is a complicated function of $h$).
\end{clm}
\begin{proof}
  Consider a switching-process where at least $1/2$ of the cups $i \in B$
  have $\fil(i) \ge -h$.

  Say the emptier \defn{neglects} the anchor set in a round if on at least one
  step of the round the emptier does not empty from every anchor cup. By
  playing the single-processor cup game for $n^2$ rounds, with only one round
  when we actually swap a cup into the anchor set, we strongly disincentives
  the emptier from neglecting the anchor set on more than a constant fraction
  of the rounds. 

  The emptier must have some binary function, $I(k)$ that indicates whether or
  not they will neglect the anchor set on round $k$ if the filler has not already
  swapped. Note that the emptier will know when the filler perform a swap, so
  whether or not the emptier neglects a round $k$ depends on this information.
  This is the only relevant statistic that the emptier can use to decide
  whether or not to neglect a round, because on any round when we simply
  redistribute water amongst the non-anchor cups we effectively have not
  changed anything about the game state. 

  If the emptier is willing to neglect the anchor set for at least $1/2$ of the
  rounds, i.e. $\sum_{k=1}^{n^2} I(k) \ge n^2 / 2$, then with probability at
  least $1/4$, $j \in ((3/4) n^2, n^2)$, in which case the emptier neglects the anchor set
  on at least $n^2/4$ rounds ($I(k)$ must be $1$ for at least $n^2/4$ of the
  first $(3/4)n^2$ rounds). Each time the emptier neglects the anchor set the
  mass of the anchor set increases by at least $1$. Thus the average fill of the anchor
  set will have increased by at least $(n^2/2)/(n/2) \ge \Omega(\poly(n))$ over the
  entire process in this case, implying that we  win automatically as there
  must be an overpowered cup. 

  Otherwise, there is at least a $1/2$ chance that the round $j$, which is
  chosen uniformly at random from the rounds, when the filler performs a switch
  into the anchor set occurs on a round with $I(j)=0$, indicating that the emptier
  won't neglect the anchor set on round $j$. In this case, the round was a
  legitimate single processor cup game on $C_j$, the randomly chosen set of
  $e^{2h}$ cups on the $j$-th round. Then we achieve fill increase $\ge 2h$ by the
  end of the game with probability at least $1/e^{2h}!$, the probability that we
  correctly guess the sequence of cups within the single processor cup game
  that the emptier empties from. 

  The probability that the random set $C_j \subset B$ contains only elements
  with fill $\ge -h$ is basically $1/2^{e^{2h}}$, because at least half of the
  elements of $B$ have fill $\ge -h$ ({\color{red}in reality the selection of
    elements of $C$ are not independent events, but as $h$ is constant here this
  does not matter}). If all elements of $C_j$ have fill $\ge -h$, then the fill
  of the winner of the cup game has fill at least $-h + 2h = h$ if we guess the
  emptier's emptying sequence correctly.

  Combining the results, we have that for such a switching-process there is a
  constant probability of the cup which we switch into the anchor set has fill
  $\ge h$. 

  Say that this probability is $k \in (0,1)$. Then the expectation of the
  number of cups $i \in A$ with $\fil(i) \ge h$ is at least $kn/2$. Let $X_i$
  be the binary random variables, with $X_i$ taking value $1$ if the $i$-th
  switching-process succeeded, and $0$ if it failed. Then by a Chernoff Bound
  (Hoeffding's Inequality applied to Binary Random Variables),
  $$P\left(\sum_{i=1}^{n/2} X_i\le nk/4\right) \le e^{-n(k/2)^2}.$$ 
  That is, the probability that less than $nk/4$ of the anchor cups have fill
  at least $h$ is exponentially small in $n$.

\end{proof}

\begin{clm}
  \label{clm:xtreme}
  In Case 2, with probability at least $1- 1/\polylog(n)$, we achieve positive tilt $hn/8$ in the anchor set.
\end{clm}

\begin{proof}
  Consider a switching-process where we have less than $1/2$ of the cups $i\in B$
  with $\fil(i) \ge -h$.

  % RIP this totally doesn't take into account that B might start with neg fill.

  %! oh crap and fill is sinking! make sure it doesn't sink too much!!!
  We assume for simplicity that the average fill of $B$ is $0$. In reality this
  is not the case, but by a Hoeffding bound and the fact that overpowered cups don't
  exist, the fill is really tightly concentrated around $0$, so this is almost
  without loss of generality.

  Let the positive tilt of a cup $i$ be $\tilt_+(i) \defeq \max(\fil(i), 0)$.
  We have
  $$\E[\tilt_+(X)] = \frac{1}{2}\E[|\fil(X)|] \ge h$$
  (because negative tilt is at least $nh/2$ and positive tilt must oppose this).
  
  Let $Y_i$ be the random variable $Y_i=\tilt_+(X)$ where $X$ is a randomly
  selected cup from the non-anchor set at the start of the $i$-th round of
  playing single processor cups games. {\color{red}Note that the $Y_i$ are not really
  independent, but it is probably ok}. Note that $0\le Y_i \le hn/\lg\lg n$.
  Now we have, by Hoeffding's inequality, that 
  $$P\left(\Big|\frac{1}{n/2} \sum_{i=1}^{n/2} (Y_i - \E[Y_i])\Big|\ge h/2
  \right) \le$$
  $$2\exp\left(-\frac{n(h/2)^2}{(\sqrt{hn/\lg\lg n})^2}\right) $$
  $$P\left(\frac{1}{n/2}\sum_{i=1}^{n/2} Y_i \le h/4\right) \le 1/\polylog(n) $$

\end{proof}

  In both cases we achieve, with probability at least $1-1/\polylog n$,
  positive tilt at least $hnk$ in the anchor set for some known $k\in(0,1)$. Using the
  positive tilt, with one processors, we can transfer over the fill into $nk$ cups. 
  Note, we use one processor because we do not know how many cups the fill is
  concentrated in. The filler repeatedly distributes $1$ unit of fill to each
  of the $nk$ cups in succession, and continues until $h'$ fill has been
  distributed. We cannot continue beyond this point because we have used up the
  positive tilt. Now we recurse on this set of $nk$ cups.

  Note that this is the only part of this proof that was specific to a greedy
  emptier: when we wanted to achieve known fill in some cups. Against an
  arbitrary opponent we can't assume that just because they are far behind
  means that they won't oppose our attempts to achieve cups with known fill.
  Extending this result to non-greedy emptiers, or showing that it cannot be
  extended is an important open question.

  We can perform $\Omega(\log n)$ levels of recursion, and gain $\Omega(1)$
  fill at each step. Hence, overall, backlog of $\Omega(\log n)$ is achieved.
\end{proof}


\begin{lemma}[The Oblivious Amplification Lemma]
  Given an oblivious filling strategy for achieving backlog $f(n)$ in the
  variable-processor cup game on $n$ cups that succeeds with probability at
  least $1/2$, there exists a strategy for achieving backlog 
  $$f'(n) \ge \frac{1}{32}(f(n/2) + f(n/4) + f(n/8) + \cdots) $$ that succeeds
  with constant probability.
\end{lemma}
\begin{proof}
  We essentially perform the same proof as Proposition \ref{prop:obliviousBase}, but some new issues arise, which we proceed to highlight and address. 

\begin{clm}
  Let a cup be \defn{verysad} if it has fill $< -nh/\lg\lg n$.
  WLOG there are no verysad cups. 
\end{clm}
\begin{proof}
  First note that because WLOG there are no overpowered cups, there fewer than $n/2$ verysad cups.

  Consider 2 cases:
  \begin{itemize}
    \item If the mass of the verysad cups is less than $nh/8$ then we can
      ignore them and accept a $-h/8$ penalty to the average fill.
    \item On the other hand, if the mass of the verysad cups is greater than
      $nh/8$, then by the end the average fill of everything else is already
      $h/8$ which is also basically as desired.
  \end{itemize}
\end{proof}

\begin{clm}
  WLOG $A,B$ have average fill $\ge -h/8$.
  In particular, we can construct a subset of $n/2$
  cups with average fill $\ge -h/8$ with high probability in $n$. 
\end{clm}
\begin{proof}

  Recall the definition of an overpowered cup as a cup with fill $\ge nh / \lg \lg n$,
  and the fact that WLOG there are no overpowered cups.
  So, If we randomly pick $B$ then this means that we are pretty good. 
  Formalizing this, let $X_i$ be the fill of the $n/2$-th randomly chosen cup
  for $B$. Unfortunately these are not quite independent events.

  Lets say we pick $2n$ things from $n$ things with replacement. Claim: with
  exponentially good probability we have $n/2$ distinct things. 
  Proof: chernoff bound. Let $X_i$ be indicator variable for cup $i$ (whether
  it was chosen or not). Probability that $X_i$ was chosen: $1-((n-1)/n)^n
  \approx 1-1/e > 1/2$ for large $n$. 
  Then by a Chernoff Bound we have that $\sum_i X_i$ is tightly concentrated
  around its mean, which is larger than $n$. In particular, with probability
  exponentially close to $1$ in $n$ we have that at least $n/2$ cups were chosen.

    initially solution: no overpowered cups wlog, so if we pick them randomly star holds
    by Hoeffding's. (kinda, bc stuff isnt really independent, can probably swap
    with replacement to fix this tho)
  
\end{proof}
\begin{clm}
  What if $C$ needs to be big because we need big backlog? 
\end{clm}
\begin{proof}
 this isn't a problem because the base case is the only case that needs to
 explicitly deal with positive and negative fill.
\end{proof}
These concerns resolved, the exact same argument as in Proposition
\ref{prop:obliviousBase} gives the desired result.

\end{proof}

\begin{corollary}
  There is an oblivious filling strategy for the variable-processor cup game on
  $n$ cups that achieves backlog $2^{\Omega(\sqrt{\log n})}$ in running time
  $O(n)$
\end{corollary}
\begin{proof}
  We must reduce want to reduce $\log^2 n$ to $\log n$ to achieve the
  appropriate running-time, so we reduce $n$ to $n' = 2^{\sqrt{\log n}}$. This
  detail taken care of we apply exactly the same recursive construction of
  $f_{\theta(\log n)}$ as in Corollary \ref{cor:adaptivePoly}, but using
  repeated application of the Oblivious Amplification Lemma rather than the
  Adaptive Amplification Lemma, which yields the disclaimer that the backlog is
  only achieved with constant probability.
  So we achieve backlog $\Omega(2^{\log n'})$ in running time $O(2^{\log^2
  n'})$. By design, expressing this in terms of $n$ we have running time $O(n)$
  (randomized lower bounds are not supposed to take longer than $\poly(n)$
  time), and as a consequence we get backlog $\Omega(2^{\sqrt{\log n}})$.
\end{proof}


\bibliographystyle{plain}
\bibliography{paper}
\end{document}
