\section{Adaptive Filler Lower Bound}\label{sec:adaptive}

In this section we give a $2^{\polylog n}$-time filling strategy
that achieves backlog $n^{1 - \varepsilon}$ for any positive
constant $\varepsilon$. 
We also give a $O(n!)$-time filling strategy that achieves
backlog $\Omega(n)$.

We begin with a simple proposition that gives backlog $1/2$ for two cups.
\begin{proposition}
  \label{prop:adaptiveBase}
  Consider an instance of the negative-fill $1$-processor cup
  game on $2$ cups, and let the cups start in any state where the
  average fill is $0$. There is an $O(1)$-step adaptive filling
  strategy that achieves backlog at least $1/2$.
\end{proposition}
\begin{proof}
  Let the fills of the $2$ cups start as $x$ and $-x$ for some $x\ge
  0$. If $x\ge 1/2$ the algorithm need not do anything. Otherwise, the filling
  strategy adds $1/2 - x$ fill to the cup with fill $x$, and adds
  $1/2 + x$ fill to the cup with fill $-x$. This results in $2$
  cups both having fill $1/2$; the emptier then empties from one
  of these, and leaves a cup with fill $1/2$, as desired.
\end{proof}

% We begin by modifying the proof of the classic lower bound for
% the single-processor cup game to work with a cup configuration
% that includes negative fills; allowing for negative fills will be
% important when applying the result in later constructions. 
% \begin{proposition}
% \label{prop:adaptiveBaseAlternate}
%   Consider an instance of the negative-fill $1$-processor cup
%   game on $n$ cups, and let the cups start in any state where the
%   average fill is $0$. There is an $O(n)$-step adaptive filling
%   strategy that achieves backlog at least
%   $\frac{1}{4}(\ln (n/2) - 1)$.
% \end{proposition}
% \begin{proof}
%   Let $h = \frac{1}{4}(\ln (n/2) -1)$ be the desired fill. Once a cup with fill at
%   least $h$ is achieved the filler stops, and the algorithm is done.  
  
%   We claim that, at the beginning of the game, either the
%   algorithm is already done, or there are at least $n / 2$ cups
%   containing fills greater than $-2h$. If the filling process is
%   not yet complete then $\fil(c) < h$ for all cups $c$, and thus
%   the mass of the cups with non-negative fills is less than $hn$.
%   Assume for contradiction that at least $n / 2$ cups have fills
%   $-2h$ or smaller. The mass of those cups is less than or equal
%   to $-hn$. Since the mass of the cups with non-negative fills is
%   less than $hn$, it follows that the total mass of the cups is
%   negative, a contradiction. 

%   We now describe the filler's strategy. If the algorithm is not
%   already done at the beginning of the game, then at least $n /
%   2$ cups must have fills greater than $-2h$. At the beginning of
%   the algorithm, $n / 2$ such cups are labeled as \defn{active
%   cups}. In each of step of the algorithm, the filler distributes
%   $1$ unit of water evenly among the active cups. The emptier
%   then removes water from some cup $c$. Finally, the filler
%   reduces the number of active cups by $1$, removing cup $c$ if
%   it was active, and otherwise removing an arbitrary cup. Now
%   consider the state of the final active cup after $n / 2  - 1$
%   steps. This cup's fill has increased by 
%   $$1/(n/2) + 1/(n/2 - 1) + \cdots + 1/2 \ge \ln (n/2) -1 = 4h.$$ 
%   This cup's fill started as at least $-2h$. Thus this cup now
%   has fill at least $2h$, as desired.
% \end{proof}

Next we prove the \defn{Amplification Lemma}.
\begin{lemma}[Adaptive Amplification Lemma]\label{lem:adaptiveAmplification}
  Let $\delta\in(0,1/2)$ be a parameter.
  Let $\alg(f)$ be an adaptive filling strategy that 
  achieves backlog $f(n) < n$ in the negative-fill variable-processor cup game
  on $n$ cups in running time $T(n)$ starting from any initial
  cup state where the average fill is $0$.

  Then there exists an adaptive filling strategy $\alg(f')$ that
  achieves backlog $f'(n)$ satisfying 
  $$f'(n) \ge (1-\delta)f(\floor{(1-\delta)n}) + f(\ceil{\delta n}) $$
  and $f'(n) \ge f(n)$
  in the negative-fill variable-processor cup game on $n$ cups in running time 
  $$T'(n) \le n^2 \delta \cdot T(\floor{(1-\delta)n}) + T(\ceil{\delta n})$$
  starting from any initial cup state where the average fill is $0$.
\end{lemma}

Before proving the Amplification Lemma, we briefly motivate it. 
We call $\alg(f')$, the filling strategy created by the Amplification
Lemma, the \defn{amplification} of $\alg(f)$.
As suggested by the name, $\alg(f')$ will be able to achieve
higher backlog than $\alg(f)$. In particular, we
will show that by starting with a filling strategy $\alg(f_0)$ for achieving
constant backlog and then recursively forming a sufficiently
long sequence of filling strategies $\alg(f_0), \alg(f_1),
\ldots, \alg(f_{i_*})$ with
$\alg(f_{i+1})$ the amplification of $\alg(f_i)$, we eventually
get a filling strategy for achieving $\poly(n)$ backlog.
  
\begin{proof}[Proof of Amplification Lemma]
  The filler defaults to using $\alg(f)$ if $f(n) \ge
(1-\delta)f(\floor{(1-\delta)n}) + f(\ceil{\delta n})$; in this
case using $\alg(f)$
achieves the desired backlog in the desired running time. In the
rest of the proof, we describe our strategy for achieving backlog
$(1-\delta)f(\floor{(1-\delta)n}) + f(\ceil{\delta n})$. 

  Let $A$, the \defn{anchor set}, be initialized to consist of
  the $\ceil{n\delta}$ fullest cups, and let $B$ the
  \defn{non-anchor set} be initialized to consist of the rest of
  the cups (so $|B| = \floor{(1-\delta)n}$). Let $h =
  (1-\delta)f(\floor{(1-\delta)n}).$

  The filler's strategy is roughly as follows: \\
  \textbf{Step 1:} Get $\mu(A) \ge h$ by using $\alg(f)$
  repeatedly on $B$ to achieve cups with fill at least $\mu(B) +
  f(|B|)$ in $B$ and then swapping these into $A$.\\
  \textbf{Step 2:} Use $\alg(f)$ once on $A$ to obtain some cup
  with fill $\mu(A)+f(|A|)$.\\
  Note that in order to use $\alg(f)$ on subsets of the cups the
  filler will need to vary $p$.

  We now describe how to achieve Step 1, which is
  complicated by the fact that the emptier may attempt to
  prevent the filler from achieving high fill in a cup
  in $B$.

  The filling strategy always places $1$ unit of water in each
  anchor cup. This ensures that no cups in the anchor set ever
  have their fill decrease. If the emptier wishes to keep the
  average fill of the anchor cups from increasing, then emptier
  must empty from every anchor cup on each step. If the emptier
  fails to do this on a given round, then we say that the emptier
  has \defn{neglected} the anchor cups. 

  We say that the filler \defn{applies} $\alg(f)$ to $B$ if it
  follows the filling strategy $\alg(f)$ on $B$ while placing $1$
  unit of water in each anchor cup. An application of $\alg(f)$ to
  $B$ is said to be \defn{successful} if $A$ is never neglected
  during the application of $\alg(f)$ to $B$. The filler uses a
  procedure that we call a \defn{swapping-process} to achieve the
  desired average fill in $A$. In a swapping-process, the filler
  repeatedly applies $\alg(f)$ to $B$ until a successful
  application occurs, and then takes the cup generated by
  $\alg(f)$ within $B$ on this successful application with fill at
  least $\mu(B) + f(|B|)$ and swaps it with the least full cup in
  $A$. If the average fill in $A$ ever reaches $h$, then the
  algorithm immediately halts (even if it is in the middle of a
  swapping-process) and is complete.
  
  Note that $$\mu(A) \cdot |A| + \mu(B)\cdot |B| = 0,$$ so
  $$\mu(A) = - \mu(B) \cdot
  \frac{\floor{(1-\delta)n}}{\ceil{\delta n}} \ge -
  \frac{1-\delta}{\delta} \mu(B).$$ Thus, if at any
  point $B$ has average fill lower than $-h \cdot
  \delta/(1-\delta)$, then $A$ has average fill at least $h$, so
  the algorithm is finished. Thus we can assume in our analysis that
  \begin{equation}
    \mu(B) \ge -h\cdot\delta/(1-\delta).
  \label{eq:Batleast}
  \end{equation}
  We will now show that during each swapping process, the filler
  applies $\alg(f)$ to $B$ at most $h n \delta + 1$ times. 
  Each time the emptier neglects the anchor set, the mass of the
  anchor set increases by $1$. If the emptier neglects the anchor set $h
  n\delta + 1$ times, then the average fill in the anchor set increases by
  more than $h$, so the desired average fill is achieved in the
  anchor set. Thus the swapping process consists of at most
  $hn\delta + 1$ applications of $\alg(f)$.  

  Consider the fill of a cup $c$ swapped into $A$ at the end of a
  swapping-process. Cup $c$'s fill is at least $\mu(B) + f(|B|)$,
  which by \eqref{eq:Batleast} is at least
  $$-h \cdot \frac{\delta}{1-\delta} + f(\floor{n (1-\delta)}) =
  (1-\delta)f(\floor{n (1-\delta)}) = h.$$ 
  Thus the algorithm for Step 1 succeeds within $|A| =
  \ceil{\delta n}$ swapping-processes, since at the end of the $|A|$-th
  swapping process every cup in $A$ has fill at least $h$, or
  the algorithm halted before $|A|$ swapping-processes because it
  already achieved $\mu(A) \ge h$. 
  
  Now the filler performs Step 2, i.e. the filler applies
  $\alg(f)$ to $A$, and hence achieves a cup with fill at least 
  $$\mu(A) + f(|A|) \ge (1-\delta)f(\floor{(1-\delta)n)}) + f(\ceil{\delta n}),$$
  as desired.

  Now we analyze the running time of the filling strategy
  $\alg(f')$. First, recall that in Step 1 $\alg(f')$ calls $\alg(f)$ on a
  set of size $\floor{(1-\delta)n}$ as many as $hn\delta +1$ times.
  Because we mandate that $h < n$, Step 1 contributes no more
  than $(n\cdot n\delta) \cdot T(|B|)$ to the running time.
  Step 2 requires applying $\alg(f)$ to $|A|$ cups one time, and hence
  contributes $T(|A|)$ to the running time. Summing these we have
  $$T'(n) \le n^2\delta \cdot T(\floor{(1-\delta)n}) + T(\ceil{\delta n}).$$

\end{proof}

We next show that by recursively using the Amplification Lemma we
can achieve backlog $n^{1 - \varepsilon}$.
\begin{theorem}
  \label{thm:adaptivePoly}
  There is an adaptive filling strategy for the variable-processor cup game on
  $n$ cups that achieves backlog $\Omega(n^{1-\varepsilon})$ for any constant
  $\varepsilon > 0$ of our choice in running time $2^{O(\log^2 n)}$.
\end{theorem}
\begin{proof}
  Take constant $\varepsilon \in (0,1/2)$. Let $c, \delta$ be
  parameters, with $c\in (0,1), 0 < \delta \ll 1/2$, these will
  be chosen later as functions of $\varepsilon$.
  We show how to achieve backlog at least $cn^{1-\varepsilon}-1$.

  By \cref{prop:adaptiveBase} there exists a constant
  $n_0$ such that a filler can achieve backlog $1$
  on $n_0$ cups (e.g., $n_0 = 1000$ works). Let $\alg(f_0)$ by
  the filling strategy described in \cref{prop:adaptiveBase},
  where $f_0(k)
  \ge 1$ for all $k\ge n_0$. 

  Next, using the Amplification Lemma we recursively construct
  $\alg(f_{i+1})$ as the amplification of $\alg(f_{i})$ for $i\ge 0$. 

  Define a sequence $g_i$ with 
  $$ g_i = \begin{cases}
    \ceil{16/\delta},  & i = 0,\\
    \floor{g_{i-1}/(1-\delta)} & i \ge 1
  \end{cases} $$

  We claim the following regarding this construction:
  \begin{clm}
    \label{clm:fikinduction}
    For all $i\ge0$,
    \begin{equation}
      f_i(k) \ge ck^{1-\varepsilon}-1\,\, \text{ for all }\,\, k\in [g_{i}].
    \label{eqn:fikinduction}
    \end{equation}
  \end{clm}
  \begin{proof}
  We prove \cref{clm:fikinduction} by induction on $i$.
  For $i=0$, the base case, \eqref{eqn:fikinduction} can
  be made true by taking $c$ and $\delta$ sufficiently small.
  In particular, we we choose $c=\Theta(1)$ small enough to make 
  $c n_0^{1-\varepsilon} -1 \le 0$, which implies
  \eqref{eqn:fikinduction} holds for $k \in [n_0]$ by
  monotonicity of $ck^{1-\varepsilon}-1$; we also choose $\delta$
  small enough to make $g_0 \ge n_0$, and we choose $c$ small
  enough to make $c g_0^{1-\varepsilon} -1 \le f_0(g_0) = 1$, which
  implies \eqref{eqn:fikinduction} holds for $k\in [n_0, g_0]$ by
  monotonicity of $ck^{1-\varepsilon}-1$. \footnote{Note
  that it is important here that $\varepsilon$ and
  $\delta$ are constants, that way $c$ is also a constant.}

  As our inductive hypothesis we assume
  \eqref{eqn:fikinduction} for $f_i$; we aim to show that 
  \eqref{eqn:fikinduction} holds for $f_{i+1}$. Note that, by
  design of $g_i$, if $k \le g_{i+1}$ then $\floor{k\cdot (1-\delta)} \le g_i$.
  Consider any $k\in [g_{i+1}]$. First we deal with the trivial
  case where $k \le g_0$. In this case 
  $$f_{i+1}(k) \ge f_i(k) \ge \cdots \ge f_0(k) \ge ck^{1-\varepsilon} -1.$$

  Now we consider the case where $k \ge g_0$.
  Since $f_{i+1}$ is the amplification of $f_i$ we have
  $$f_{i+1}(k) \ge (1-\delta) f_i(\floor{(1-\delta)k}) + f_i(\ceil{\delta k}).$$
  By our inductive hypothesis, which applies as $\ceil{\delta k}\le g_i, \floor{k\cdot (1-\delta)} \le g_i$, we have
  $$f_{i+1}(k) \ge (1-\delta) (c \cdot\floor{(1-\delta)k}^{1-\varepsilon}-1) + c\ceil{\delta k}^{1-\varepsilon} - 1. $$
  Dropping the floor and ceiling, incurring a $-1$ for dropping the floor, we have
  $$f_{i+1}(k) \ge (1-\delta) (c \cdot ((1-\delta)k-1)^{1-\varepsilon}-1) + c (\delta k)^{1-\varepsilon} - 1.$$
  Because $(x-1)^{1-\varepsilon} \ge x^{1-\varepsilon} -1$, due to the
  fact that $x\mapsto x^{1-\varepsilon}$ is a sub-linear
  sub-additive function, we have 
  $$f_{i+1}(k) \ge (1-\delta) c \cdot (((1-\delta)k)^{1-\varepsilon}-2) + c(\delta k)^{1-\varepsilon}-1.$$
  Moving the $ck^{1-\varepsilon}$ to the front we have
  $$ f_{i+1}(k) \ge ck^{1-\varepsilon} \cdot\left((1-\delta)^{2-\varepsilon} + \delta^{1-\varepsilon} - \frac{2(1-\delta)}{k^{1-\varepsilon}} \right) -1.$$
  Because $(1-\delta)^{2-\varepsilon} \ge 1-(2-\varepsilon)\delta$, a fact called Bernoulli's Identity, we have
  $$f_{i+1}(k) \ge ck^{1-\varepsilon} \cdot\left(1-(2-\varepsilon)\delta + \delta^{1-\varepsilon} - \frac{2(1-\delta)}{k^{1-\varepsilon}} \right)-1.$$
  Of course $-2(1-\delta) \ge -2$, so 
  $$f_{i+1}(k) \ge ck^{1-\varepsilon} \cdot\left(1-(2-\varepsilon)\delta + \delta^{1-\varepsilon} - \frac{2}{k^{1-\varepsilon}} \right) -1.$$
  Because 
  $$\frac{-2}{k^{1-\varepsilon}} \ge \frac{-2}{g_0^{1-\varepsilon}} \ge -2(\delta/16)^{1-\varepsilon} \ge -\delta^{1-\varepsilon}/2,$$ 
  which follows from our choice of $g_0 = \ceil{16/\delta}$ and the restriction
  $\varepsilon<1/2$, we have
  $$f_{i+1}(k) \ge ck^{1-\varepsilon}
  \cdot\left(1-(2-\varepsilon)\delta + \delta^{1-\varepsilon} - \delta^{1-\varepsilon}/2 \right)-1.$$
  Finally, combining terms we have
  $$f_{i+1}(k) \ge  ck^{1-\varepsilon} \cdot\left(1-(2-\varepsilon)\delta + \delta^{1-\varepsilon}/2\right)-1. $$

  Because $\delta^{1-\varepsilon}$ dominates $\delta$ for
  sufficiently small $\delta$, there is a choice of
  $\delta=\Theta(1)$ such that 
  $$1-(2-\varepsilon)\delta + \delta^{1-\varepsilon}/2 \ge 1.$$ 
  Taking $\delta$ to be this
  small we have,
  $$f_{i+1}(k) \ge ck^{1-\varepsilon}-1,$$
  completing the proof. We remark that the choices of $c, \delta$
  are the same for every $i$ in the inductive proof, and depend
  only on $\varepsilon$. 
  \end{proof}

  To complete the proof, we will show that $g_i$ grows exponentially in $i$. Thus,
  after there exists $i_* \le O(\log n)$ such that
  $g_{i_*} \ge n$, and hence we have an algorithm $\alg(f_{i_*})$
  that achieves backlog $cn^{1-\varepsilon}-1$ on $n$ cups, as
  desired.
  
  We lower bound the sequence $g_i$ with another sequence $g_i'$
  defined as 
  $$g_i'=\begin{cases}
    4/\delta, & i=0\\
    g_{i-1}' / (1-\delta) -1, & i> 0.
  \end{cases}$$
  Solving this recurrence, we find 
  $$g_i' = \frac{4-(1-\delta)^2}{\delta} \frac{1}{(1-\delta)^i}
  \ge \frac{1}{(1-\delta)^i},$$
  which clearly exhibits exponential growth. 
  In particular, let $i_* = \ceil{\log_{1/(1-\delta)} n}$. Then,
  $$ g_{i_*} \ge g_{i_*}' \ge n,$$ as desired.

  Let the running time of $f_i(n)$ be $T_i(n)$. From the Amplification Lemma we have following recurrence bounding $T_i(n)$:
  \begin{align*}
  T_i(n) &\le n^2\delta \cdot T_{i-1}(\floor{(1-\delta)n}) +
  T_{i-1}(\ceil{\delta n}) \\
  &\le 2n^2T_{i-1}(\floor{(1-\delta)n}).
  \end{align*}
  It follows that $\alg(f_{i_*})$, recalling that $i_* \le O(\log n)$, has running time
  $$T_{i_*}(n) \le (2n^2)^{O(\log n)} \le 2^{O(\log^2 n)}$$
  as desired.

\end{proof}

Now we provide a very simple construction that can achieve backlog $\Omega(n)$
in very long games. The construction can be interpreted as the same
argument as in \cref{thm:adaptivePoly} but with an extremal setting of
$\delta$ to $\Theta(1/n)$. \footnote{Or more precisely, setting
$\delta$ in each level of recursion to be $\Theta(1 / n)$, where
$n$ is the subproblem size; note in particular that $\delta$
changes between levels of recursion, which was not the case in
the proof of \cref{thm:adaptivePoly}.}

\begin{proposition}
  \label{prop:factorialTimeAlg}
  There is an adaptive filling strategy that
  achieves backlog $\Omega(n)$ in time $O(n!)$.
\end{proposition}
\begin{proof}
  We start, as in the proof of \cref{thm:adaptivePoly}, with an
  algorithm $\alg(f_0)$ for
  achieving backlog $f_0(k) \ge 1$ on $k\ge n_0$ cups, which is
  possible by \cref{prop:adaptiveBase}. 
  For $i > 0$ we construct $\alg(f_{i})$ as the
  amplification of $\alg(f_{i-1})$ using the 
  Amplification Lemma with parameter $\delta = 1/(i+1)$. 

  We claim the following regarding this construction:
  \begin{clm}
    \label{clm:yayactuallygetn}
  For all $i\ge 0$,
  \begin{equation}
    \label{eq:omegaNpfinduction}
    f_i((i+1)\cdot n_0) \ge \sum_{j=0}^i \left(1-\frac{j}{i+1}\right).
  \end{equation}
  \end{clm}
  \begin{proof}
  We prove \cref{clm:yayactuallygetn} by induction on $i$. When $i=0$, the base case, \eqref{eq:omegaNpfinduction} becomes 
  $f_{0}(n_0) \ge 1$ which is true. Assuming
  \eqref{eq:omegaNpfinduction} for $f_{i-1}$, we now show
  \eqref{eq:omegaNpfinduction} holds for $f_{i}$.
  Because $f_{i}$ is the amplification of $f_{i-1}$ with $\delta = 1/(i+1)$, we have by the Amplification Lemma
  $$f_{i}((i+1)\cdot n_0) \ge \left(1 - \frac{1}{i+1}\right) f_{i-1}(i\cdot n_0) + f_{i-1}(n_0).$$
  Since $f_{i-1}(n_0) \ge f_0(n_0) \ge 1$ we have
  $$f_{i}((i+1)\cdot n_0) \ge \left(1 - \frac{1}{i+1}\right) f_{i-1}(i\cdot n_0) + 1.$$
  Using the inductive hypothesis we have
  $$f_{i}((i+1)\cdot n_0) \ge \left(1 - \frac{1}{i+1}\right)\sum_{j=0}^{i-1} \left(1-\frac{j}{i}\right) + 1.$$
  Note that 
  \begin{align*}
    \left(1 - \frac{1}{i+1}\right)\cdot \left(1-\frac{j}{i}\right) &= \frac{i}{i+1} \cdot \frac{i-j}{i} \\
  &= \frac{i-j}{i+1}\\
  &= 1 - \frac{j+1}{i+1}.
  \end{align*}
  Thus we have
  $$f_{i}((i+1)\cdot n_0) \ge \sum_{j=1}^{i} \left(1-\frac{j}{i+1}\right) + 1 = \sum_{j=0}^{i} \left(1-\frac{j}{i+1}\right),$$
  as desired.
  \end{proof}

  Let $i_* = \floor{n/n_0}-1$, which by design satisfies
  $(i_*+1)n_0 \le n$. By \cref{clm:yayactuallygetn} we have
  $$f_{i_*}((i_*+1)\cdot n_0) \ge \sum_{j=0}^{i_*} \left(1 -
  \frac{j}{i_*+1} \right) = i_*/2 + 1.$$ As $i_* = \Theta(n)$, we
  have thus shown that $\alg(f_{i_*})$ can achieve backlog
  $\Omega(n)$ on $n$ cups.

    Let $T_i$ be the running time of $\alg(f_i)$.
  The recurrence for the running running time of $f_{i_*}$ is 
  $$T_i(n) \le n \cdot n_0T_{i-1}(n-n_0)+O(1).$$
  Clearly $T_{i_*}(n) \le O(n!)$.

  % This algorithm can be interpreted very simply. To achieve large backlog on
  % $n$ cups we create an anchor set $A$ of $n_0$ cups and a set $B$ of $n-n_0$
  % cups; We recursively apply our strategy to $B$ for each cup in $A$. In
  % order for the average fill difference between $A$ and $B$ to be $f(n-n_0)$,
  % $\mu(A)$ must rise by $\frac{n-n_0}{n}$ of this difference whereas $\mu(B)$
  % must sink by $\frac{n_0}{n}$ of this difference. Hence we achieve average
  % fill $\frac{n-n_0}{n}f(n-n_0)$ in $A$. Then, using the strategy from
  % \cref{prop:adaptiveBase} we can achieve backlog $1$ on these cups. 
\end{proof}

